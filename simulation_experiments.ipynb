{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jesper\\Documents\\GitHub\\Knowledge-Growth-Prediction\\models\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import em_algorithm\n",
    "from simulation_framework.simulate_competency import respondent_population\n",
    "from simulation_framework.simulate_responses import response_simulation\n",
    "from scipy.stats import multivariate_normal\n",
    "import models\n",
    "import em_algorithm\n",
    "import pandas as pd\n",
    "import time\n",
    "from girth import multidimensional_twopl_mml\n",
    "from girth import twopl_mml\n",
    "import cma\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def params_to_vector(model):\n",
    "    item_dimension = model.item_dimension\n",
    "    latent_dimension = model.latent_dimension\n",
    "    A_flat = model.item_parameters[\"discrimination_matrix\"].flatten()\n",
    "    A_flat = A_flat[A_flat != 0]\n",
    "    A_cut = len(A_flat)\n",
    "    delta_cut = A_cut+item_dimension\n",
    "    delta = model.item_parameters[\"intercept_vector\"]\n",
    "    sigma_flat = model.person_parameters[\"covariance\"][np.triu_indices(\n",
    "            model.latent_dimension, k=1)]\n",
    "    return(np.concatenate((A_flat, delta, sigma_flat), axis=0))\n",
    "\n",
    "def vector_to_params(vector, model):\n",
    "    item_dimension = model.item_dimension\n",
    "    latent_dimension = model.latent_dimension \n",
    "    q_matrix = model.item_parameters[\"q_matrix\"] \n",
    "    q_flat = q_matrix.flatten()\n",
    "    A_cut = len(q_flat[q_flat != 0])\n",
    "    delta_cut = A_cut+item_dimension\n",
    "    A = vector[0:A_cut]\n",
    "    A = model.fill_zero_discriminations(A).reshape((item_dimension, latent_dimension))\n",
    "    delta = vector[A_cut:delta_cut]\n",
    "    item_parameters = {\"discrimination_matrix\": A, \"intercept_vector\": delta}\n",
    "    corr = vector[delta_cut: len(vector)]\n",
    "    sigma = model.corr_to_sigma(corr, False)\n",
    "    return({\"item_parameters\": item_parameters, \"person_parameters\": {\"covariance\": sigma}})\n",
    "\n",
    "def direct_marginal_optimization(model, response_data):\n",
    "    #Get initial parameters\n",
    "    x0 = params_to_vector(model)\n",
    "    response_data = response_data.to_numpy()\n",
    "    #Optimize with GA\n",
    "    def marginal_l_func(input_vector):\n",
    "        parameters = vector_to_params(input_vector, model)\n",
    "        try:\n",
    "            model.set_parameters(parameters)\n",
    "        except Exception:\n",
    "            return(np.inf)\n",
    "        result = -1*model.marginal_response_loglikelihood(response_data)\n",
    "        return(result)\n",
    "    es = cma.CMAEvolutionStrategy(x0=x0, sigma0=0.5)\n",
    "    es.optimize(marginal_l_func, maxfun=100000)\n",
    "    #Get result\n",
    "    result = es.result.xfavorite\n",
    "    return(vector_to_params(result, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.mirt_2pl import mirt_2pl\n",
    "\n",
    "def rmse(y_pred: np.array, y_true: np.array) -> float:\n",
    "    MSE = np.square(np.subtract(y_pred.flatten(), y_true.flatten())).mean()\n",
    "    RMSE = np.sqrt(MSE)\n",
    "    return(float(RMSE))\n",
    "\n",
    "def experiment_performance(estimated_parameter_dict, real_parameter_dict):\n",
    "    res_dict = {}\n",
    "    if \"item_parameters\" in estimated_parameter_dict.keys():\n",
    "        A_pred = estimated_parameter_dict[\"item_parameters\"][\"discrimination_matrix\"]\n",
    "        delta_pred = estimated_parameter_dict[\"item_parameters\"][\"intercept_vector\"]\n",
    "\n",
    "        A_true = real_parameter_dict[\"item_parameters\"][\"discrimination_matrix\"]\n",
    "        delta_true = real_parameter_dict[\"item_parameters\"][\"intercept_vector\"]\n",
    "\n",
    "        print(\"Absolute diff in A:\")\n",
    "        print(np.abs(A_true-A_pred))\n",
    "\n",
    "        print(\"Absolute diff in delta:\")\n",
    "        print(np.abs(delta_true-delta_pred))\n",
    "\n",
    "        res_dict[\"rmse_A\"] = rmse(A_pred, A_true)\n",
    "        res_dict[\"rmse_delta\"] = rmse(delta_true, delta_pred)\n",
    "\n",
    "    if \"person_parameters\" in estimated_parameter_dict.keys():\n",
    "        sigma_pred = estimated_parameter_dict[\"person_parameters\"][\"covariance\"]\n",
    "        sigma_true = real_parameter_dict[\"person_parameters\"][\"covariance\"]\n",
    "\n",
    "        print(\"Absolute diff in sigma:\")\n",
    "        print(np.abs(sigma_true-sigma_pred)) \n",
    "\n",
    "        res_dict[\"rmse_sigma\"] = rmse(sigma_true, sigma_pred) \n",
    "    if len(res_dict.keys())==0:\n",
    "        raise Exception(\"No performance to calculate\")\n",
    "    return(res_dict)\n",
    "\n",
    "def standardize_parameters(parameter_dict):\n",
    "        covariance = parameter_dict[\"person_parameters\"][\"covariance\"]\n",
    "        A = parameter_dict[\"item_parameters\"][\"discrimination_matrix\"]\n",
    "        if len(covariance.shape)<=1:\n",
    "            standardized_cov = np.array([[1]])\n",
    "            inv_sqrt_cov = np.array([[np.sqrt(1/covariance)]])\n",
    "            A = np.multiply(A, inv_sqrt_cov)\n",
    "        else:\n",
    "            inv_sqrt_cov = np.linalg.inv(scipy.linalg.sqrtm(covariance))\n",
    "            standardized_cov = np.dot(np.dot(inv_sqrt_cov, covariance), inv_sqrt_cov)\n",
    "            A = np.dot(A, np.linalg.inv(inv_sqrt_cov))\n",
    "        parameter_dict[\"item_parameters\"][\"discrimination_matrix\"] = A\n",
    "        parameter_dict[\"person_parameters\"][\"covariance\"] = standardized_cov\n",
    "        return(parameter_dict)\n",
    "\n",
    "def create_parameter_dict(estimated_early_parameters, real_early_parameters, estimated_late_parameters, real_late_parameters):\n",
    "    parameter_dict = {\"real_early_parameters\": real_early_parameters,\n",
    "                   \"estimated_early_parameters\": estimated_early_parameters}\n",
    "    return(parameter_dict)\n",
    "\n",
    "\n",
    "def create_performance_dict(parameter_dict, run_dict, sample=None, baselines=None, model=None):\n",
    "    result_dict = parameter_dict\n",
    "    result_dict[\"sample\"] = sample\n",
    "    #Model Performance\n",
    "    result_dict[\"early_performance\"] = {}\n",
    "    result_dict[\"early_performance\"][\"rmse\"] = experiment_performance(real_parameter_dict=result_dict[\"real_early_parameters\"], \n",
    "                                                              estimated_parameter_dict=result_dict[\"estimated_early_parameters\"])\n",
    "    #Baseline's Performance\n",
    "    baselines[\"early_initial\"][\"performance\"] = {\"rmse\": experiment_performance(real_parameter_dict=result_dict[\"real_early_parameters\"], \n",
    "                                                              estimated_parameter_dict=baselines[\"early_initial\"][\"parameters\"])}\n",
    "    if \"girth\" in baselines.keys():\n",
    "        girth_data = result_dict[\"sample\"][\"early_responses\"].to_numpy().transpose()\n",
    "        if model.latent_dimension == 1:\n",
    "            girth_estimates = twopl_mml(girth_data)\n",
    "        else:\n",
    "            girth_estimates = multidimensional_twopl_mml(girth_data, n_factors=model.latent_dimension)\n",
    "        girth_item_parameters = {\"discrimination_matrix\": girth_estimates[\"Discrimination\"], \"intercept_vector\": girth_estimates[\"Difficulty\"]}\n",
    "        girth_parameters = {\"item_parameters\": girth_item_parameters}\n",
    "        girth_estimated_covariance = np.cov(girth_estimates[\"Ability\"], rowvar=True)\n",
    "        girth_parameters[\"person_parameters\"] = {\"covariance\": girth_estimated_covariance}\n",
    "        girth_parameters = standardize_parameters(girth_parameters)\n",
    "        girth_performance_rmse = experiment_performance(real_parameter_dict=result_dict[\"real_early_parameters\"], \n",
    "                                                              estimated_parameter_dict=girth_parameters)\n",
    "        baselines[\"girth\"][\"parameters\"] = girth_parameters\n",
    "        baselines[\"girth\"][\"performance\"] = {\"rmse\": girth_performance_rmse}\n",
    "\n",
    "    if \"early_direct\" in baselines.keys():\n",
    "        dir_model = mirt_2pl(item_dimension=model.item_dimension, latent_dimension=model.latent_dimension, Q=model.item_parameters[\"q_matrix\"])\n",
    "        direct_early_item_parameters = direct_marginal_optimization(dir_model, response_data=sample[\"early_responses\"])\n",
    "        direct_early_performance_rmse = experiment_performance(real_parameter_dict=result_dict[\"real_early_parameters\"], \n",
    "                                                              estimated_parameter_dict=direct_early_item_parameters)\n",
    "        baselines[\"early_direct\"][\"parameters\"] = direct_early_item_parameters\n",
    "        baselines[\"early_direct\"][\"performance\"] = {\"rmse\": direct_early_performance_rmse}\n",
    "\n",
    "    result_dict[\"baselines\"] = baselines\n",
    "    likelihood = calculate_marginal_likelihoods(model=model, response_data=sample[\"early_responses\"], real_parameters=result_dict[\"real_early_parameters\"],\n",
    "                                                initial_parameters=baselines[\"early_initial\"][\"parameters\"], estimated_parameters=result_dict[\"estimated_early_parameters\"])\n",
    "    result_dict[\"early_performance\"][\"marginal_likelihood\"] = likelihood\n",
    "    result_dict[\"early_performance\"][\"run\"] = run_dict[\"early\"]\n",
    "    return(result_dict)\n",
    "\n",
    "def calculate_marginal_likelihoods(model, response_data, real_parameters, initial_parameters, estimated_parameters):\n",
    "    model.set_parameters(initial_parameters)\n",
    "    initial_marginal_likelihood = model.marginal_response_loglikelihood(response_data=response_data.to_numpy())\n",
    "    model.set_parameters(real_parameters)\n",
    "    optimal_marginal_likelihood = model.marginal_response_loglikelihood(response_data=response_data.to_numpy())\n",
    "    model.set_parameters(estimated_parameters)\n",
    "    marginal_likelihood_estimated = model.marginal_response_loglikelihood(response_data=response_data.to_numpy())\n",
    "    likelihood_dict = {\"optimal\": optimal_marginal_likelihood, \"estimated\": marginal_likelihood_estimated, \"initial\": initial_marginal_likelihood}\n",
    "    return(likelihood_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def direct_optimization_benchmark():\n",
    "    latent_dimension = 2\n",
    "    item_dimension = 6\n",
    "    sample_size=100\n",
    "\n",
    "    #Define Population\n",
    "    real_latent_cov = np.array([[1,0.2],\n",
    "                    [0.2,1]])\n",
    "\n",
    "    latent_distribution = multivariate_normal(mean=np.array([0,0]), cov=real_latent_cov)\n",
    "    population = respondent_population(latent_dimension=latent_dimension, latent_distribution=latent_distribution)\n",
    "\n",
    "    #Define Test\n",
    "    A = np.array([[0.5,0],\n",
    "                  [2,0],\n",
    "                  [0,0.4],\n",
    "                  [0.7,0.6],\n",
    "                  [2, 0.9],\n",
    "                  [0, 1.5]])\n",
    "    Q = np.array([[1,0],\n",
    "                  [1,0],\n",
    "                  [0,1],\n",
    "                  [1,1],\n",
    "                  [1,1],\n",
    "                  [0,1]])\n",
    "\n",
    "    delta = np.array([0, 0.5, 1, 0, 1.5, 0.9])\n",
    "    early_item_parameters = {\"discrimination_matrix\": A, \"intercept_vector\": delta, \"q_matrix\": Q, \"item_dimension\": item_dimension, \"latent_dimension\": latent_dimension}\n",
    "    real_early_parameters = {\"item_parameters\": early_item_parameters, \"person_parameters\": {\"covariance\": real_latent_cov}}\n",
    "\n",
    "    #Sample responses\n",
    "    response_simulation_obj = response_simulation(population=population, item_dimension = item_dimension, early_item_params=early_item_parameters)\n",
    "    sample = response_simulation_obj.sample(sample_size)\n",
    "\n",
    "    #Fit Parameters\n",
    "    #Initialize model\n",
    "    model = models.mirt_2pl(latent_dimension=2, item_dimension=6, Q=Q)\n",
    "    model.initialize_from_responses(response_data=sample[\"early_responses\"])\n",
    "\n",
    "    estimated_params = direct_marginal_optimization(model, response_data=sample[\"early_responses\"])\n",
    "    return(estimated_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#direct_result_dict = direct_optimization_benchmark()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 0: MIRT-2PL Performance Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mirt_performance_benchmark() -> dict:\n",
    "    latent_dimension = 2\n",
    "    item_dimension = 6\n",
    "    sample_size=100\n",
    "\n",
    "    #Define Population\n",
    "    real_latent_cov = np.array([[1,0.2],\n",
    "                    [0.2,1]])\n",
    "\n",
    "    latent_distribution = multivariate_normal(mean=np.array([0,0]), cov=real_latent_cov)\n",
    "    population = respondent_population(latent_dimension=latent_dimension, latent_distribution=latent_distribution)\n",
    "\n",
    "    #Define Test\n",
    "    A = np.array([[0.5,0],\n",
    "                  [2,0],\n",
    "                  [0,0.4],\n",
    "                  [0.7,0.6],\n",
    "                  [2, 0.9],\n",
    "                  [0, 1.5]])\n",
    "    Q = np.array([[1,0],\n",
    "                  [1,0],\n",
    "                  [0,1],\n",
    "                  [1,1],\n",
    "                  [1,1],\n",
    "                  [0,1]])\n",
    "\n",
    "    delta = np.array([0, 0.5, 1, 0, 1.5, 0.9])\n",
    "    early_item_parameters = {\"discrimination_matrix\": A, \"intercept_vector\": delta, \"q_matrix\": Q, \"item_dimension\": item_dimension, \"latent_dimension\": latent_dimension}\n",
    "    real_early_parameters = {\"item_parameters\": early_item_parameters, \"person_parameters\": {\"covariance\": real_latent_cov}}\n",
    "\n",
    "    #Sample responses\n",
    "    response_simulation_obj = response_simulation(population=population, item_dimension = item_dimension, early_item_params=early_item_parameters)\n",
    "    sample = response_simulation_obj.sample(sample_size)\n",
    "\n",
    "    #Fit Parameters\n",
    "    #Initialize model\n",
    "    model = models.mirt_2pl(latent_dimension=2, item_dimension=6, Q=Q)\n",
    "    model.initialize_from_responses(response_data=sample[\"early_responses\"])\n",
    "    initial_early_parameters = model.get_parameters()\n",
    "    e_step = em_algorithm.e_step_ga_mml(model=model)\n",
    "    m_step = em_algorithm.m_step_ga_mml(model)\n",
    "    em = em_algorithm.em_algo(e_step=e_step, m_step=m_step, model=model)\n",
    "\n",
    "    #Fit Model\n",
    "    start_time = time.time()\n",
    "    em.fit(sample[\"early_responses\"], max_iter=50)\n",
    "    run_time =  (time.time() - start_time)\n",
    "\n",
    "    #Create Baselines\n",
    "    baselines = {\"early_initial\": {\"parameters\": initial_early_parameters}, \"girth\": {}, \"early_direct\": {}}\n",
    "    \n",
    "    #Create results\n",
    "    early_estimated_parameters = em.model.get_parameters()\n",
    "\n",
    "    parameter_dict = create_parameter_dict(estimated_early_parameters=early_estimated_parameters,\n",
    "                          real_early_parameters = real_early_parameters,\n",
    "                          estimated_late_parameters=None, real_late_parameters=None)\n",
    "    run_dict = {\"early\": {\"runtime\": run_time,\n",
    "                \"number_steps\": em.n_steps}}\n",
    "    performance_dict = create_performance_dict(parameter_dict=parameter_dict, run_dict=run_dict, sample=sample, baselines=baselines, model=model)\n",
    "    return(performance_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print_result(result_dict, description=\"\"):\n",
    "    #Description\n",
    "    print(\"------------------------------------\")\n",
    "    print(\"##### Results for {0}\".format(description))\n",
    "    #Experiment Properties:\n",
    "    latent_dimension = result_dict[\"sample\"][\"latent_dimension\"]\n",
    "    item_dimension = result_dict[\"sample\"][\"item_dimension\"]\n",
    "    sample_size = result_dict[\"sample\"][\"sample_size\"]\n",
    "    print(\"Latent dimension: {0},  Item dimension: {1}, sample size {2} \\\\\".format(latent_dimension, item_dimension, sample_size))\n",
    "    #Performance/time\n",
    "    ep_dict = result_dict[\"early_performance\"]\n",
    "    runtime = np.round(ep_dict[\"run\"][\"runtime\"], 2)\n",
    "    steps = ep_dict[\"run\"][\"number_steps\"]\n",
    "    print(\"Runtime: {0} seconds, {1} steps, {2} seconds per step \\\\\".format(runtime, steps, np.round(runtime/steps, 2)))\n",
    "    #Performance/results\n",
    "    l_optimal = np.round(ep_dict[\"marginal_likelihood\"][\"optimal\"], 2)\n",
    "    l_estimated = np.round(ep_dict[\"marginal_likelihood\"][\"estimated\"], 2)\n",
    "    l_real = np.round(ep_dict[\"marginal_likelihood\"][\"initial\"], 2)\n",
    "    print(\"Optimal marginal Likelihood: {0}, Estimated: {1}, Initial {2}\".format(l_optimal,l_estimated,l_real))\n",
    "    #print(\"Performance: rmse-mean = {0} \\\\\".format(np.round(np.mean(np.array(list(result_dict[\"early_performance\"].values()))), 4)))\n",
    "    rmse_model = ep_dict[\"rmse\"]\n",
    "    \n",
    "    rmse_frame = pd.DataFrame(columns=[\"rmse_A\", \"rmse_delta\", \"rmse_sigma\"])\n",
    "    rmse_frame = rmse_frame.append(rmse_model, ignore_index=True)\n",
    "    index = [\"estimated\"]\n",
    "    for baseline in list(result_dict[\"baselines\"].keys()):\n",
    "        rmse_baseline = result_dict[\"baselines\"][baseline][\"performance\"][\"rmse\"]\n",
    "        rmse_frame = rmse_frame.append(rmse_baseline, ignore_index=True)\n",
    "        index.append(baseline)\n",
    "    rmse_frame.index = index\n",
    "    print(rmse_frame.to_markdown())\n",
    "                                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EM Iteration 1\n",
      "E-step\n",
      "M-step\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 1: current parameter_diff: 1.2567301074756312, current marginal loglikelihood: -375.1421997312442\n",
      "EM Iteration 2\n",
      "E-step\n",
      "M-step\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 2: current parameter_diff: 1.1735462079724877, current marginal loglikelihood: -373.45158271723454\n",
      "EM Iteration 3\n",
      "E-step\n",
      "M-step\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jesper\\Documents\\GitHub\\Knowledge-Growth-Prediction\\em_algorithm\\e_step_mirt_2pl.py:121: RuntimeWarning: divide by zero encountered in log\n",
      "  factor = np.log(self.model.latent_density(theta, sigma=sigma))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 3: current parameter_diff: 0.8265478443830845, current marginal loglikelihood: -373.4654458545487\n",
      "Absolute diff in A:\n",
      "[[0.5        0.        ]\n",
      " [0.46339285 0.        ]\n",
      " [0.         0.71731294]\n",
      " [0.3        0.4       ]\n",
      " [0.03802601 0.14669707]\n",
      " [0.         0.5       ]]\n",
      "Absolute diff in delta:\n",
      "[0.12014431 0.26055518 0.02438504 0.08004271 0.21689406 0.13450474]\n",
      "Absolute diff in sigma:\n",
      "[[0.         0.19761626]\n",
      " [0.19761626 0.        ]]\n",
      "Absolute diff in A:\n",
      "[[0.5 0. ]\n",
      " [1.  0. ]\n",
      " [0.  0.6]\n",
      " [0.3 0.4]\n",
      " [1.  0.1]\n",
      " [0.  0.5]]\n",
      "Absolute diff in delta:\n",
      "[0.12014431 0.25883794 0.1998807  0.08004271 0.50537742 0.23670578]\n",
      "Absolute diff in sigma:\n",
      "[[0.  0.2]\n",
      " [0.2 0. ]]\n",
      "Absolute diff in A:\n",
      "[[0.96034219 0.56850671]\n",
      " [2.81360249 2.42479264]\n",
      " [0.36796096 0.33191234]\n",
      " [0.43219029 0.04798496]\n",
      " [1.73557079 1.45570555]\n",
      " [3.82950637 1.56957838]]\n",
      "Absolute diff in delta:\n",
      "[0.14161911 0.04648048 0.02454361 0.09092068 0.61251765 1.28998857]\n",
      "Absolute diff in sigma:\n",
      "[[4.4408921e-16 2.0000000e-01]\n",
      " [2.0000000e-01 0.0000000e+00]]\n",
      "(6_w,12)-aCMA-ES (mu_w=3.7,w_1=40%) in dimension 15 (seed=251882, Wed Sep 14 16:27:53 2022)\n",
      "Iterat #Fevals   function value  axis ratio  sigma  min&max std  t[m:s]\n",
      "    1     12 4.016511488399090e+02 1.0e+00 4.74e-01  5e-01  5e-01 0:00.1\n",
      "    2     24 3.927471973199310e+02 1.1e+00 4.58e-01  4e-01  5e-01 0:00.1\n",
      "    3     36 3.872821762088916e+02 1.2e+00 4.37e-01  4e-01  4e-01 0:00.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jesper\\Anaconda3\\lib\\site-packages\\cma\\utilities\\utils.py:343: UserWarning: function values with index [7] are not finite but [inf]. (class=CMAEvolutionStrategy method=ask )\n",
      "  warnings.warn(msg + ' (' +\n",
      "c:\\Users\\Jesper\\Anaconda3\\lib\\site-packages\\cma\\utilities\\utils.py:343: UserWarning: function values with index [7] are not finite but [inf]. (class=CMAEvolutionStrategy method=ask iteration=1)\n",
      "  warnings.warn(msg + ' (' +\n",
      "c:\\Users\\Jesper\\Anaconda3\\lib\\site-packages\\cma\\utilities\\utils.py:343: UserWarning: function values with index [8] are not finite but [inf]. (class=CMAEvolutionStrategy method=ask iteration=2)\n",
      "  warnings.warn(msg + ' (' +\n",
      "c:\\Users\\Jesper\\Anaconda3\\lib\\site-packages\\cma\\utilities\\utils.py:343: UserWarning: function values with index [3, 7, 9] are not finite but [inf, inf, inf]. (class=CMAEvolutionStrategy method=ask iteration=7)\n",
      "  warnings.warn(msg + ' (' +\n",
      "c:\\Users\\Jesper\\Anaconda3\\lib\\site-packages\\cma\\utilities\\utils.py:343: UserWarning: function values with index [1] are not finite but [inf]. (class=CMAEvolutionStrategy method=ask iteration=8)\n",
      "  warnings.warn(msg + ' (' +\n",
      "c:\\Users\\Jesper\\Anaconda3\\lib\\site-packages\\cma\\utilities\\utils.py:343: UserWarning: function values with index [3, 6] are not finite but [inf, inf]. (class=CMAEvolutionStrategy method=ask iteration=10)\n",
      "  warnings.warn(msg + ' (' +\n",
      "c:\\Users\\Jesper\\Anaconda3\\lib\\site-packages\\cma\\utilities\\utils.py:343: UserWarning: function values with index [4, 8] are not finite but [inf, inf]. (class=CMAEvolutionStrategy method=ask iteration=11)\n",
      "  warnings.warn(msg + ' (' +\n",
      "c:\\Users\\Jesper\\Anaconda3\\lib\\site-packages\\cma\\utilities\\utils.py:343: UserWarning: function values with index [4] are not finite but [inf]. (class=CMAEvolutionStrategy method=ask iteration=12)\n",
      "  warnings.warn(msg + ' (' +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   48    576 3.701673977864670e+02 2.5e+00 9.22e-02  6e-02  1e-01 0:03.3\n",
      "  100   1200 3.699217640340609e+02 3.9e+00 3.98e-02  2e-02  5e-02 0:06.8\n",
      "  175   2100 3.698959605436000e+02 6.2e+00 1.56e-02  8e-03  2e-02 0:11.8\n",
      "  200   2400 3.698368066989854e+02 7.1e+00 1.49e-02  7e-03  2e-02 0:13.4\n",
      "  300   3600 3.697993185265197e+02 1.2e+01 1.68e-02  7e-03  2e-02 0:20.2\n",
      "  400   4800 3.696491512125918e+02 1.2e+01 2.91e-02  1e-02  4e-02 0:26.9\n",
      "  500   6000 3.696210028037321e+02 1.7e+01 2.60e-02  7e-03  4e-02 0:33.5\n",
      "  600   7200 3.697838635170694e+02 2.5e+01 8.63e-03  3e-03  1e-02 0:40.2\n",
      "  700   8400 3.697881709193089e+02 3.0e+01 7.05e-03  2e-03  8e-03 0:46.9\n",
      "  800   9600 3.697530900601794e+02 4.0e+01 7.50e-03  2e-03  8e-03 0:53.6\n",
      "  900  10800 3.696887047527095e+02 5.9e+01 1.02e-02  3e-03  1e-02 1:00.4\n",
      " 1000  12000 3.697589610425783e+02 1.1e+02 6.10e-03  2e-03  9e-03 1:07.0\n",
      "Iterat #Fevals   function value  axis ratio  sigma  min&max std  t[m:s]\n",
      " 1100  13200 3.697078970062637e+02 1.4e+02 5.17e-03  1e-03  9e-03 1:13.7\n",
      " 1200  14400 3.696696455564439e+02 1.9e+02 1.96e-03  3e-04  3e-03 1:20.4\n",
      " 1300  15600 3.697238097930502e+02 2.9e+02 3.81e-03  6e-04  6e-03 1:27.4\n",
      "Absolute diff in A:\n",
      "[[0.19119191 0.        ]\n",
      " [0.55200942 0.        ]\n",
      " [0.         1.64351644]\n",
      " [0.45186798 0.22034579]\n",
      " [0.84466137 0.22705548]\n",
      " [0.         0.94786368]]\n",
      "Absolute diff in delta:\n",
      "[0.14181989 0.03481082 0.36320576 0.11629737 0.73161167 0.19725181]\n",
      "Absolute diff in sigma:\n",
      "[[0.         0.11044882]\n",
      " [0.11044882 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "performance_dict = mirt_performance_benchmark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "##### Results for Monte Cralo with fixed sample per em-step\n",
      "Latent dimension: 2,  Item dimension: 6, sample size 100 \\\n",
      "Runtime: 0.95 seconds, 4 steps, 0.24 seconds per step \\\n",
      "Optimal marginal Likelihood: -374.12, Estimated: -373.06, Initial -376.52\n",
      "|               |   rmse_A |   rmse_delta |   rmse_sigma |\n",
      "|:--------------|---------:|-------------:|-------------:|\n",
      "| estimated     | 0.353817 |     0.160447 |    0.139736  |\n",
      "| early_initial | 0.509902 |     0.270563 |    0.141421  |\n",
      "| girth         | 1.77332  |     0.587414 |    0.141421  |\n",
      "| early_direct  | 0.64282  |     0.35141  |    0.0780991 |\n"
     ]
    }
   ],
   "source": [
    "print_result(performance_dict, \"Monte Cralo with fixed sample per em-step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------\n",
    "##### Results for Naive, all-Genetic, no vectorization\n",
    "Runtime: 29100 seconds, 100+ steps, 291 seconds per step\\\n",
    "Performance: rmse-mean = 0.5896464054719196\n",
    "\n",
    "------------------------------------\n",
    "##### Results for Vectorized q_item\n",
    "Runtime: 613.3871161937714 seconds, 100+ steps, 6.0731397642947655 seconds per step \\\n",
    "Performance: rmse-mean = 0.6466789259215839\n",
    "\n",
    "------------------------------------\n",
    "##### Results for More precise results through higher N and pop_size\n",
    "Runtime: 2239.073846578598 seconds, 100+ steps, 22.169047985926714 seconds per step \\\n",
    "Performance: rmse-mean = 0.6384660709857508\n",
    "\n",
    "------------------------------------\n",
    "##### Results for Debug GA sorting, Add Likelihood-based stopping criterion\n",
    "Runtime: 135.11203932762146 seconds, 7 steps, 19.301719903945923 seconds per step \\\n",
    "Performance: rmse-mean = 0.5616448369465917\n",
    "\n",
    "------------------------------------\n",
    "##### Results for Add vectorization in Q_0\n",
    "Runtime: 228.78 seconds, 17 steps, 13.46 seconds per step \\\n",
    "Performance: rmse-mean = 0.6174\n",
    "\n",
    "------------------------------------\n",
    "##### Results for Add vectorization in E-Step normalizing constant\n",
    "Runtime: 28.37 seconds, 9 steps, 3.15 seconds per step \\\n",
    "Performance: rmse-mean = 0.5808\n",
    "\n",
    "------------------------------------\n",
    "##### Results for Add Suggested Initial Parameters (Zhang)\n",
    "Runtime: 61.22 seconds, 19 steps, 3.22 seconds per step \\\n",
    "Performance: rmse-mean = 0.5625\n",
    "\n",
    "------------------------------------\n",
    "##### Results for Fixed Q_item\n",
    "Runtime: 81.11 seconds, 12 steps, 6.76 seconds per step \\\n",
    "Optimal marginal Likelihood: -375.43, Estimated: -393.8, Initial -391.83\n",
    "|           |   rmse_A |   rmse_delta |   rmse_sigma |\n",
    "|:----------|---------:|-------------:|-------------:|\n",
    "| Estimated | 0.762005 |     0.512703 |     0.600404 |\n",
    "| Girth     | 1.61804  |     0.750525 |   nan        |\n",
    "| Initial   | 0.770281 |     0.227528 |     0.141421 |\n",
    "\n",
    "------------------------------------\n",
    "##### Results for Inproved GA stoppimg rule\n",
    "Runtime: 42.54 seconds, 7 steps, 6.08 seconds per step \\\n",
    "Optimal marginal Likelihood: -378.68, Estimated: -391.87, Initial -378.08\n",
    "|           |   rmse_A |   rmse_delta |   rmse_sigma |\n",
    "|:----------|---------:|-------------:|-------------:|\n",
    "| Estimated | 0.845078 |     0.568092 |    0.167374  |\n",
    "| Girth     | 0.930362 |     0.554795 |    0.141421  |\n",
    "| direct    | 0.401578 |     0.609516 |    0.0526782 |\n",
    "| Initial   | 0.509902 |     0.364352 |    0.141421  |\n",
    "\n",
    "------------------------------------\n",
    "##### Results for pycma ga used\n",
    "Runtime: 489.8 seconds, 16 steps, 30.61 seconds per step \\\n",
    "Optimal marginal Likelihood: -381.34, Estimated: -414.28, Initial -379.77\n",
    "|           |   rmse_A |   rmse_delta |   rmse_sigma |\n",
    "|:----------|---------:|-------------:|-------------:|\n",
    "| Estimated | 0.942127 |     0.505808 |     0.215139 |\n",
    "| Girth     | 1.42144  |     0.632431 |   nan        |\n",
    "| Initial   | 0.509902 |     0.489947 |     0.141421 |\n",
    "\n",
    "------------------------------------\n",
    "##### Results for pycma, higher sigma0\n",
    "Runtime: 282.36 seconds, 10 steps, 28.24 seconds per step \\\n",
    "Optimal marginal Likelihood: -368.93, Estimated: -399.56, Initial -369.53\n",
    "|           |   rmse_A |   rmse_delta |   rmse_sigma |\n",
    "|:----------|---------:|-------------:|-------------:|\n",
    "| Estimated | 0.898735 |     0.48221  |     0.195257 |\n",
    "| Girth     | 1.79316  |     0.515695 |   nan        |\n",
    "| direct    | 0.458306 |     0.262779 |     0.139413 |\n",
    "| Initial   | 0.509902 |     0.273981 |     0.141421 |\n",
    "\n",
    "------------------------------------\n",
    "##### Results for Monte Carlo with seed\n",
    "Runtime: 97.6 seconds, 9 steps, 10.84 seconds per step \\\n",
    "Optimal marginal Likelihood: -376.79, Estimated: -399.07, Initial -372.28\n",
    "|           |      rmse_A |   rmse_delta |   rmse_sigma |\n",
    "|:----------|------------:|-------------:|-------------:|\n",
    "| Estimated |    1.09615  |     0.970204 |     0.120425 |\n",
    "| Girth     |    1.45372  |     0.34729  |     0.141421 |\n",
    "| direct    | 2935.78     |  1035.68     |     0.014461 |\n",
    "| Initial   |    0.509902 |     0.445143 |     0.141421 |\n",
    "\n",
    "------------------------------------\n",
    "##### Results for Monte Cralo with fixed sample per em-step\n",
    "Runtime: 1.22 seconds, 5 steps, 0.24 seconds per step \\\n",
    "Optimal marginal Likelihood: -381.06, Estimated: -373.26, Initial -377.69\n",
    "|           |   rmse_A |   rmse_delta |   rmse_sigma |\n",
    "|:----------|---------:|-------------:|-------------:|\n",
    "| Estimated | 0.500043 |     0.273166 |    0.0853068 |\n",
    "| Girth     | 0.98542  |     0.334766 |    0.141421  |\n",
    "| direct    | 0.57518  |     0.335156 |    0.0914744 |\n",
    "| Initial   | 0.509902 |     0.431741 |    0.141421  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procedure for better runtime\n",
    "\n",
    "1. Add Performance Benchmark (done)\n",
    "2. Add Vectorization to q_item (done)\n",
    "3. Add better Initialization (done)\n",
    "3. Add Vectorization to q_0 (done)\n",
    "4. Add q_0 Derivation 1. + BFGS\n",
    "5. Add q_0 Derivation 2. + Newton Raphson\n",
    "6. Use cython (maybe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1: MIRT-2PL Parameter Recovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unittest import result\n",
    "\n",
    "\n",
    "def mirt_param_recovery(sample_size, item_dimension = 20, latent_dimension=3, q_type=\"seperated\", girth=True) -> dict:\n",
    "    \n",
    "    #Define Population\n",
    "    population = respondent_population(latent_dimension=latent_dimension)\n",
    "    real_latent_cov = population.initialize_random_person_parameters()\n",
    "\n",
    "    #Sample responses\n",
    "    response_simulation_obj = response_simulation(population=population, item_dimension=item_dimension)\n",
    "    response_simulation_obj.initialize_random_q_structured_matrix(structure=q_type)\n",
    "    early_item_parameters = response_simulation_obj.initialize_random_item_parameters()\n",
    "    early_item_parameters.update({\"item_dimension\": item_dimension, \"latent_dimension\": latent_dimension})\n",
    "    sample = response_simulation_obj.sample(sample_size=sample_size)\n",
    "    real_early_parameters = {\"item_parameters\": early_item_parameters, \"person_parameters\": {\"covariance\": real_latent_cov}}\n",
    "\n",
    "    #Fit Parameters\n",
    "    #Initialize model\n",
    "    model = models.mirt_2pl(latent_dimension=latent_dimension, item_dimension=item_dimension, Q=early_item_parameters[\"q_matrix\"])\n",
    "    model.initialize_from_responses(response_data=sample[\"early_responses\"])\n",
    "    initial_early_parameters = model.get_parameters()\n",
    "    e_step = em_algorithm.e_step_ga_mml(model=model)\n",
    "    m_step = em_algorithm.m_step_ga_mml(model)\n",
    "    em = em_algorithm.em_algo(e_step=e_step, m_step=m_step, model=model)\n",
    "\n",
    "    #Fit Model\n",
    "    start_time = time.time()\n",
    "    em.fit(sample[\"early_responses\"], max_iter=100)\n",
    "    run_time =  (time.time() - start_time)\n",
    "\n",
    "    #Measure Performance\n",
    "    early_estimated_item_parameters = em.model.item_parameters\n",
    "    early_estimated_person_parameters = em.model.person_parameters\n",
    "\n",
    "    #Create Baselines\n",
    "    baselines = {\"early_initial\": {\"parameters\": initial_early_parameters}}\n",
    "    if girth==True:\n",
    "        baselines[\"girth\"] = {}\n",
    "\n",
    "    #Create results\n",
    "    early_estimated_parameters = em.model.get_parameters()\n",
    "\n",
    "    parameter_dict = create_parameter_dict(estimated_early_parameters=early_estimated_parameters,\n",
    "                          real_early_parameters = real_early_parameters,\n",
    "                          estimated_late_parameters=None, real_late_parameters=None)\n",
    "    run_dict = {\"early\": {\"runtime\": run_time,\n",
    "                \"number_steps\": em.n_steps}}\n",
    "    performance_dict = create_performance_dict(parameter_dict=parameter_dict, run_dict=run_dict, sample=sample, baselines=baselines, model=model)\n",
    "\n",
    "    return(performance_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Univariate IRT Recovery\n",
    "#result_dict = mirt_param_recovery(1000, q_type=\"singular\", item_dimension=20, latent_dimension=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print_result(result_dict, \"Fixed sample per em-step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate IRT/Full GA\n",
    "\n",
    "------------------------------------\n",
    "##### Item Dimension=12, sample_size=200: Results for Fixed sample per em-step\n",
    "Runtime: 4.38 seconds, 7 steps, 0.63 seconds per step \\\n",
    "Optimal marginal Likelihood: -1284.1, Estimated: -1273.09, Initial -1330.43\n",
    "|           |   rmse_A |   rmse_delta |   rmse_sigma |\n",
    "|:----------|---------:|-------------:|-------------:|\n",
    "| Estimated | 0.508687 |     0.196944 |            0 |\n",
    "| Girth     | 0.377882 |     2.65875  |            0 |\n",
    "| direct    | 0.305489 |     0.318168 |            0 |\n",
    "| Initial   | 1.5583   |     0.861273 |            0 |\n",
    "\n",
    "------------------------------------\n",
    "##### Item Dimension=20, sample_size=1000: Results for Fixed sample per em-step\n",
    "Runtime: 85.11 seconds, 19 steps, 4.48 seconds per step \\\n",
    "Optimal marginal Likelihood: -9199.01, Estimated: -9183.03, Initial -9784.69\n",
    "|           |   rmse_A |   rmse_delta |   rmse_sigma |\n",
    "|:----------|---------:|-------------:|-------------:|\n",
    "| Estimated | 0.352003 |     0.578688 |            0 |\n",
    "| Girth     | 0.468473 |     4.98511  |            0 |\n",
    "| Initial   | 1.66615  |     2.01114  |            0 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EM Iteration 1\n",
      "E-step\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Jesper\\Documents\\GitHub\\Knowledge-Growth-Prediction\\simulation_experiments.ipynb Zelle 18\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Jesper/Documents/GitHub/Knowledge-Growth-Prediction/simulation_experiments.ipynb#X30sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m performance_dict \u001b[39m=\u001b[39m mirt_param_recovery(sample_size\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m, item_dimension\u001b[39m=\u001b[39;49m\u001b[39m30\u001b[39;49m, latent_dimension\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, q_type\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mseperated\u001b[39;49m\u001b[39m\"\u001b[39;49m, girth\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "\u001b[1;32mc:\\Users\\Jesper\\Documents\\GitHub\\Knowledge-Growth-Prediction\\simulation_experiments.ipynb Zelle 18\u001b[0m in \u001b[0;36mmirt_param_recovery\u001b[1;34m(sample_size, item_dimension, latent_dimension, q_type, girth)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Jesper/Documents/GitHub/Knowledge-Growth-Prediction/simulation_experiments.ipynb#X30sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m#Fit Model\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Jesper/Documents/GitHub/Knowledge-Growth-Prediction/simulation_experiments.ipynb#X30sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Jesper/Documents/GitHub/Knowledge-Growth-Prediction/simulation_experiments.ipynb#X30sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m em\u001b[39m.\u001b[39;49mfit(sample[\u001b[39m\"\u001b[39;49m\u001b[39mearly_responses\u001b[39;49m\u001b[39m\"\u001b[39;49m], max_iter\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Jesper/Documents/GitHub/Knowledge-Growth-Prediction/simulation_experiments.ipynb#X30sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m run_time \u001b[39m=\u001b[39m  (time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Jesper/Documents/GitHub/Knowledge-Growth-Prediction/simulation_experiments.ipynb#X30sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39m#Measure Performance\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jesper\\Documents\\GitHub\\Knowledge-Growth-Prediction\\em_algorithm\\em_algorithm.py:42\u001b[0m, in \u001b[0;36mem_algorithm.fit\u001b[1;34m(self, data, hyper_params, max_iter)\u001b[0m\n\u001b[0;32m     40\u001b[0m last_step_marginal_loglikelihood \u001b[39m=\u001b[39m marginal_loglikelihood\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m     41\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mE-step\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 42\u001b[0m posterior_expectation \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49me_step\u001b[39m.\u001b[39;49mstep(response_data\u001b[39m=\u001b[39;49mdata)\n\u001b[0;32m     43\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mM-step\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     44\u001b[0m current_parameters, log_likelihood \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mm_step\u001b[39m.\u001b[39mstep(\n\u001b[0;32m     45\u001b[0m     pe_functions\u001b[39m=\u001b[39mposterior_expectation)\n",
      "File \u001b[1;32mc:\\Users\\Jesper\\Documents\\GitHub\\Knowledge-Growth-Prediction\\em_algorithm\\e_step_mirt_2pl.py:103\u001b[0m, in \u001b[0;36me_step_ga_mml.step\u001b[1;34m(self, response_data, current_item_parameters, current_person_parameters, N)\u001b[0m\n\u001b[0;32m    101\u001b[0m theta_sample \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39msample_competency(sample_size\u001b[39m=\u001b[39mN)\n\u001b[0;32m    102\u001b[0m r_0_theta \u001b[39m=\u001b[39m r_0(theta_sample)\n\u001b[1;32m--> 103\u001b[0m r_item_theta_list \u001b[39m=\u001b[39m [r_item(item, theta_sample)\n\u001b[0;32m    104\u001b[0m                      \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, J)]\n\u001b[0;32m    106\u001b[0m q_0 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mq_0(\n\u001b[0;32m    107\u001b[0m     theta\u001b[39m=\u001b[39mtheta_sample, normalising_constant_array\u001b[39m=\u001b[39mnormalising_constant_array, response_data\u001b[39m=\u001b[39mresponse_data)\n\u001b[0;32m    108\u001b[0m q_item_list \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mq_item(item\u001b[39m=\u001b[39mj, theta\u001b[39m=\u001b[39mtheta_sample, r_0_theta\u001b[39m=\u001b[39mr_0_theta,\n\u001b[0;32m    109\u001b[0m                            r_item_theta\u001b[39m=\u001b[39mr_item_theta_list[j]) \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, J)]\n",
      "File \u001b[1;32mc:\\Users\\Jesper\\Documents\\GitHub\\Knowledge-Growth-Prediction\\em_algorithm\\e_step_mirt_2pl.py:103\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    101\u001b[0m theta_sample \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39msample_competency(sample_size\u001b[39m=\u001b[39mN)\n\u001b[0;32m    102\u001b[0m r_0_theta \u001b[39m=\u001b[39m r_0(theta_sample)\n\u001b[1;32m--> 103\u001b[0m r_item_theta_list \u001b[39m=\u001b[39m [r_item(item, theta_sample)\n\u001b[0;32m    104\u001b[0m                      \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, J)]\n\u001b[0;32m    106\u001b[0m q_0 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mq_0(\n\u001b[0;32m    107\u001b[0m     theta\u001b[39m=\u001b[39mtheta_sample, normalising_constant_array\u001b[39m=\u001b[39mnormalising_constant_array, response_data\u001b[39m=\u001b[39mresponse_data)\n\u001b[0;32m    108\u001b[0m q_item_list \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mq_item(item\u001b[39m=\u001b[39mj, theta\u001b[39m=\u001b[39mtheta_sample, r_0_theta\u001b[39m=\u001b[39mr_0_theta,\n\u001b[0;32m    109\u001b[0m                            r_item_theta\u001b[39m=\u001b[39mr_item_theta_list[j]) \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, J)]\n",
      "File \u001b[1;32mc:\\Users\\Jesper\\Documents\\GitHub\\Knowledge-Growth-Prediction\\em_algorithm\\e_step_mirt_2pl.py:65\u001b[0m, in \u001b[0;36me_step_ga_mml.step.<locals>.r_item\u001b[1;34m(item, theta)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mr_item\u001b[39m(item: \u001b[39mint\u001b[39m, theta: np\u001b[39m.\u001b[39marray):\n\u001b[1;32m---> 65\u001b[0m     numerator \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mresponse_matrix_probability(\n\u001b[0;32m     66\u001b[0m         theta\u001b[39m=\u001b[39;49mtheta, response_matrix\u001b[39m=\u001b[39;49mresponse_data\u001b[39m.\u001b[39;49mto_numpy()))\n\u001b[0;32m     67\u001b[0m     \u001b[39m# This coefficient is different to r_0\u001b[39;00m\n\u001b[0;32m     68\u001b[0m     numerator \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmultiply(\n\u001b[0;32m     69\u001b[0m         numerator, response_data\u001b[39m.\u001b[39miloc[:, item]\u001b[39m.\u001b[39mto_numpy()\u001b[39m.\u001b[39mtranspose())\n",
      "File \u001b[1;32mc:\\Users\\Jesper\\Documents\\GitHub\\Knowledge-Growth-Prediction\\models\\mirt_2pl.py:140\u001b[0m, in \u001b[0;36mresponse_matrix_probability\u001b[1;34m(self, theta, response_matrix, A, delta)\u001b[0m\n\u001b[0;32m    136\u001b[0m correct_response_probabilities \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39micc(\n\u001b[0;32m    137\u001b[0m     theta, A, delta)\n\u001b[0;32m    138\u001b[0m \u001b[39m# We want to apply each response vector to each competency-induced correct-response-probability\u001b[39;00m\n\u001b[0;32m    139\u001b[0m correct_response_probabilities \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mexpand_dims(\n\u001b[1;32m--> 140\u001b[0m     correct_response_probabilities, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m    141\u001b[0m probability_vector \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39madd(np\u001b[39m.\u001b[39mmultiply(correct_response_probabilities, response_matrix),\n\u001b[0;32m    142\u001b[0m                             np\u001b[39m.\u001b[39mmultiply(np\u001b[39m.\u001b[39msubtract(\u001b[39m1\u001b[39m, correct_response_probabilities), np\u001b[39m.\u001b[39msubtract(\u001b[39m1\u001b[39m, response_matrix)))\n\u001b[0;32m    143\u001b[0m probability \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mprod(probability_vector, axis\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "performance_dict = mirt_param_recovery(sample_size=1000, item_dimension=20, latent_dimension=2, q_type=\"seperated\", girth=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "##### Results for Seperated Q-Matrix\n",
      "Latent dimension: 3,  Item dimension: 20, sample size 1000 \\\n",
      "Runtime: 313.22 seconds, 51 steps, 6.14 seconds per step \\\n",
      "Optimal marginal Likelihood: -9452.24, Estimated: -9813.87, Initial -11216.48\n",
      "|               |   rmse_A |   rmse_delta |   rmse_sigma |\n",
      "|:--------------|---------:|-------------:|-------------:|\n",
      "| estimated     |  5.34115 |      1.4068  |     0.425982 |\n",
      "| early_initial |  5.98238 |      2.25109 |     0.234288 |\n"
     ]
    }
   ],
   "source": [
    "print_result(performance_dict, \"Seperated Q-Matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------\n",
    "##### Results for Seperated Q-Matrix\n",
    "Latent dimension: 2,  Item dimension: 20, sample size 1000 \\\n",
    "Runtime: 142.07 seconds, 26 steps, 5.46 seconds per step \\\n",
    "Optimal marginal Likelihood: -9384.38, Estimated: -10189.47, Initial -11459.9\n",
    "|               |   rmse_A |   rmse_delta |   rmse_sigma |\n",
    "|:--------------|---------:|-------------:|-------------:|\n",
    "| estimated     |  4.00013 |      3.10678 |    0.0201383 |\n",
    "| early_initial |  4.5183  |      2.5846  |    0.165491  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EM Iteration 1\n",
      "E-step\n",
      "M-step\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 1: current parameter_diff: 23.12312711436075, current marginal loglikelihood: -35761.39247710205\n",
      "EM Iteration 2\n",
      "E-step\n",
      "M-step\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 2: current parameter_diff: 15.045925135773842, current marginal loglikelihood: -34991.455427700406\n",
      "EM Iteration 3\n",
      "E-step\n",
      "M-step\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 3: current parameter_diff: 6.5781986369907965, current marginal loglikelihood: -34724.07681260245\n",
      "EM Iteration 4\n",
      "E-step\n",
      "M-step\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 4: current parameter_diff: 7.391088602508791, current marginal loglikelihood: -34427.36549908407\n",
      "EM Iteration 5\n",
      "E-step\n",
      "M-step\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 5: current parameter_diff: 7.140970376816044, current marginal loglikelihood: -34210.502106857006\n",
      "EM Iteration 6\n",
      "E-step\n",
      "M-step\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 6: current parameter_diff: 9.815207981887937, current marginal loglikelihood: -33756.88410585955\n",
      "EM Iteration 7\n",
      "E-step\n",
      "M-step\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 7: current parameter_diff: 7.8336992165726445, current marginal loglikelihood: -33420.538627999646\n",
      "EM Iteration 8\n",
      "E-step\n",
      "M-step\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 8: current parameter_diff: 6.719894371999371, current marginal loglikelihood: -33304.543044255006\n",
      "EM Iteration 9\n",
      "E-step\n",
      "M-step\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 9: current parameter_diff: 8.57810739300545, current marginal loglikelihood: -33021.14472311552\n",
      "EM Iteration 10\n",
      "E-step\n",
      "M-step\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 10: current parameter_diff: 7.428574452551608, current marginal loglikelihood: -32742.543118937978\n",
      "EM Iteration 11\n",
      "E-step\n",
      "M-step\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 11: current parameter_diff: 5.14373388560652, current marginal loglikelihood: -32673.2162506925\n",
      "EM Iteration 12\n",
      "E-step\n",
      "M-step\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 12: current parameter_diff: 1.8484660079608244, current marginal loglikelihood: -32652.598152049384\n",
      "EM Iteration 13\n",
      "E-step\n",
      "M-step\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 13: current parameter_diff: 2.35267340266186, current marginal loglikelihood: -32640.673531173394\n",
      "EM Iteration 14\n",
      "E-step\n",
      "M-step\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 14: current parameter_diff: 0.3542602947023293, current marginal loglikelihood: -32637.29107259937\n",
      "EM Iteration 15\n",
      "E-step\n",
      "M-step\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 15: current parameter_diff: 2.6595295794675535, current marginal loglikelihood: -32595.20892594723\n",
      "EM Iteration 16\n",
      "E-step\n",
      "M-step\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 16: current parameter_diff: 2.9766300108015438, current marginal loglikelihood: -32565.099702061118\n",
      "EM Iteration 17\n",
      "E-step\n",
      "M-step\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 17: current parameter_diff: 1.9871399662315916, current marginal loglikelihood: -32561.271464347177\n",
      "EM Iteration 18\n",
      "E-step\n",
      "M-step\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 18: current parameter_diff: 0.7001581662645731, current marginal loglikelihood: -32561.864933123972\n",
      "EM Iteration 19\n",
      "E-step\n",
      "M-step\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 19: current parameter_diff: 2.5873951700313547, current marginal loglikelihood: -32518.199787568796\n",
      "EM Iteration 20\n",
      "E-step\n",
      "M-step\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 20: current parameter_diff: 1.0095031755787536, current marginal loglikelihood: -32527.84132950064\n",
      "EM Iteration 21\n",
      "E-step\n",
      "M-step\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 21: current parameter_diff: 0.3154359357135447, current marginal loglikelihood: -32550.489197607145\n",
      "EM Iteration 22\n",
      "E-step\n",
      "M-step\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 22: current parameter_diff: 0.8492551356752592, current marginal loglikelihood: -32519.20522132404\n",
      "EM Iteration 23\n",
      "E-step\n",
      "M-step\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 23: current parameter_diff: 1.2680989921341785, current marginal loglikelihood: -32495.06725726371\n",
      "EM Iteration 24\n",
      "E-step\n",
      "M-step\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 24: current parameter_diff: 1.5905060970213594, current marginal loglikelihood: -32518.12865947679\n",
      "EM Iteration 25\n",
      "E-step\n",
      "M-step\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 25: current parameter_diff: 0.845500041977119, current marginal loglikelihood: -32491.07539006501\n",
      "EM Iteration 26\n",
      "E-step\n",
      "M-step\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 26: current parameter_diff: 0.1799085233178186, current marginal loglikelihood: -32499.926768366924\n",
      "EM Iteration 27\n",
      "E-step\n",
      "M-step\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 27: current parameter_diff: 1.332891418290103, current marginal loglikelihood: -32485.668692791798\n",
      "EM Iteration 28\n",
      "E-step\n",
      "M-step\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 28: current parameter_diff: 1.1306231094447012, current marginal loglikelihood: -32519.552994091835\n",
      "EM Iteration 29\n",
      "E-step\n",
      "M-step\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 29: current parameter_diff: 1.2600765106491816, current marginal loglikelihood: -32486.997556857285\n",
      "EM Iteration 30\n",
      "E-step\n",
      "M-step\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 30: current parameter_diff: 0.5761413325945861, current marginal loglikelihood: -32494.949743076635\n",
      "EM Iteration 31\n",
      "E-step\n",
      "M-step\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 31: current parameter_diff: 0.3214775718907621, current marginal loglikelihood: -32496.457984443936\n",
      "EM Iteration 32\n",
      "E-step\n",
      "M-step\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 32: current parameter_diff: 0.21814855081067774, current marginal loglikelihood: -32487.581139852206\n",
      "EM Iteration 33\n",
      "E-step\n",
      "M-step\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 33: current parameter_diff: 1.692334213966599, current marginal loglikelihood: -32514.4768071611\n",
      "EM Iteration 34\n",
      "E-step\n",
      "M-step\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 34: current parameter_diff: 0.326825871495244, current marginal loglikelihood: -32502.10474251602\n",
      "EM Iteration 35\n",
      "E-step\n",
      "M-step\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 35: current parameter_diff: 0.6450957226425195, current marginal loglikelihood: -32530.121081940706\n",
      "EM Iteration 36\n",
      "E-step\n",
      "M-step\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 36: current parameter_diff: 1.7957004636124012, current marginal loglikelihood: -32489.03931057883\n",
      "EM Iteration 37\n",
      "E-step\n",
      "M-step\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 37: current parameter_diff: 4.345828673359769, current marginal loglikelihood: -32458.349715901244\n",
      "EM Iteration 38\n",
      "E-step\n",
      "M-step\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 38: current parameter_diff: 1.097349964313147, current marginal loglikelihood: -32515.790499665596\n",
      "EM Iteration 39\n",
      "E-step\n",
      "M-step\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 39: current parameter_diff: 2.535294435756901, current marginal loglikelihood: -32475.44764404514\n",
      "EM Iteration 40\n",
      "E-step\n",
      "M-step\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 40: current parameter_diff: 0.12685383397242656, current marginal loglikelihood: -32473.40595600024\n",
      "EM Iteration 41\n",
      "E-step\n",
      "M-step\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 41: current parameter_diff: 0.4363385767364062, current marginal loglikelihood: -32485.816845898324\n",
      "EM Iteration 42\n",
      "E-step\n",
      "M-step\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 42: current parameter_diff: 2.5012692351181425, current marginal loglikelihood: -32506.764338065972\n",
      "EM Iteration 43\n",
      "E-step\n",
      "M-step\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 43: current parameter_diff: 4.616221744819617, current marginal loglikelihood: -32597.45663862176\n",
      "EM Iteration 44\n",
      "E-step\n",
      "M-step\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 44: current parameter_diff: 5.12122403412296, current marginal loglikelihood: -32519.812792939505\n",
      "EM Iteration 45\n",
      "E-step\n",
      "M-step\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 45: current parameter_diff: 1.8757513936359458, current marginal loglikelihood: -32484.58394776075\n",
      "EM Iteration 46\n",
      "E-step\n",
      "M-step\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 46: current parameter_diff: 3.1417143978562354, current marginal loglikelihood: -32520.1216966448\n",
      "EM Iteration 47\n",
      "E-step\n",
      "M-step\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 47: current parameter_diff: 4.469237255410547, current marginal loglikelihood: -32543.422652345496\n",
      "EM Iteration 48\n",
      "E-step\n",
      "M-step\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 48: current parameter_diff: 4.442150823437718, current marginal loglikelihood: -32627.97801761298\n",
      "EM Iteration 49\n",
      "E-step\n",
      "M-step\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 49: current parameter_diff: 5.242816862673449, current marginal loglikelihood: -32517.609396988322\n",
      "EM Iteration 50\n",
      "E-step\n",
      "M-step\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 50: current parameter_diff: 3.975760233140745, current marginal loglikelihood: -32538.385712730982\n",
      "EM Iteration 51\n",
      "E-step\n",
      "M-step\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 51: current parameter_diff: 3.7568757238028594, current marginal loglikelihood: -32505.057906175512\n",
      "EM Iteration 52\n",
      "E-step\n",
      "M-step\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 52: current parameter_diff: 7.448137499530432, current marginal loglikelihood: -32511.04321384616\n",
      "EM Iteration 53\n",
      "E-step\n",
      "M-step\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 53: current parameter_diff: 3.7539680926434267, current marginal loglikelihood: -32513.232987971016\n",
      "EM Iteration 54\n",
      "E-step\n",
      "M-step\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 54: current parameter_diff: 7.110471572698492, current marginal loglikelihood: -32641.22309338503\n",
      "EM Iteration 55\n",
      "E-step\n",
      "M-step\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 55: current parameter_diff: 4.404063959193019, current marginal loglikelihood: -32580.05391418221\n",
      "EM Iteration 56\n",
      "E-step\n",
      "M-step\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 56: current parameter_diff: 6.044663854618015, current marginal loglikelihood: -32552.645642557367\n",
      "EM Iteration 57\n",
      "E-step\n",
      "M-step\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 57: current parameter_diff: 3.141179871644436, current marginal loglikelihood: -32604.31523684664\n",
      "EM Iteration 58\n",
      "E-step\n",
      "M-step\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 58: current parameter_diff: 4.072627833958606, current marginal loglikelihood: -32610.442351636782\n",
      "EM Iteration 59\n",
      "E-step\n",
      "M-step\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 59: current parameter_diff: 6.702888478504309, current marginal loglikelihood: -32519.46923260184\n",
      "EM Iteration 60\n",
      "E-step\n",
      "M-step\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 60: current parameter_diff: 2.707393733197047, current marginal loglikelihood: -32620.006687223366\n",
      "EM Iteration 61\n",
      "E-step\n",
      "M-step\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 61: current parameter_diff: 5.35454086436774, current marginal loglikelihood: -32643.84436430155\n",
      "EM Iteration 62\n",
      "E-step\n",
      "M-step\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 62: current parameter_diff: 6.119602141234538, current marginal loglikelihood: -32619.226600238395\n",
      "EM Iteration 63\n",
      "E-step\n",
      "M-step\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 63: current parameter_diff: 4.50849912072912, current marginal loglikelihood: -32569.14306431033\n",
      "EM Iteration 64\n",
      "E-step\n",
      "M-step\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 64: current parameter_diff: 5.594345729150428, current marginal loglikelihood: -32550.39806826072\n",
      "EM Iteration 65\n",
      "E-step\n",
      "M-step\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 65: current parameter_diff: 6.927576259582269, current marginal loglikelihood: -32526.33626839148\n",
      "EM Iteration 66\n",
      "E-step\n",
      "M-step\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 66: current parameter_diff: 2.0708937796622697, current marginal loglikelihood: -32517.062880313006\n",
      "EM Iteration 67\n",
      "E-step\n",
      "M-step\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 67: current parameter_diff: 4.44216302397928, current marginal loglikelihood: -32474.399092912256\n",
      "EM Iteration 68\n",
      "E-step\n",
      "M-step\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 68: current parameter_diff: 4.635953728922426, current marginal loglikelihood: -32457.080482671583\n",
      "EM Iteration 69\n",
      "E-step\n",
      "M-step\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 69: current parameter_diff: 5.010834674760441, current marginal loglikelihood: -32397.89796001955\n",
      "EM Iteration 70\n",
      "E-step\n",
      "M-step\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 70: current parameter_diff: 4.578697636505466, current marginal loglikelihood: -32500.188694510412\n",
      "EM Iteration 71\n",
      "E-step\n",
      "M-step\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 71: current parameter_diff: 2.3319633067200627, current marginal loglikelihood: -32515.74252008349\n",
      "EM Iteration 72\n",
      "E-step\n",
      "M-step\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 72: current parameter_diff: 2.829032106225415, current marginal loglikelihood: -32504.373312874814\n",
      "EM Iteration 73\n",
      "E-step\n",
      "M-step\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 73: current parameter_diff: 4.393228840535191, current marginal loglikelihood: -32547.741224042522\n",
      "EM Iteration 74\n",
      "E-step\n",
      "M-step\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 74: current parameter_diff: 2.542306618513379, current marginal loglikelihood: -32528.255395945336\n",
      "EM Iteration 75\n",
      "E-step\n",
      "M-step\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 75: current parameter_diff: 5.304572934445959, current marginal loglikelihood: -32528.15231583498\n",
      "Absolute diff in A:\n",
      "[[ 0.09274077  0.          0.        ]\n",
      " [ 1.10533059  0.          0.        ]\n",
      " [ 0.04142226  0.          0.        ]\n",
      " [ 4.61862604  0.          0.        ]\n",
      " [ 3.97355105  0.          0.        ]\n",
      " [ 0.14849928  0.          0.        ]\n",
      " [ 0.27740759  0.          0.        ]\n",
      " [ 0.08970068  0.10223493  0.        ]\n",
      " [ 0.04123753  0.10996824  0.        ]\n",
      " [ 0.35039632  0.67286932  0.        ]\n",
      " [ 0.30172154  0.08561342  0.        ]\n",
      " [ 0.24737286  0.64818633  0.        ]\n",
      " [ 1.09922105  6.320782    0.        ]\n",
      " [ 0.02637198  0.16098765  0.        ]\n",
      " [ 0.10615225  0.3089424   0.        ]\n",
      " [ 0.04442895  0.29588257  0.        ]\n",
      " [ 2.03663926  3.0200158   0.        ]\n",
      " [ 0.30707358  0.93767294  0.37728945]\n",
      " [ 0.1687838   0.38062727  0.15140001]\n",
      " [ 1.7404426   5.37445917  1.59963056]\n",
      " [ 3.86409821 13.68941867  2.32182075]\n",
      " [ 0.14859609  4.29367559  2.10987647]\n",
      " [ 0.20673204  0.28449607  0.77118168]\n",
      " [ 0.58747991  0.34029048  0.75314171]\n",
      " [ 0.0961965   0.11805213  0.13990336]\n",
      " [ 0.52088653  0.91498238  0.22711974]\n",
      " [ 0.50120541  5.45420813  0.49613795]\n",
      " [ 3.32078978  6.6432205   2.55327764]\n",
      " [ 0.53112057  1.65272678  0.33494136]\n",
      " [ 1.20249885  3.99119614 10.65610292]]\n",
      "Absolute diff in delta:\n",
      "[1.40719978e-01 5.40628736e-01 2.19441129e-02 4.38478294e+00\n",
      " 1.84614683e+00 8.40821379e-02 1.44604987e-01 1.71507720e-02\n",
      " 3.44569481e-02 5.54843554e-02 9.42558181e-02 1.22142112e-02\n",
      " 4.62603684e+00 5.72315683e-02 2.75917826e-02 6.13972040e-03\n",
      " 2.21158399e-01 6.47344263e-03 3.53089979e-02 2.07007848e+00\n",
      " 8.33155955e+00 1.00962002e+00 1.66767941e-01 3.52403347e-01\n",
      " 3.48162945e-02 3.98460152e-02 3.00079641e-02 2.02825694e-01\n",
      " 2.19199265e-01 1.28925636e-01]\n",
      "Absolute diff in sigma:\n",
      "[[0.         0.44904102 0.04850803]\n",
      " [0.44904102 0.         0.49053808]\n",
      " [0.04850803 0.49053808 0.        ]]\n",
      "Absolute diff in A:\n",
      "[[ 0.26565217  0.          0.        ]\n",
      " [ 1.6173707   0.          0.        ]\n",
      " [ 0.68988183  0.          0.        ]\n",
      " [ 5.61763356  0.          0.        ]\n",
      " [ 4.96946027  0.          0.        ]\n",
      " [ 0.3974077   0.          0.        ]\n",
      " [ 0.02949938  0.          0.        ]\n",
      " [ 0.77594515  1.02636323  0.        ]\n",
      " [ 0.60023156  0.47841595  0.        ]\n",
      " [ 0.02176182  0.80283002  0.        ]\n",
      " [ 1.27247547  0.19029374  0.        ]\n",
      " [ 0.34719434  1.64529108  0.        ]\n",
      " [ 3.03473418  7.31857558  0.        ]\n",
      " [ 0.86600299  0.17655404  0.        ]\n",
      " [ 0.45622381  0.54488719  0.        ]\n",
      " [ 0.66839247  1.26447176  0.        ]\n",
      " [ 2.57653632  0.72602026  0.        ]\n",
      " [ 0.61903608  1.93254292  0.83148856]\n",
      " [ 0.839114    0.85578776  0.75684932]\n",
      " [ 2.91456681 12.97452416  2.53308138]\n",
      " [ 6.64393524 13.85236144  4.44644843]\n",
      " [ 0.66341407  5.28294884  2.77408248]\n",
      " [ 0.17303302  0.29151987  1.75962834]\n",
      " [ 1.58279614  2.16435176  1.71560632]\n",
      " [ 0.93331793  0.97420687  1.10506588]\n",
      " [ 0.55501189  1.15283166  0.22711974]\n",
      " [ 6.65800717  0.54276766  1.95393582]\n",
      " [ 0.46450408  3.39786484  5.26756585]\n",
      " [ 0.99719278  0.06991898  0.16006505]\n",
      " [ 0.08546224  0.65202501 16.20514458]]\n",
      "Absolute diff in delta:\n",
      "[7.90530000e-01 1.22200466e+00 9.25188695e-03 4.37211730e+00\n",
      " 1.89938366e+00 4.91719537e-02 1.79853397e-02 1.24372209e-02\n",
      " 1.71713658e-02 1.13525380e-01 6.44942451e-02 1.82681350e-01\n",
      " 6.81882729e+00 1.00133987e-01 1.72676055e-01 9.10712312e-02\n",
      " 1.66858501e-01 6.73877972e-02 7.27689823e-03 3.01416985e+00\n",
      " 1.68091064e+01 1.29392622e+00 3.52050909e-01 4.33449558e-01\n",
      " 7.08833401e-03 3.98460152e-02 1.38125385e+00 1.68329995e+00\n",
      " 6.91218406e-01 3.69536333e-01]\n",
      "Absolute diff in sigma:\n",
      "[[0.         0.         0.        ]\n",
      " [0.         0.         0.05081872]\n",
      " [0.         0.05081872 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "performance_dict = mirt_param_recovery(sample_size=2000, item_dimension=30, latent_dimension=3, q_type=\"pyramid\", girth=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "##### Results for Pyramid Q-Matrix\n",
      "Latent dimension: 3,  Item dimension: 30, sample size 2000 \\\n",
      "Runtime: 1521.51 seconds, 76 steps, 20.02 seconds per step \\\n",
      "Optimal marginal Likelihood: -30844.13, Estimated: -32521.34, Initial -37390.6\n",
      "|               |   rmse_A |   rmse_delta |   rmse_sigma |\n",
      "|:--------------|---------:|-------------:|-------------:|\n",
      "| estimated     |  2.55959 |       1.9952 |    0.314331  |\n",
      "| early_initial |  3.32034 |       3.514  |    0.0239562 |\n"
     ]
    }
   ],
   "source": [
    "print_result(performance_dict, \"Pyramid Q-Matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------\n",
    "##### Results for Pyramid Q-Matrix\n",
    "Latent dimension: 3,  Item dimension: 20, sample size 200 \\\n",
    "Runtime: 121.22 seconds, 46 steps, 2.64 seconds per step \\\n",
    "Optimal marginal Likelihood: -2144.15, Estimated: -2155.08, Initial -2699.63\n",
    "|               |   rmse_A |   rmse_delta |   rmse_sigma |\n",
    "|:--------------|---------:|-------------:|-------------:|\n",
    "| estimated     |  11.0034 |      1.77461 |     0.889828 |\n",
    "| early_initial |  10.5116 |      2.15986 |     0.522199 |\n",
    "\n",
    "------------------------------------\n",
    "##### Results for Pyramid Q-Matrix\n",
    "Latent dimension: 3,  Item dimension: 20, sample size 1000 \\\n",
    "Runtime: 313.22 seconds, 51 steps, 6.14 seconds per step \\\n",
    "Optimal marginal Likelihood: -9452.24, Estimated: -9813.87, Initial -11216.48\n",
    "|               |   rmse_A |   rmse_delta |   rmse_sigma |\n",
    "|:--------------|---------:|-------------:|-------------:|\n",
    "| estimated     |  5.34115 |      1.4068  |     0.425982 |\n",
    "| early_initial |  5.98238 |      2.25109 |     0.234288 |\n",
    "\n",
    "------------------------------------\n",
    "##### Results for Pyramid Q-Matrix\n",
    "Latent dimension: 3,  Item dimension: 30, sample size 2000 \\\n",
    "Runtime: 1521.51 seconds, 76 steps, 20.02 seconds per step \\\n",
    "Optimal marginal Likelihood: -30844.13, Estimated: -32521.34, Initial -37390.6\n",
    "|               |   rmse_A |   rmse_delta |   rmse_sigma |\n",
    "|:--------------|---------:|-------------:|-------------:|\n",
    "| estimated     |  2.55959 |       1.9952 |    0.314331  |\n",
    "| early_initial |  3.32034 |       3.514  |    0.0239562 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procedure for better model performance:\n",
    "\n",
    "1. Implement MIRT Baseline (done)\n",
    "2. Test GA with quadratic function (done)\n",
    "3. use pycma (done)\n",
    "4. Test mirt-functions (response-matrix-probability, done)\n",
    "5. Read on MC MIRT (MC-Errorbounds usage or quasi-MC or importance sampling)\n",
    "6. Use importance sampling\n",
    "7. Implement Newton Raphson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimeted Parameters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f96c9f0abe66cee0a81d860b29e85a2729d567fff345231565bc586735399795"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
