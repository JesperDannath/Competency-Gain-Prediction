{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from simulation_framework.item_response_simulation import item_response_simulation\n",
    "from simulation_framework.simulate_competency import respondent_population\n",
    "from simulation_framework.simulate_responses import response_simulation\n",
    "from scipy.stats import multivariate_normal\n",
    "import models\n",
    "import em_algorithm\n",
    "import pandas as pd\n",
    "import time\n",
    "from girth import multidimensional_twopl_mml\n",
    "from girth import twopl_mml\n",
    "import cma\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def params_to_vector(model):\n",
    "    item_dimension = model.item_dimension\n",
    "    latent_dimension = model.latent_dimension\n",
    "    A_flat = model.item_parameters[\"discrimination_matrix\"].flatten()\n",
    "    A_flat = A_flat[A_flat != 0]\n",
    "    A_cut = len(A_flat)\n",
    "    delta_cut = A_cut+item_dimension\n",
    "    delta = model.item_parameters[\"intercept_vector\"]\n",
    "    sigma_flat = model.person_parameters[\"covariance\"][np.triu_indices(\n",
    "            model.latent_dimension, k=1)]\n",
    "    return(np.concatenate((A_flat, delta, sigma_flat), axis=0))\n",
    "\n",
    "def vector_to_params(vector, model):\n",
    "    item_dimension = model.item_dimension\n",
    "    latent_dimension = model.latent_dimension \n",
    "    q_matrix = model.item_parameters[\"q_matrix\"] \n",
    "    q_flat = q_matrix.flatten()\n",
    "    A_cut = len(q_flat[q_flat != 0])\n",
    "    delta_cut = A_cut+item_dimension\n",
    "    A = vector[0:A_cut]\n",
    "    A = model.fill_zero_discriminations(A).reshape((item_dimension, latent_dimension))\n",
    "    delta = vector[A_cut:delta_cut]\n",
    "    item_parameters = {\"discrimination_matrix\": A, \"intercept_vector\": delta}\n",
    "    corr = vector[delta_cut: len(vector)]\n",
    "    sigma = model.corr_to_sigma(corr, False)\n",
    "    return({\"item_parameters\": item_parameters, \"person_parameters\": {\"covariance\": sigma}})\n",
    "\n",
    "def direct_marginal_optimization(model, response_data):\n",
    "    #Get initial parameters\n",
    "    x0 = params_to_vector(model)\n",
    "    response_data = response_data.to_numpy()\n",
    "    #Optimize with GA\n",
    "    def marginal_l_func(input_vector):\n",
    "        parameters = vector_to_params(input_vector, model)\n",
    "        try:\n",
    "            model.set_parameters(parameters)\n",
    "        except Exception:\n",
    "            return(np.inf)\n",
    "        result = -1*model.marginal_response_loglikelihood(response_data)\n",
    "        return(result)\n",
    "    es = cma.CMAEvolutionStrategy(x0=x0, sigma0=0.5)\n",
    "    es.optimize(marginal_l_func, maxfun=100000)\n",
    "    #Get result\n",
    "    result = es.result.xfavorite\n",
    "    return(vector_to_params(result, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.mirt_2pl import mirt_2pl\n",
    "\n",
    "def rmse(y_pred: np.array, y_true: np.array) -> float:\n",
    "    MSE = np.square(np.subtract(y_pred.flatten(), y_true.flatten())).mean()\n",
    "    RMSE = np.sqrt(MSE)\n",
    "    return(float(RMSE))\n",
    "\n",
    "def experiment_performance(estimated_parameter_dict, real_parameter_dict):\n",
    "    res_dict = {}\n",
    "    if \"item_parameters\" in estimated_parameter_dict.keys():\n",
    "        A_pred = estimated_parameter_dict[\"item_parameters\"][\"discrimination_matrix\"]\n",
    "        delta_pred = estimated_parameter_dict[\"item_parameters\"][\"intercept_vector\"]\n",
    "\n",
    "        A_true = real_parameter_dict[\"item_parameters\"][\"discrimination_matrix\"]\n",
    "        delta_true = real_parameter_dict[\"item_parameters\"][\"intercept_vector\"]\n",
    "\n",
    "        print(\"Absolute diff in A:\")\n",
    "        print(np.abs(A_true-A_pred))\n",
    "\n",
    "        print(\"Absolute diff in delta:\")\n",
    "        print(np.abs(delta_true-delta_pred))\n",
    "\n",
    "        res_dict[\"rmse_A\"] = rmse(A_pred, A_true)\n",
    "        res_dict[\"rmse_delta\"] = rmse(delta_true, delta_pred)\n",
    "\n",
    "    if \"person_parameters\" in estimated_parameter_dict.keys():\n",
    "        sigma_pred = estimated_parameter_dict[\"person_parameters\"][\"covariance\"]\n",
    "        sigma_true = real_parameter_dict[\"person_parameters\"][\"covariance\"]\n",
    "\n",
    "        print(\"Absolute diff in sigma:\")\n",
    "        print(np.abs(sigma_true-sigma_pred)) # TODO: Evtl. die Hauptdiagonale ausschlie√üen!\n",
    "\n",
    "        res_dict[\"rmse_sigma\"] = rmse(sigma_true, sigma_pred) \n",
    "    if len(res_dict.keys())==0:\n",
    "        raise Exception(\"No performance to calculate\")\n",
    "    return(res_dict)\n",
    "\n",
    "def standardize_parameters(parameter_dict):\n",
    "        covariance = parameter_dict[\"person_parameters\"][\"covariance\"]\n",
    "        A = parameter_dict[\"item_parameters\"][\"discrimination_matrix\"]\n",
    "        if len(covariance.shape)<=1:\n",
    "            correlation_matrix  = np.array([[1]])\n",
    "            inv_sqrt_cov = np.array([[np.sqrt(1/covariance)]])\n",
    "            A = np.multiply(A, inv_sqrt_cov)\n",
    "        else:\n",
    "            sd_vector = np.sqrt(covariance.diagonal())\n",
    "            inv_sd_matrix = np.linalg.inv(np.diag(sd_vector))\n",
    "            correlation_matrix = np.dot(\n",
    "            np.dot(inv_sd_matrix, covariance), inv_sd_matrix)\n",
    "            A = np.dot(A, np.linalg.inv(inv_sd_matrix))\n",
    "        parameter_dict[\"item_parameters\"][\"discrimination_matrix\"] = A\n",
    "        parameter_dict[\"person_parameters\"][\"covariance\"] = correlation_matrix\n",
    "        return(parameter_dict)\n",
    "\n",
    "def create_parameter_dict(estimated_early_parameters, real_early_parameters, estimated_late_parameters, real_late_parameters):\n",
    "    parameter_dict = {\"real_early_parameters\": real_early_parameters,\n",
    "                   \"estimated_early_parameters\": estimated_early_parameters}\n",
    "    return(parameter_dict)\n",
    "\n",
    "\n",
    "def create_performance_dict(parameter_dict, run_dict, sample=None, baselines=None, model=None):\n",
    "    result_dict = parameter_dict\n",
    "    result_dict[\"sample\"] = sample\n",
    "    #Model Performance\n",
    "    result_dict[\"early_performance\"] = {}\n",
    "    result_dict[\"early_performance\"][\"rmse\"] = experiment_performance(real_parameter_dict=result_dict[\"real_early_parameters\"], \n",
    "                                                              estimated_parameter_dict=result_dict[\"estimated_early_parameters\"])\n",
    "    #Baseline's Performance\n",
    "    baselines[\"early_initial\"][\"performance\"] = {\"rmse\": experiment_performance(real_parameter_dict=result_dict[\"real_early_parameters\"], \n",
    "                                                              estimated_parameter_dict=baselines[\"early_initial\"][\"parameters\"])}\n",
    "    if \"girth\" in baselines.keys():\n",
    "        girth_data = result_dict[\"sample\"][\"early_responses\"].to_numpy().transpose()\n",
    "        if model.latent_dimension == 1:\n",
    "            girth_estimates = twopl_mml(girth_data)\n",
    "        else:\n",
    "            girth_estimates = multidimensional_twopl_mml(girth_data, n_factors=model.latent_dimension)\n",
    "        girth_item_parameters = {\"discrimination_matrix\": girth_estimates[\"Discrimination\"], \"intercept_vector\": girth_estimates[\"Difficulty\"]}\n",
    "        girth_parameters = {\"item_parameters\": girth_item_parameters}\n",
    "        girth_estimated_covariance = np.cov(girth_estimates[\"Ability\"], rowvar=True)\n",
    "        girth_parameters[\"person_parameters\"] = {\"covariance\": girth_estimated_covariance}\n",
    "        girth_parameters = standardize_parameters(girth_parameters)\n",
    "        girth_performance_rmse = experiment_performance(real_parameter_dict=result_dict[\"real_early_parameters\"], \n",
    "                                                              estimated_parameter_dict=girth_parameters)\n",
    "        baselines[\"girth\"][\"parameters\"] = girth_parameters\n",
    "        baselines[\"girth\"][\"performance\"] = {\"rmse\": girth_performance_rmse}\n",
    "\n",
    "    if \"early_direct\" in baselines.keys():\n",
    "        dir_model = mirt_2pl(item_dimension=model.item_dimension, latent_dimension=model.latent_dimension, Q=model.item_parameters[\"q_matrix\"])\n",
    "        direct_early_item_parameters = direct_marginal_optimization(dir_model, response_data=sample[\"early_responses\"])\n",
    "        direct_early_performance_rmse = experiment_performance(real_parameter_dict=result_dict[\"real_early_parameters\"], \n",
    "                                                              estimated_parameter_dict=direct_early_item_parameters)\n",
    "        baselines[\"early_direct\"][\"parameters\"] = direct_early_item_parameters\n",
    "        baselines[\"early_direct\"][\"performance\"] = {\"rmse\": direct_early_performance_rmse}\n",
    "\n",
    "    result_dict[\"baselines\"] = baselines\n",
    "    likelihood = calculate_marginal_likelihoods(model=model, response_data=sample[\"early_responses\"], real_parameters=result_dict[\"real_early_parameters\"],\n",
    "                                                initial_parameters=baselines[\"early_initial\"][\"parameters\"], estimated_parameters=result_dict[\"estimated_early_parameters\"])\n",
    "    result_dict[\"early_performance\"][\"marginal_likelihood\"] = likelihood\n",
    "    result_dict[\"early_performance\"][\"run\"] = run_dict[\"early\"]\n",
    "    return(result_dict)\n",
    "\n",
    "def calculate_marginal_likelihoods(model, response_data, real_parameters, initial_parameters, estimated_parameters):\n",
    "    model.set_parameters(initial_parameters)\n",
    "    initial_marginal_likelihood = model.marginal_response_loglikelihood(response_data=response_data.to_numpy())\n",
    "    model.set_parameters(real_parameters)\n",
    "    optimal_marginal_likelihood = model.marginal_response_loglikelihood(response_data=response_data.to_numpy())\n",
    "    model.set_parameters(estimated_parameters)\n",
    "    marginal_likelihood_estimated = model.marginal_response_loglikelihood(response_data=response_data.to_numpy())\n",
    "    likelihood_dict = {\"optimal\": optimal_marginal_likelihood, \"estimated\": marginal_likelihood_estimated, \"initial\": initial_marginal_likelihood}\n",
    "    return(likelihood_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def direct_optimization_benchmark():\n",
    "    latent_dimension = 2\n",
    "    item_dimension = 6\n",
    "    sample_size=100\n",
    "\n",
    "    #Define Population\n",
    "    real_latent_cov = np.array([[1,0.2],\n",
    "                    [0.2,1]])\n",
    "\n",
    "    latent_distribution = multivariate_normal(mean=np.array([0,0]), cov=real_latent_cov)\n",
    "    population = respondent_population(latent_dimension=latent_dimension, latent_distribution=latent_distribution)\n",
    "\n",
    "    #Define Test\n",
    "    A = np.array([[0.5,0],\n",
    "                  [2,0],\n",
    "                  [0,0.4],\n",
    "                  [0.7,0.6],\n",
    "                  [2, 0.9],\n",
    "                  [0, 1.5]])\n",
    "    Q = np.array([[1,0],\n",
    "                  [1,0],\n",
    "                  [0,1],\n",
    "                  [1,1],\n",
    "                  [1,1],\n",
    "                  [0,1]])\n",
    "\n",
    "    delta = np.array([0, 0.5, 1, 0, 1.5, 0.9])\n",
    "    early_item_parameters = {\"discrimination_matrix\": A, \"intercept_vector\": delta, \"q_matrix\": Q, \"item_dimension\": item_dimension, \"latent_dimension\": latent_dimension}\n",
    "    real_early_parameters = {\"item_parameters\": early_item_parameters, \"person_parameters\": {\"covariance\": real_latent_cov}}\n",
    "\n",
    "    #Sample responses\n",
    "    response_simulation_obj = response_simulation(population=population, item_dimension = item_dimension, early_item_params=early_item_parameters)\n",
    "    sample = response_simulation_obj.sample(sample_size)\n",
    "\n",
    "    #Fit Parameters\n",
    "    #Initialize model\n",
    "    model = models.mirt_2pl(latent_dimension=2, item_dimension=6, Q=Q)\n",
    "    model.initialize_from_responses(response_data=sample[\"early_responses\"])\n",
    "\n",
    "    estimated_params = direct_marginal_optimization(model, response_data=sample[\"early_responses\"])\n",
    "    return(estimated_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 0: MIRT-2PL Performance Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mirt_performance_benchmark() -> dict:\n",
    "    latent_dimension = 2\n",
    "    item_dimension = 6\n",
    "    sample_size=100\n",
    "\n",
    "    #Define Population\n",
    "    real_latent_cov = np.array([[1,0.2],\n",
    "                    [0.2,1]])\n",
    "\n",
    "    latent_distribution = multivariate_normal(mean=np.array([0,0]), cov=real_latent_cov)\n",
    "    population = respondent_population(latent_dimension=latent_dimension, latent_distribution=latent_distribution)\n",
    "\n",
    "    #Define Test\n",
    "    A = np.array([[0.5,0],\n",
    "                  [2,0],\n",
    "                  [0,0.4],\n",
    "                  [0.7,0.6],\n",
    "                  [2, 0.9],\n",
    "                  [0, 1.5]])\n",
    "    Q = np.array([[1,0],\n",
    "                  [1,0],\n",
    "                  [0,1],\n",
    "                  [1,1],\n",
    "                  [1,1],\n",
    "                  [0,1]])\n",
    "\n",
    "    delta = np.array([0, 0.5, 1, 0, 1.5, 0.9])\n",
    "    early_item_parameters = {\"discrimination_matrix\": A, \"intercept_vector\": delta, \"q_matrix\": Q, \"item_dimension\": item_dimension, \"latent_dimension\": latent_dimension}\n",
    "    real_early_parameters = {\"item_parameters\": early_item_parameters, \"person_parameters\": {\"covariance\": real_latent_cov}}\n",
    "\n",
    "    #Sample responses\n",
    "    response_simulation_obj = response_simulation(population=population, item_dimension = item_dimension, early_item_params=early_item_parameters)\n",
    "    sample = response_simulation_obj.sample(sample_size)\n",
    "\n",
    "    #Fit Parameters\n",
    "    #Initialize model\n",
    "    model = models.mirt_2pl(latent_dimension=2, item_dimension=6, Q=Q)\n",
    "    model.initialize_from_responses(response_data=sample[\"early_responses\"])\n",
    "    initial_early_parameters = model.get_parameters()\n",
    "    e_step = em_algorithm.e_step_ga_mml(model=model)\n",
    "    m_step = em_algorithm.m_step_ga_mml(model)\n",
    "    em = em_algorithm.em_algo(e_step=e_step, m_step=m_step, model=model)\n",
    "\n",
    "    #Fit Model\n",
    "    start_time = time.time()\n",
    "    em.fit(sample[\"early_responses\"], max_iter=50)\n",
    "    run_time =  (time.time() - start_time)\n",
    "\n",
    "    #Create Baselines\n",
    "    baselines = {\"early_initial\": {\"parameters\": initial_early_parameters}, \"girth\": {}, \"early_direct\": {}}\n",
    "    \n",
    "    #Create results\n",
    "    early_estimated_parameters = em.model.get_parameters()\n",
    "\n",
    "    parameter_dict = create_parameter_dict(estimated_early_parameters=early_estimated_parameters,\n",
    "                          real_early_parameters = real_early_parameters,\n",
    "                          estimated_late_parameters=None, real_late_parameters=None)\n",
    "    run_dict = {\"early\": {\"runtime\": run_time,\n",
    "                \"number_steps\": em.n_steps}}\n",
    "    performance_dict = create_performance_dict(parameter_dict=parameter_dict, run_dict=run_dict, sample=sample, baselines=baselines, model=model)\n",
    "    return(performance_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print_result(result_dict, description=\"\"):\n",
    "    #Description\n",
    "    print(\"------------------------------------\")\n",
    "    print(\"##### Results for {0}\".format(description))\n",
    "    #Experiment Properties:\n",
    "    latent_dimension = result_dict[\"sample\"][\"latent_dimension\"]\n",
    "    item_dimension = result_dict[\"sample\"][\"item_dimension\"]\n",
    "    sample_size = result_dict[\"sample\"][\"sample_size\"]\n",
    "    print(\"Latent dimension: {0},  Item dimension: {1}, sample size {2} \\\\\".format(latent_dimension, item_dimension, sample_size))\n",
    "    #Performance/time\n",
    "    ep_dict = result_dict[\"early_performance\"]\n",
    "    runtime = np.round(ep_dict[\"run\"][\"runtime\"], 2)\n",
    "    steps = ep_dict[\"run\"][\"number_steps\"]\n",
    "    print(\"Runtime: {0} seconds, {1} steps, {2} seconds per step \\\\\".format(runtime, steps, np.round(runtime/steps, 2)))\n",
    "    #Performance/results\n",
    "    l_optimal = np.round(ep_dict[\"marginal_likelihood\"][\"optimal\"], 2)\n",
    "    l_estimated = np.round(ep_dict[\"marginal_likelihood\"][\"estimated\"], 2)\n",
    "    l_real = np.round(ep_dict[\"marginal_likelihood\"][\"initial\"], 2)\n",
    "    print(\"Optimal marginal Likelihood: {0}, Estimated: {1}, Initial {2}\".format(l_optimal,l_estimated,l_real))\n",
    "    #print(\"Performance: rmse-mean = {0} \\\\\".format(np.round(np.mean(np.array(list(result_dict[\"early_performance\"].values()))), 4)))\n",
    "    rmse_model = ep_dict[\"rmse\"]\n",
    "    \n",
    "    rmse_frame = pd.DataFrame(columns=[\"rmse_A\", \"rmse_delta\", \"rmse_sigma\"])\n",
    "    rmse_frame = rmse_frame.append(rmse_model, ignore_index=True)\n",
    "    index = [\"estimated\"]\n",
    "    for baseline in list(result_dict[\"baselines\"].keys()):\n",
    "        rmse_baseline = result_dict[\"baselines\"][baseline][\"performance\"][\"rmse\"]\n",
    "        rmse_frame = rmse_frame.append(rmse_baseline, ignore_index=True)\n",
    "        index.append(baseline)\n",
    "    rmse_frame.index = index\n",
    "    print(rmse_frame.to_markdown())\n",
    "                                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EM Iteration 2\n",
      "Current Monte Carlo Sample size: 300\n",
      "[[1.         0.50955533]\n",
      " [0.50955533 1.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jesper\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_qmc.py:2039: UserWarning: The balance properties of Sobol' points require n to be a power of 2.\n",
      "  samples = self.engine.random(n)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 2: current parameter_diff: 1.5345205134548143, current marginal loglikelihood: -373.66879312920685\n",
      "EM Iteration 3\n",
      "Current Monte Carlo Sample size: 300\n",
      "[[1.         0.51132214]\n",
      " [0.51132214 1.        ]]\n",
      "Step: 3: current parameter_diff: 1.1496593361417635, current marginal loglikelihood: -371.8482760165528\n",
      "EM Iteration 4\n",
      "Current Monte Carlo Sample size: 330\n",
      "[[1.         0.49955822]\n",
      " [0.49955822 1.        ]]\n",
      "Step: 4: current parameter_diff: 1.0378484654568882, current marginal loglikelihood: -370.6098519099325\n",
      "EM Iteration 5\n",
      "Current Monte Carlo Sample size: 363\n",
      "[[1.         0.50319628]\n",
      " [0.50319628 1.        ]]\n",
      "Step: 5: current parameter_diff: 0.8044879101413374, current marginal loglikelihood: -369.27034978664943\n",
      "EM Iteration 6\n",
      "Current Monte Carlo Sample size: 399\n",
      "[[1.         0.50370618]\n",
      " [0.50370618 1.        ]]\n",
      "Step: 6: current parameter_diff: 0.8104581755325072, current marginal loglikelihood: -369.1616783778356\n",
      "EM Iteration 7\n",
      "Current Monte Carlo Sample size: 438\n",
      "[[1.         0.51292774]\n",
      " [0.51292774 1.        ]]\n",
      "Step: 7: current parameter_diff: 1.0469522752062685, current marginal loglikelihood: -368.00236788965657\n",
      "EM Iteration 8\n",
      "Current Monte Carlo Sample size: 481\n",
      "[[1.         0.49696855]\n",
      " [0.49696855 1.        ]]\n",
      "Step: 8: current parameter_diff: 0.49051194177039437, current marginal loglikelihood: -367.82508572245337\n",
      "EM Iteration 9\n",
      "Current Monte Carlo Sample size: 529\n",
      "[[1.         0.48830637]\n",
      " [0.48830637 1.        ]]\n",
      "Step: 9: current parameter_diff: 0.0922709089523529, current marginal loglikelihood: -368.0236512889189\n",
      "EM Iteration 10\n",
      "Current Monte Carlo Sample size: 581\n",
      "[[1.         0.47447678]\n",
      " [0.47447678 1.        ]]\n",
      "Step: 10: current parameter_diff: 0.06215656708303363, current marginal loglikelihood: -367.71504042802684\n",
      "EM Iteration 11\n",
      "Current Monte Carlo Sample size: 639\n",
      "[[1.         0.46886681]\n",
      " [0.46886681 1.        ]]\n",
      "Step: 11: current parameter_diff: 0.6170888594984181, current marginal loglikelihood: -367.4892899819944\n",
      "EM Iteration 12\n",
      "Current Monte Carlo Sample size: 702\n",
      "[[1.         0.46577511]\n",
      " [0.46577511 1.        ]]\n",
      "Step: 12: current parameter_diff: 0.2805331833863616, current marginal loglikelihood: -367.4324869150373\n",
      "EM Iteration 13\n",
      "Current Monte Carlo Sample size: 772\n",
      "[[1.         0.46772916]\n",
      " [0.46772916 1.        ]]\n",
      "Step: 13: current parameter_diff: 0.6637961799197538, current marginal loglikelihood: -367.4875037191287\n",
      "EM Iteration 14\n",
      "Current Monte Carlo Sample size: 849\n",
      "[[1.         0.46013793]\n",
      " [0.46013793 1.        ]]\n",
      "Step: 14: current parameter_diff: 0.015199999999999991, current marginal loglikelihood: -367.60914492131803\n",
      "EM Iteration 15\n",
      "Current Monte Carlo Sample size: 933\n",
      "[[1.         0.45697872]\n",
      " [0.45697872 1.        ]]\n",
      "Step: 15: current parameter_diff: 0.010943374727804156, current marginal loglikelihood: -367.32118089074226\n",
      "EM Iteration 16\n",
      "Current Monte Carlo Sample size: 1026\n",
      "[[1.         0.45688928]\n",
      " [0.45688928 1.        ]]\n",
      "Step: 16: current parameter_diff: 0.13414830050704082, current marginal loglikelihood: -367.34013626017304\n",
      "EM Iteration 17\n",
      "Current Monte Carlo Sample size: 1128\n",
      "[[1.         0.45358975]\n",
      " [0.45358975 1.        ]]\n",
      "Step: 17: current parameter_diff: 0.038130156465345566, current marginal loglikelihood: -367.21787449554694\n",
      "EM Iteration 18\n",
      "Current Monte Carlo Sample size: 1240\n",
      "[[1.         0.45423055]\n",
      " [0.45423055 1.        ]]\n",
      "Step: 18: current parameter_diff: 0.0013999999999999568, current marginal loglikelihood: -367.37023080888235\n",
      "EM Iteration 19\n",
      "Current Monte Carlo Sample size: 1240\n",
      "[[1.         0.45291825]\n",
      " [0.45291825 1.        ]]\n",
      "Step: 19: current parameter_diff: 0.10903829455829417, current marginal loglikelihood: -367.07207059675034\n",
      "EM Iteration 20\n",
      "Current Monte Carlo Sample size: 1240\n",
      "[[1.         0.45584247]\n",
      " [0.45584247 1.        ]]\n",
      "Step: 20: current parameter_diff: 0.2563346599438904, current marginal loglikelihood: -367.39131689056256\n",
      "EM Iteration 21\n",
      "Current Monte Carlo Sample size: 1240\n",
      "[[1.         0.44891055]\n",
      " [0.44891055 1.        ]]\n",
      "Step: 21: current parameter_diff: 0.013799999999999923, current marginal loglikelihood: -367.04340887825697\n",
      "EM Iteration 22\n",
      "Current Monte Carlo Sample size: 1364\n",
      "[[1.         0.44049505]\n",
      " [0.44049505 1.        ]]\n",
      "Step: 22: current parameter_diff: 0.1095185946306334, current marginal loglikelihood: -367.0737421744601\n",
      "EM Iteration 23\n",
      "Current Monte Carlo Sample size: 1500\n",
      "[[1.         0.43840152]\n",
      " [0.43840152 1.        ]]\n",
      "Step: 23: current parameter_diff: 0.04125945643509832, current marginal loglikelihood: -367.2055499737368\n",
      "EM Iteration 24\n",
      "Current Monte Carlo Sample size: 1650\n",
      "[[1.         0.43917021]\n",
      " [0.43917021 1.        ]]\n",
      "Step: 24: current parameter_diff: 0.09205122827445622, current marginal loglikelihood: -367.2374776424095\n",
      "EM Iteration 25\n",
      "Current Monte Carlo Sample size: 1815\n",
      "[[1.         0.43175471]\n",
      " [0.43175471 1.        ]]\n",
      "Step: 25: current parameter_diff: 0.014800000000000035, current marginal loglikelihood: -367.05812317554023\n",
      "EM Iteration 26\n",
      "Current Monte Carlo Sample size: 1815\n",
      "[[1.         0.42659216]\n",
      " [0.42659216 1.        ]]\n",
      "Step: 26: current parameter_diff: 0.04358300573385199, current marginal loglikelihood: -367.1959307419724\n",
      "EM Iteration 27\n",
      "Current Monte Carlo Sample size: 1996\n",
      "[[1.         0.41976107]\n",
      " [0.41976107 1.        ]]\n",
      "Step: 27: current parameter_diff: 0.2594566593949592, current marginal loglikelihood: -366.68366055167064\n",
      "EM Iteration 28\n",
      "Current Monte Carlo Sample size: 2195\n",
      "[[1.         0.41315222]\n",
      " [0.41315222 1.        ]]\n",
      "Step: 28: current parameter_diff: 0.01319999999999999, current marginal loglikelihood: -367.454385056152\n",
      "EM Iteration 29\n",
      "Current Monte Carlo Sample size: 2414\n",
      "[[1.        0.4064611]\n",
      " [0.4064611 1.       ]]\n",
      "Step: 29: current parameter_diff: 0.013500000000000068, current marginal loglikelihood: -366.65494380584136\n",
      "EM Iteration 30\n",
      "Current Monte Carlo Sample size: 2655\n",
      "[[1.        0.4016965]\n",
      " [0.4016965 1.       ]]\n",
      "Step: 30: current parameter_diff: 0.015246756239278736, current marginal loglikelihood: -366.97684526455913\n",
      "EM Iteration 31\n",
      "Current Monte Carlo Sample size: 2920\n",
      "[[1.         0.39934576]\n",
      " [0.39934576 1.        ]]\n",
      "Step: 31: current parameter_diff: 0.11203928804761815, current marginal loglikelihood: -366.8833271975856\n",
      "EM Iteration 32\n",
      "Current Monte Carlo Sample size: 3212\n",
      "[[1.         0.39154925]\n",
      " [0.39154925 1.        ]]\n",
      "Step: 32: current parameter_diff: 0.015599999999999947, current marginal loglikelihood: -366.9852289294566\n",
      "EM Iteration 33\n",
      "Current Monte Carlo Sample size: 3533\n",
      "[[1.         0.38717071]\n",
      " [0.38717071 1.        ]]\n",
      "Step: 33: current parameter_diff: 0.00880000000000003, current marginal loglikelihood: -367.10433511868234\n",
      "EM Iteration 34\n",
      "Current Monte Carlo Sample size: 3886\n",
      "[[1.         0.38109822]\n",
      " [0.38109822 1.        ]]\n",
      "Step: 34: current parameter_diff: 0.024599880608237368, current marginal loglikelihood: -366.8653834199779\n",
      "EM Iteration 35\n",
      "Current Monte Carlo Sample size: 4274\n",
      "[[1.         0.37960111]\n",
      " [0.37960111 1.        ]]\n",
      "Step: 35: current parameter_diff: 0.029649472593451964, current marginal loglikelihood: -367.38886615774425\n",
      "EM Iteration 36\n",
      "Current Monte Carlo Sample size: 4701\n",
      "[[1.         0.37677536]\n",
      " [0.37677536 1.        ]]\n",
      "Step: 36: current parameter_diff: 0.005800000000000027, current marginal loglikelihood: -367.12558889624484\n",
      "EM Iteration 37\n",
      "Current Monte Carlo Sample size: 5171\n",
      "[[1.         0.37296142]\n",
      " [0.37296142 1.        ]]\n",
      "Step: 37: current parameter_diff: 0.05954094440448243, current marginal loglikelihood: -366.6808981059179\n",
      "EM Iteration 38\n",
      "Current Monte Carlo Sample size: 5688\n",
      "[[1.         0.36952286]\n",
      " [0.36952286 1.        ]]\n",
      "Step: 38: current parameter_diff: 0.006900000000000017, current marginal loglikelihood: -366.78649625461054\n",
      "EM Iteration 39\n",
      "Current Monte Carlo Sample size: 6256\n",
      "[[1.         0.36751698]\n",
      " [0.36751698 1.        ]]\n",
      "Step: 39: current parameter_diff: 0.0040999999999999925, current marginal loglikelihood: -366.91741655023685\n",
      "EM Iteration 40\n",
      "Current Monte Carlo Sample size: 6881\n",
      "[[1.         0.36557524]\n",
      " [0.36557524 1.        ]]\n",
      "Step: 40: current parameter_diff: 0.0040000000000000036, current marginal loglikelihood: -366.7538060961093\n",
      "EM Iteration 41\n",
      "Current Monte Carlo Sample size: 6881\n",
      "[[1.         0.36350004]\n",
      " [0.36350004 1.        ]]\n",
      "Step: 41: current parameter_diff: 0.04565569855214768, current marginal loglikelihood: -366.76209679402905\n",
      "EM Iteration 42\n",
      "Current Monte Carlo Sample size: 6881\n",
      "[[1.         0.36085772]\n",
      " [0.36085772 1.        ]]\n",
      "Step: 42: current parameter_diff: 0.005499999999999949, current marginal loglikelihood: -366.79556789732425\n",
      "EM Iteration 43\n",
      "Current Monte Carlo Sample size: 7569\n",
      "[[1.         0.35966711]\n",
      " [0.35966711 1.        ]]\n",
      "Step: 43: current parameter_diff: 0.0024000000000000687, current marginal loglikelihood: -366.4664072174019\n",
      "EM Iteration 44\n",
      "Current Monte Carlo Sample size: 8325\n",
      "[[1.         0.35897063]\n",
      " [0.35897063 1.        ]]\n",
      "Step: 44: current parameter_diff: 0.0038656939903264353, current marginal loglikelihood: -366.59233457190896\n",
      "EM Iteration 45\n",
      "Current Monte Carlo Sample size: 8325\n",
      "[[1.         0.35771023]\n",
      " [0.35771023 1.        ]]\n",
      "Step: 45: current parameter_diff: 0.0023999999999999577, current marginal loglikelihood: -366.7571014087759\n",
      "EM Iteration 46\n",
      "Current Monte Carlo Sample size: 9157\n",
      "[[1.         0.35681808]\n",
      " [0.35681808 1.        ]]\n",
      "Step: 46: current parameter_diff: 0.8296589044610274, current marginal loglikelihood: -366.72374898545615\n",
      "EM Iteration 47\n",
      "Current Monte Carlo Sample size: 10072\n",
      "[[1.         0.35465597]\n",
      " [0.35465597 1.        ]]\n",
      "Step: 47: current parameter_diff: 0.03976115323621554, current marginal loglikelihood: -366.7984455424187\n",
      "EM Iteration 48\n",
      "Current Monte Carlo Sample size: 10072\n",
      "[[1.         0.35219554]\n",
      " [0.35219554 1.        ]]\n",
      "Step: 48: current parameter_diff: 0.1501608924805985, current marginal loglikelihood: -366.57709132321423\n",
      "EM Iteration 49\n",
      "Current Monte Carlo Sample size: 11079\n",
      "[[1.         0.34864609]\n",
      " [0.34864609 1.        ]]\n",
      "Step: 49: current parameter_diff: 0.007099999999999995, current marginal loglikelihood: -366.72433637585254\n",
      "EM Iteration 50\n",
      "Current Monte Carlo Sample size: 12186\n",
      "[[1.        0.3466352]\n",
      " [0.3466352 1.       ]]\n",
      "Step: 50: current parameter_diff: 0.07714324888323154, current marginal loglikelihood: -366.6760991986703\n",
      "EM Iteration 51\n",
      "Current Monte Carlo Sample size: 13404\n",
      "[[1.         0.34415707]\n",
      " [0.34415707 1.        ]]\n",
      "Step: 51: current parameter_diff: 0.014146936920724884, current marginal loglikelihood: -366.4475453536203\n",
      "Absolute diff in A:\n",
      "[[0.30822323 0.        ]\n",
      " [0.12752466 0.        ]\n",
      " [0.         0.07245972]\n",
      " [0.17184334 0.31422829]\n",
      " [2.10914469 0.31052867]\n",
      " [0.         0.55751364]]\n",
      "Absolute diff in delta:\n",
      "[0.13016036 0.15221287 0.17508666 0.06694503 0.89388447 0.14317076]\n",
      "Absolute diff in sigma:\n",
      "[[0.000e+00 1.441e-01]\n",
      " [1.441e-01 1.000e-04]]\n",
      "Absolute diff in A:\n",
      "[[0.5 0. ]\n",
      " [1.  0. ]\n",
      " [0.  0.6]\n",
      " [0.3 0.4]\n",
      " [1.  0.1]\n",
      " [0.  0.5]]\n",
      "Absolute diff in delta:\n",
      "[0.12014431 0.25883794 0.15267951 0.04000533 0.6998807  0.41045177]\n",
      "Absolute diff in sigma:\n",
      "[[0.  0.3]\n",
      " [0.3 0. ]]\n",
      "Absolute diff in A:\n",
      "[[0.30256243 0.79157404]\n",
      " [0.76433124 0.66574362]\n",
      " [1.85030151 2.66325334]\n",
      " [0.15977911 0.43633017]\n",
      " [0.29269744 1.6381139 ]\n",
      " [0.65603994 1.5       ]]\n",
      "Absolute diff in delta:\n",
      "[0.14898251 0.12077913 1.99826226 0.04489428 0.90361002 0.33299936]\n",
      "Absolute diff in sigma:\n",
      "[[2.22044605e-16 5.36019964e-02]\n",
      " [5.36019964e-02 2.22044605e-16]]\n",
      "(6_w,12)-aCMA-ES (mu_w=3.7,w_1=40%) in dimension 15 (seed=251436, Wed Oct 19 12:15:21 2022)\n",
      "Iterat #Fevals   function value  axis ratio  sigma  min&max std  t[m:s]\n",
      "    1     12 3.937673538368082e+02 1.0e+00 4.45e-01  4e-01  4e-01 0:00.1\n",
      "    2     24 3.833957115973383e+02 1.1e+00 4.38e-01  4e-01  4e-01 0:00.1\n",
      "    3     36 3.877673029378675e+02 1.2e+00 4.13e-01  4e-01  4e-01 0:00.2\n",
      "[[ 1.         -1.19675488]\n",
      " [-1.19675488  1.        ]]\n",
      "[[ 1.         -1.13869452]\n",
      " [-1.13869452  1.        ]]\n",
      "[[ 1.         -1.04799055]\n",
      " [-1.04799055  1.        ]]\n",
      "[[ 1.         -1.14973086]\n",
      " [-1.14973086  1.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jesper\\Anaconda3\\lib\\site-packages\\cma\\utilities\\utils.py:343: UserWarning: function values with index [3, 6, 9] are not finite but [inf, inf, inf]. (class=CMAEvolutionStrategy method=ask iteration=4)\n",
      "  warnings.warn(msg + ' (' +\n",
      "c:\\Users\\Jesper\\Anaconda3\\lib\\site-packages\\cma\\utilities\\utils.py:343: UserWarning: function values with index [10] are not finite but [inf]. (class=CMAEvolutionStrategy method=ask iteration=6)\n",
      "  warnings.warn(msg + ' (' +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         1.13184141]\n",
      " [1.13184141 1.        ]]\n",
      "[[1.         1.14029677]\n",
      " [1.14029677 1.        ]]\n",
      "[[1.         1.03185824]\n",
      " [1.03185824 1.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jesper\\Anaconda3\\lib\\site-packages\\cma\\utilities\\utils.py:343: UserWarning: function values with index [10] are not finite but [inf]. (class=CMAEvolutionStrategy method=ask iteration=15)\n",
      "  warnings.warn(msg + ' (' +\n",
      "c:\\Users\\Jesper\\Anaconda3\\lib\\site-packages\\cma\\utilities\\utils.py:343: UserWarning: function values with index [2, 9] are not finite but [inf, inf]. (class=CMAEvolutionStrategy method=ask iteration=18)\n",
      "  warnings.warn(msg + ' (' +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         1.09200055]\n",
      " [1.09200055 1.        ]]\n",
      "[[1.         1.14279112]\n",
      " [1.14279112 1.        ]]\n",
      "[[1.        1.0559787]\n",
      " [1.0559787 1.       ]]\n",
      "[[1.         1.02270144]\n",
      " [1.02270144 1.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jesper\\Anaconda3\\lib\\site-packages\\cma\\utilities\\utils.py:343: UserWarning: function values with index [5] are not finite but [inf]. (class=CMAEvolutionStrategy method=ask iteration=26)\n",
      "  warnings.warn(msg + ' (' +\n",
      "c:\\Users\\Jesper\\Anaconda3\\lib\\site-packages\\cma\\utilities\\utils.py:343: UserWarning: function values with index [1, 5] are not finite but [inf, inf]. (class=CMAEvolutionStrategy method=ask iteration=27)\n",
      "  warnings.warn(msg + ' (' +\n",
      "c:\\Users\\Jesper\\Anaconda3\\lib\\site-packages\\cma\\utilities\\utils.py:343: UserWarning: function values with index [6] are not finite but [inf]. (class=CMAEvolutionStrategy method=ask iteration=28)\n",
      "  warnings.warn(msg + ' (' +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   56    672 3.669582785863784e+02 2.4e+00 6.10e-02  4e-02  7e-02 0:03.2\n",
      "  100   1200 3.666234875412319e+02 3.2e+00 3.94e-02  2e-02  5e-02 0:05.8\n",
      "  186   2232 3.664839823266960e+02 5.7e+00 2.99e-02  1e-02  4e-02 0:10.9\n",
      "  200   2400 3.666607845292899e+02 6.3e+00 1.72e-02  8e-03  2e-02 0:11.7\n",
      "  300   3600 3.663931043568954e+02 1.0e+01 1.04e-02  5e-03  1e-02 0:17.5\n",
      "  400   4800 3.663900371537832e+02 1.8e+01 2.70e-02  1e-02  4e-02 0:23.8\n",
      "  500   6000 3.663403986926041e+02 1.8e+01 2.62e-02  9e-03  3e-02 0:30.4\n",
      "  600   7200 3.664181422211946e+02 2.3e+01 1.82e-02  6e-03  2e-02 0:37.2\n",
      "  700   8400 3.664285330482364e+02 3.7e+01 9.72e-03  3e-03  1e-02 0:43.7\n",
      "  800   9600 3.661100435690640e+02 6.3e+01 2.38e-02  7e-03  3e-02 0:50.2\n",
      "  900  10800 3.663329541166315e+02 6.7e+01 1.10e-02  2e-03  1e-02 0:56.7\n",
      "  980  11760 3.662611574835303e+02 8.8e+01 7.31e-03  2e-03  8e-03 1:02.1\n",
      "Absolute diff in A:\n",
      "[[0.26219961 0.        ]\n",
      " [0.12162323 0.        ]\n",
      " [0.         0.12362127]\n",
      " [0.18017018 0.41543923]\n",
      " [1.75784975 0.74659716]\n",
      " [0.         0.68833627]]\n",
      "Absolute diff in delta:\n",
      "[0.11357453 0.08716461 0.0985446  0.06043184 0.77590877 0.16821629]\n",
      "Absolute diff in sigma:\n",
      "[[0.         0.10543515]\n",
      " [0.10543515 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "performance_dict = mirt_performance_benchmark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "##### Results for Increasing Monte Carlo sample-size based on ttest with normal MC\n",
      "Latent dimension: 2,  Item dimension: 6, sample size 100 \\\n",
      "Runtime: 24.05 seconds, 52 steps, 0.46 seconds per step \\\n",
      "Optimal marginal Likelihood: -370.02, Estimated: -366.57, Initial -377.33\n",
      "|               |   rmse_A |   rmse_delta |   rmse_sigma |\n",
      "|:--------------|---------:|-------------:|-------------:|\n",
      "| estimated     | 0.651954 |     0.386172 |    0.101894  |\n",
      "| early_initial | 0.509902 |     0.356989 |    0.212132  |\n",
      "| girth         | 1.22228  |     0.909143 |    0.0379023 |\n",
      "| early_direct  | 0.607256 |     0.332714 |    0.0745539 |\n"
     ]
    }
   ],
   "source": [
    "print_result(performance_dict, \"Increasing Monte Carlo sample-size based on ttest with normal MC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------\n",
    "##### Results for Naive, all-Genetic, no vectorization\n",
    "Runtime: 29100 seconds, 100+ steps, 291 seconds per step\\\n",
    "Performance: rmse-mean = 0.5896464054719196\n",
    "\n",
    "------------------------------------\n",
    "##### Results for Vectorized q_item\n",
    "Runtime: 613.3871161937714 seconds, 100+ steps, 6.0731397642947655 seconds per step \\\n",
    "Performance: rmse-mean = 0.6466789259215839\n",
    "\n",
    "------------------------------------\n",
    "##### Results for More precise results through higher N and pop_size\n",
    "Runtime: 2239.073846578598 seconds, 100+ steps, 22.169047985926714 seconds per step \\\n",
    "Performance: rmse-mean = 0.6384660709857508\n",
    "\n",
    "------------------------------------\n",
    "##### Results for Debug GA sorting, Add Likelihood-based stopping criterion\n",
    "Runtime: 135.11203932762146 seconds, 7 steps, 19.301719903945923 seconds per step \\\n",
    "Performance: rmse-mean = 0.5616448369465917\n",
    "\n",
    "------------------------------------\n",
    "##### Results for Add vectorization in Q_0\n",
    "Runtime: 228.78 seconds, 17 steps, 13.46 seconds per step \\\n",
    "Performance: rmse-mean = 0.6174\n",
    "\n",
    "------------------------------------\n",
    "##### Results for Add vectorization in E-Step normalizing constant\n",
    "Runtime: 28.37 seconds, 9 steps, 3.15 seconds per step \\\n",
    "Performance: rmse-mean = 0.5808\n",
    "\n",
    "------------------------------------\n",
    "##### Results for Add Suggested Initial Parameters (Zhang)\n",
    "Runtime: 61.22 seconds, 19 steps, 3.22 seconds per step \\\n",
    "Performance: rmse-mean = 0.5625\n",
    "\n",
    "------------------------------------\n",
    "##### Results for Fixed Q_item\n",
    "Runtime: 81.11 seconds, 12 steps, 6.76 seconds per step \\\n",
    "Optimal marginal Likelihood: -375.43, Estimated: -393.8, Initial -391.83\n",
    "|           |   rmse_A |   rmse_delta |   rmse_sigma |\n",
    "|:----------|---------:|-------------:|-------------:|\n",
    "| Estimated | 0.762005 |     0.512703 |     0.600404 |\n",
    "| Girth     | 1.61804  |     0.750525 |   nan        |\n",
    "| Initial   | 0.770281 |     0.227528 |     0.141421 |\n",
    "\n",
    "------------------------------------\n",
    "##### Results for Inproved GA stoppimg rule\n",
    "Runtime: 42.54 seconds, 7 steps, 6.08 seconds per step \\\n",
    "Optimal marginal Likelihood: -378.68, Estimated: -391.87, Initial -378.08\n",
    "|           |   rmse_A |   rmse_delta |   rmse_sigma |\n",
    "|:----------|---------:|-------------:|-------------:|\n",
    "| Estimated | 0.845078 |     0.568092 |    0.167374  |\n",
    "| Girth     | 0.930362 |     0.554795 |    0.141421  |\n",
    "| direct    | 0.401578 |     0.609516 |    0.0526782 |\n",
    "| Initial   | 0.509902 |     0.364352 |    0.141421  |\n",
    "\n",
    "------------------------------------\n",
    "##### Results for pycma ga used\n",
    "Runtime: 489.8 seconds, 16 steps, 30.61 seconds per step \\\n",
    "Optimal marginal Likelihood: -381.34, Estimated: -414.28, Initial -379.77\n",
    "|           |   rmse_A |   rmse_delta |   rmse_sigma |\n",
    "|:----------|---------:|-------------:|-------------:|\n",
    "| Estimated | 0.942127 |     0.505808 |     0.215139 |\n",
    "| Girth     | 1.42144  |     0.632431 |   nan        |\n",
    "| Initial   | 0.509902 |     0.489947 |     0.141421 |\n",
    "\n",
    "------------------------------------\n",
    "##### Results for pycma, higher sigma0\n",
    "Runtime: 282.36 seconds, 10 steps, 28.24 seconds per step \\\n",
    "Optimal marginal Likelihood: -368.93, Estimated: -399.56, Initial -369.53\n",
    "|           |   rmse_A |   rmse_delta |   rmse_sigma |\n",
    "|:----------|---------:|-------------:|-------------:|\n",
    "| Estimated | 0.898735 |     0.48221  |     0.195257 |\n",
    "| Girth     | 1.79316  |     0.515695 |   nan        |\n",
    "| direct    | 0.458306 |     0.262779 |     0.139413 |\n",
    "| Initial   | 0.509902 |     0.273981 |     0.141421 |\n",
    "\n",
    "------------------------------------\n",
    "##### Results for Monte Carlo with seed\n",
    "Runtime: 97.6 seconds, 9 steps, 10.84 seconds per step \\\n",
    "Optimal marginal Likelihood: -376.79, Estimated: -399.07, Initial -372.28\n",
    "|           |      rmse_A |   rmse_delta |   rmse_sigma |\n",
    "|:----------|------------:|-------------:|-------------:|\n",
    "| Estimated |    1.09615  |     0.970204 |     0.120425 |\n",
    "| Girth     |    1.45372  |     0.34729  |     0.141421 |\n",
    "| direct    | 2935.78     |  1035.68     |     0.014461 |\n",
    "| Initial   |    0.509902 |     0.445143 |     0.141421 |\n",
    "\n",
    "------------------------------------\n",
    "##### Results for Monte Cralo with fixed sample per em-step\n",
    "Runtime: 1.22 seconds, 5 steps, 0.24 seconds per step \\\n",
    "Optimal marginal Likelihood: -381.06, Estimated: -373.26, Initial -377.69\n",
    "|           |   rmse_A |   rmse_delta |   rmse_sigma |\n",
    "|:----------|---------:|-------------:|-------------:|\n",
    "| Estimated | 0.500043 |     0.273166 |    0.0853068 |\n",
    "| Girth     | 0.98542  |     0.334766 |    0.141421  |\n",
    "| direct    | 0.57518  |     0.335156 |    0.0914744 |\n",
    "| Initial   | 0.509902 |     0.431741 |    0.141421  |\n",
    "\n",
    "------------------------------------\n",
    "##### Results for Newton Raphson of Q_0 with approximate second derivative\n",
    "Latent dimension: 2,  Item dimension: 6, sample size 100 \\\n",
    "Runtime: 2.2 seconds, 9 steps, 0.24 seconds per step \\\n",
    "Optimal marginal Likelihood: -389.58, Estimated: -375.96, Initial -386.41\n",
    "|               |   rmse_A |   rmse_delta |   rmse_sigma |\n",
    "|:--------------|---------:|-------------:|-------------:|\n",
    "| estimated     | 0.452731 |     0.428534 |     0.011738 |\n",
    "| early_initial | 0.509902 |     0.451316 |     0.212132 |\n",
    "| girth         | 1.54173  |     0.489318 |     0.164638 |\n",
    "| early_direct  | 1.10778  |     0.416042 |     0.189961 |\n",
    "\n",
    "------------------------------------\n",
    "##### Results for Quasi Monte-Carlo with increasing sample-size based on ttest'scipy\n",
    "Latent dimension: 2,  Item dimension: 6, sample size 100 \\\n",
    "Runtime: 589.08 seconds, 52 steps, 11.33 seconds per step \\\n",
    "Optimal marginal Likelihood: -371.52, Estimated: -366.22, Initial -373.6\n",
    "|               |   rmse_A |   rmse_delta |   rmse_sigma |\n",
    "|:--------------|---------:|-------------:|-------------:|\n",
    "| estimated     | 0.287802 |     0.302635 |    0.0019799 |\n",
    "| early_initial | 0.509902 |     0.292938 |    0.212132  |\n",
    "| girth         | 1.1188   |     0.385494 |    0.0478773 |\n",
    "| early_direct  | 0.282345 |     0.319402 |    0.0080443 |\n",
    "\n",
    "------------------------------------\n",
    "##### Results for Increasing Monte Carlo sample-size based on ttest with normal MC\n",
    "Latent dimension: 2,  Item dimension: 6, sample size 100 \\\n",
    "Runtime: 3.3 seconds, 15 steps, 0.22 seconds per step \\\n",
    "Optimal marginal Likelihood: -371.46, Estimated: -365.03, Initial -374.57\n",
    "|               |   rmse_A |   rmse_delta |   rmse_sigma |\n",
    "|:--------------|---------:|-------------:|-------------:|\n",
    "| estimated     | 0.660667 |     0.316008 |    0.0573464 |\n",
    "| early_initial | 0.509902 |     0.28936  |    0.212132  |\n",
    "| girth         | 1.0658   |     0.31617  |    0.12943   |\n",
    "| early_direct  | 0.848957 |     0.59659  |    0.116858  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procedure for better runtime\n",
    "\n",
    "1. Add Performance Benchmark (done)\n",
    "2. Add Vectorization to q_item (done)\n",
    "3. Add better Initialization (done)\n",
    "3. Add Vectorization to q_0 (done)\n",
    "4. Add q_0 Derivation 1. + BFGS (done)\n",
    "5. Add q_0 Derivation 2. + Newton Raphson\n",
    "6. Use cython (maybe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1: MIRT-2PL Parameter Recovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unittest import result\n",
    "\n",
    "def mirt_param_recovery(sample_size, item_dimension = 20, latent_dimension=3, q_type=\"seperated\", girth=True, stop_threshold=0.2, ensure_id=False, q_share=0.0) -> dict:\n",
    "    \n",
    "    #Simulate Responses\n",
    "    simulation = item_response_simulation(item_dimension=item_dimension, latent_dimension=latent_dimension)\n",
    "    parameter_dict = simulation.set_up(q_structure=q_type, q_share=q_share, ensure_id=ensure_id)\n",
    "    sample = simulation.sample(sample_size=sample_size)\n",
    "\n",
    "    #Define Population\n",
    "    #population = respondent_population(latent_dimension=latent_dimension)\n",
    "    real_latent_cov = parameter_dict[\"real_early_parameters\"][\"person_parameters\"][\"covariance\"]\n",
    "    print(\"Real latent covariance: {0}\".format(real_latent_cov))\n",
    "    \n",
    "\n",
    "    #Sample responses\n",
    "    #response_simulation_obj = response_simulation(population=population, item_dimension=item_dimension)\n",
    "    #response_simulation_obj.initialize_random_q_structured_matrix(structure=q_type, ensure_id=ensure_id)\n",
    "    #early_item_parameters = response_simulation_obj.initialize_random_item_parameters()\n",
    "    parameter_dict[\"real_early_parameters\"].update({\"item_dimension\": item_dimension, \"latent_dimension\": latent_dimension})\n",
    "    real_early_parameters = parameter_dict[\"real_early_parameters\"]#{\"item_parameters\": early_item_parameters, \"person_parameters\": {\"covariance\": real_latent_cov}}\n",
    "\n",
    "    #Fit Parameters\n",
    "    #Initialize model\n",
    "    model = models.mirt_2pl(latent_dimension=latent_dimension, item_dimension=item_dimension, Q=real_early_parameters[\"item_parameters\"][\"q_matrix\"])\n",
    "    print(\"Covariance matrix is good: {0}\".format(model.check_sigma(real_latent_cov)))\n",
    "    model.initialize_from_responses(response_data=sample[\"early_responses\"])\n",
    "    initial_early_parameters = model.get_parameters()\n",
    "    e_step = em_algorithm.e_step_ga_mml(model=model)\n",
    "    m_step = em_algorithm.m_step_ga_mml(model)\n",
    "    em = em_algorithm.em_algo(e_step=e_step, m_step=m_step, model=model)\n",
    "\n",
    "    #Fit Model\n",
    "    start_time = time.time()\n",
    "    em.fit(sample[\"early_responses\"], max_iter=100, stop_threshold=stop_threshold)\n",
    "    run_time =  (time.time() - start_time)\n",
    "\n",
    "    #Measure Performance\n",
    "    early_estimated_item_parameters = em.model.item_parameters\n",
    "    early_estimated_person_parameters = em.model.person_parameters\n",
    "\n",
    "    #Create Baselines\n",
    "    baselines = {\"early_initial\": {\"parameters\": initial_early_parameters}}\n",
    "    if girth==True:\n",
    "        baselines[\"girth\"] = {}\n",
    "\n",
    "    #Create results\n",
    "    early_estimated_parameters = em.model.get_parameters()\n",
    "\n",
    "    parameter_dict = create_parameter_dict(estimated_early_parameters=early_estimated_parameters,\n",
    "                          real_early_parameters = real_early_parameters,\n",
    "                          estimated_late_parameters=None, real_late_parameters=None)\n",
    "    run_dict = {\"early\": {\"runtime\": run_time,\n",
    "                \"number_steps\": em.n_steps}}\n",
    "    performance_dict = create_performance_dict(parameter_dict=parameter_dict, run_dict=run_dict, sample=sample, baselines=baselines, model=model)\n",
    "\n",
    "    return(performance_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real latent covariance: [[1.]]\n",
      "Covariance matrix is good: True\n",
      "EM Iteration 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jesper\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_qmc.py:2039: UserWarning: The balance properties of Sobol' points require n to be a power of 2.\n",
      "  samples = self.engine.random(n)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Monte Carlo Sample size: 150\n",
      "Step: 2: current parameter_diff: 22.742099580485075, current marginal loglikelihood: -8816.976449557947\n",
      "EM Iteration 3\n",
      "Current Monte Carlo Sample size: 165\n",
      "Step: 3: current parameter_diff: 10.719114330591957, current marginal loglikelihood: -8747.334230330345\n",
      "EM Iteration 4\n",
      "Current Monte Carlo Sample size: 165\n",
      "Step: 4: current parameter_diff: 4.741911411251834, current marginal loglikelihood: -8715.022616878563\n",
      "EM Iteration 5\n",
      "Current Monte Carlo Sample size: 165\n",
      "Step: 5: current parameter_diff: 1.8142332751245616, current marginal loglikelihood: -8712.134520806754\n",
      "EM Iteration 6\n",
      "Current Monte Carlo Sample size: 181\n",
      "Step: 6: current parameter_diff: 1.2343984015305836, current marginal loglikelihood: -8716.601796257768\n",
      "EM Iteration 7\n",
      "Current Monte Carlo Sample size: 199\n",
      "Step: 7: current parameter_diff: 1.691136460449655, current marginal loglikelihood: -8705.167502668424\n",
      "EM Iteration 8\n",
      "Current Monte Carlo Sample size: 199\n",
      "Step: 8: current parameter_diff: 0.2547466106287172, current marginal loglikelihood: -8700.162497959529\n",
      "EM Iteration 9\n",
      "Current Monte Carlo Sample size: 199\n",
      "Step: 9: current parameter_diff: 0.7355861538568866, current marginal loglikelihood: -8703.959490776922\n",
      "EM Iteration 10\n",
      "Current Monte Carlo Sample size: 199\n",
      "Step: 10: current parameter_diff: 0.1776645604785898, current marginal loglikelihood: -8704.337547876567\n",
      "EM Iteration 11\n",
      "Current Monte Carlo Sample size: 199\n",
      "Step: 11: current parameter_diff: 0.21422883852065394, current marginal loglikelihood: -8697.540415284748\n",
      "EM Iteration 12\n",
      "Current Monte Carlo Sample size: 199\n",
      "Step: 12: current parameter_diff: 0.41389714854448423, current marginal loglikelihood: -8701.266272287821\n",
      "EM Iteration 13\n",
      "Current Monte Carlo Sample size: 218\n",
      "Step: 13: current parameter_diff: 0.6380289667922019, current marginal loglikelihood: -8699.120577942349\n",
      "EM Iteration 14\n",
      "Current Monte Carlo Sample size: 239\n",
      "Step: 14: current parameter_diff: 0.18583090466334562, current marginal loglikelihood: -8700.498414285612\n",
      "EM Iteration 15\n",
      "Current Monte Carlo Sample size: 239\n",
      "Step: 15: current parameter_diff: 0.21416430038885137, current marginal loglikelihood: -8696.79514155463\n",
      "EM Iteration 16\n",
      "Current Monte Carlo Sample size: 262\n",
      "Step: 16: current parameter_diff: 0.1909580094424126, current marginal loglikelihood: -8702.14373481644\n",
      "EM Iteration 17\n",
      "Current Monte Carlo Sample size: 288\n",
      "Step: 17: current parameter_diff: 0.34105519931365746, current marginal loglikelihood: -8700.647419398761\n",
      "EM Iteration 18\n",
      "Current Monte Carlo Sample size: 316\n",
      "Step: 18: current parameter_diff: 0.04308677798857863, current marginal loglikelihood: -8699.933789661973\n",
      "EM Iteration 19\n",
      "Current Monte Carlo Sample size: 316\n",
      "Step: 19: current parameter_diff: 0.2024689513587688, current marginal loglikelihood: -8701.074678352565\n",
      "Absolute diff in A:\n",
      "[[0.1020642 ]\n",
      " [0.20663693]\n",
      " [0.03573951]\n",
      " [0.00609694]\n",
      " [0.06516089]\n",
      " [0.01231139]\n",
      " [0.19665506]\n",
      " [0.00442154]\n",
      " [0.15067377]\n",
      " [0.56588477]\n",
      " [0.06358961]\n",
      " [0.3477551 ]\n",
      " [0.07468231]\n",
      " [0.23280827]\n",
      " [0.14366572]\n",
      " [0.01964551]\n",
      " [0.11642367]\n",
      " [0.08059222]\n",
      " [0.02668696]\n",
      " [0.01302053]]\n",
      "Absolute diff in delta:\n",
      "[0.01372103 0.22600127 0.15797519 0.08365494 0.03256898 0.0999537\n",
      " 0.03129984 0.07269897 0.08900448 0.82638419 0.00167903 0.11498386\n",
      " 0.12192369 0.097956   0.15068923 0.06682692 0.09762189 0.14604488\n",
      " 0.04722096 0.04711922]\n",
      "Absolute diff in sigma:\n",
      "[[0.]]\n",
      "Absolute diff in A:\n",
      "[[0.50480738]\n",
      " [2.43900995]\n",
      " [0.72186482]\n",
      " [0.02314259]\n",
      " [0.799451  ]\n",
      " [0.77279166]\n",
      " [2.32243462]\n",
      " [3.07388443]\n",
      " [1.98502202]\n",
      " [3.35444471]\n",
      " [1.95801906]\n",
      " [3.47411164]\n",
      " [0.68078693]\n",
      " [1.19511503]\n",
      " [0.11594162]\n",
      " [0.48457238]\n",
      " [0.81020703]\n",
      " [0.04190402]\n",
      " [0.41282297]\n",
      " [0.79047423]]\n",
      "Absolute diff in delta:\n",
      "[0.15616958 2.07119572 0.19025844 0.13573243 1.20619844 0.06185352\n",
      " 0.92410513 1.27926034 2.15956441 5.28107992 0.57975271 0.13153789\n",
      " 0.40685445 1.39300472 0.98756327 0.61693666 0.53702806 0.08668895\n",
      " 0.02792248 0.04123975]\n",
      "Absolute diff in sigma:\n",
      "[[0.]]\n",
      "Absolute diff in A:\n",
      "[[2.83315462e-01 2.52385628e+00 1.12282671e+00 3.65691722e-01\n",
      "  5.42272713e-01 1.23571703e+00 2.37241685e+00 3.07591464e+00\n",
      "  1.99636962e+00 2.36348024e+00 1.81406166e+00 3.19221538e+00\n",
      "  2.65606562e-01 5.95141383e-01 1.45580546e-01 1.48689370e-01\n",
      "  5.91097731e-01 4.53287136e-01 8.21637537e-01 1.23228696e+00]\n",
      " [1.65088711e+00 5.89653704e-01 3.05702928e+00 2.29989430e+00\n",
      "  1.39192986e+00 3.16991961e+00 4.38214271e-01 1.14171206e+00\n",
      "  6.21670481e-02 4.29277667e-01 1.20140915e-01 1.25801281e+00\n",
      "  1.66859601e+00 1.33906119e+00 2.07978312e+00 1.78551321e+00\n",
      "  1.34310484e+00 2.38748971e+00 2.75584011e+00 3.16648953e+00]\n",
      " [1.50998766e+00 3.75052848e+00 1.03845490e-01 8.60980476e-01\n",
      "  1.76894491e+00 9.04483461e-03 3.59908904e+00 4.30258683e+00\n",
      "  3.22304182e+00 3.59015244e+00 3.04073386e+00 4.41888758e+00\n",
      "  1.49227876e+00 1.82181358e+00 1.08109165e+00 1.37536157e+00\n",
      "  1.81776993e+00 7.73385062e-01 4.05034661e-01 5.61476163e-03]\n",
      " [7.64980254e-01 3.00552107e+00 6.41161915e-01 1.15973070e-01\n",
      "  1.02393751e+00 7.54052240e-01 2.85408164e+00 3.55757943e+00\n",
      "  2.47803442e+00 2.84514503e+00 2.29572645e+00 3.67388017e+00\n",
      "  7.47271354e-01 1.07680618e+00 3.36084247e-01 6.30354162e-01\n",
      "  1.07276252e+00 2.83776562e-02 3.39972744e-01 7.50622167e-01]\n",
      " [1.13281560e-02 2.22921266e+00 1.41747033e+00 6.60335340e-01\n",
      "  2.47629095e-01 1.53036065e+00 2.07777323e+00 2.78127102e+00\n",
      "  1.70172601e+00 2.06883662e+00 1.51941804e+00 2.89757176e+00\n",
      "  2.90370560e-02 3.00497766e-01 4.40224163e-01 1.45954248e-01\n",
      "  2.96454113e-01 7.47930754e-01 1.11628115e+00 1.52693058e+00]\n",
      " [1.56091450e+00 3.80145532e+00 1.54772332e-01 9.11907317e-01\n",
      "  1.81987175e+00 4.18820069e-02 3.65001589e+00 4.35351368e+00\n",
      "  3.27396866e+00 3.64107928e+00 3.09166070e+00 4.46981442e+00\n",
      "  1.54320560e+00 1.87274042e+00 1.13201849e+00 1.42628841e+00\n",
      "  1.86869677e+00 8.24311903e-01 4.55961503e-01 4.53120799e-02]\n",
      " [1.53431178e+00 7.06229034e-01 2.94045395e+00 2.18331897e+00\n",
      "  1.27535453e+00 3.05334428e+00 5.54789602e-01 1.25828739e+00\n",
      "  1.78742378e-01 5.45852997e-01 3.56558494e-03 1.37458814e+00\n",
      "  1.55202068e+00 1.22248586e+00 1.96320779e+00 1.66893787e+00\n",
      "  1.22652951e+00 2.27091438e+00 2.63926478e+00 3.04991420e+00]\n",
      " [2.28576159e+00 4.52207736e-02 3.69190376e+00 2.93476877e+00\n",
      "  2.02680434e+00 3.80479408e+00 1.96660206e-01 5.06837585e-01\n",
      "  5.72707429e-01 2.05596810e-01 7.55015392e-01 6.23138330e-01\n",
      "  2.30347049e+00 1.97393567e+00 2.71465760e+00 2.42038768e+00\n",
      "  1.97797932e+00 3.02236419e+00 3.39071459e+00 3.80136401e+00]\n",
      " [1.19689918e+00 1.04364164e+00 2.60304135e+00 1.84590636e+00\n",
      "  9.37941926e-01 2.71593167e+00 8.92202207e-01 1.59570000e+00\n",
      "  5.16154984e-01 8.83265603e-01 3.33847021e-01 1.71200074e+00\n",
      "  1.21460808e+00 8.85073256e-01 1.62579518e+00 1.33152527e+00\n",
      "  8.89116908e-01 1.93350178e+00 2.30185218e+00 2.71250160e+00]\n",
      " [2.56632187e+00 3.25781055e-01 3.97246404e+00 3.21532906e+00\n",
      "  2.30736462e+00 4.08535437e+00 4.77220487e-01 2.26277303e-01\n",
      "  8.53267710e-01 4.86157091e-01 1.03557567e+00 3.42578049e-01\n",
      "  2.58403077e+00 2.25449595e+00 2.99521788e+00 2.70094796e+00\n",
      "  2.25853960e+00 3.30292447e+00 3.67127487e+00 4.08192429e+00]\n",
      " [1.16989622e+00 1.07064459e+00 2.57603839e+00 1.81890341e+00\n",
      "  9.10938973e-01 2.68892872e+00 9.19205160e-01 1.62270295e+00\n",
      "  5.43157937e-01 9.10268556e-01 3.60849974e-01 1.73900370e+00\n",
      "  1.18760512e+00 8.58070302e-01 1.59879223e+00 1.30452232e+00\n",
      "  8.62113955e-01 1.90649882e+00 2.27484922e+00 2.68549865e+00]\n",
      " [2.68598880e+00 4.45447988e-01 4.09213097e+00 3.33499599e+00\n",
      "  2.42703155e+00 4.20502130e+00 5.96887420e-01 1.06610370e-01\n",
      "  9.72934643e-01 6.05824024e-01 1.15524261e+00 2.22911116e-01\n",
      "  2.70369770e+00 2.37416288e+00 3.11488481e+00 2.82061490e+00\n",
      "  2.37820654e+00 3.42259140e+00 3.79094180e+00 4.20159123e+00]\n",
      " [1.07335910e-01 2.34787673e+00 1.29880626e+00 5.41671275e-01\n",
      "  3.66293160e-01 1.41169658e+00 2.19643729e+00 2.89993508e+00\n",
      "  1.82039007e+00 2.18750069e+00 1.63808211e+00 3.01623583e+00\n",
      "  8.96270096e-02 4.19161831e-01 3.21560098e-01 2.72901826e-02\n",
      "  4.15118178e-01 6.29266689e-01 9.97617089e-01 1.40826651e+00]\n",
      " [4.06992192e-01 1.83354862e+00 1.81313436e+00 1.05599938e+00\n",
      "  1.48034941e-01 1.92602469e+00 1.68210919e+00 2.38560698e+00\n",
      "  1.30606197e+00 1.67317259e+00 1.12375401e+00 2.50190773e+00\n",
      "  4.24701092e-01 9.51662703e-02 8.35888199e-01 5.41618284e-01\n",
      "  9.92099232e-02 1.14359479e+00 1.51194519e+00 1.92259461e+00]\n",
      " [6.72181222e-01 2.91272204e+00 7.33960948e-01 2.31740377e-02\n",
      "  9.31138473e-01 8.46851273e-01 2.76128261e+00 3.46478040e+00\n",
      "  2.38523538e+00 2.75234600e+00 2.20292742e+00 3.58108114e+00\n",
      "  6.54472322e-01 9.84007143e-01 2.43285214e-01 5.37555130e-01\n",
      "  9.79963490e-01 6.44213764e-02 4.32771777e-01 8.43421200e-01]\n",
      " [3.03550464e-01 2.54409128e+00 1.10259171e+00 3.45456720e-01\n",
      "  5.62507715e-01 1.21548203e+00 2.39265185e+00 3.09614964e+00\n",
      "  2.01660463e+00 2.38371524e+00 1.83429666e+00 3.21245038e+00\n",
      "  2.85841564e-01 6.15376386e-01 1.25345543e-01 1.68924372e-01\n",
      "  6.11332733e-01 4.33052134e-01 8.01402535e-01 1.21205196e+00]\n",
      " [2.20841859e-02 2.21845663e+00 1.42822636e+00 6.71091370e-01\n",
      "  2.36873065e-01 1.54111668e+00 2.06701720e+00 2.77051499e+00\n",
      "  1.69096998e+00 2.05808059e+00 1.50866201e+00 2.88681573e+00\n",
      "  3.97930858e-02 2.89741736e-01 4.50980193e-01 1.56710278e-01\n",
      "  2.85698083e-01 7.58686784e-01 1.12703718e+00 1.53768661e+00]\n",
      " [7.46218818e-01 2.98675963e+00 6.59923352e-01 9.72116343e-02\n",
      "  1.00517607e+00 7.72813676e-01 2.83532020e+00 3.53881799e+00\n",
      "  2.45927298e+00 2.82638360e+00 2.27696502e+00 3.65511874e+00\n",
      "  7.28509918e-01 1.05804474e+00 3.17322811e-01 6.11592726e-01\n",
      "  1.05400109e+00 9.61622017e-03 3.58734180e-01 7.69383603e-01]\n",
      " [1.20094581e+00 3.44148663e+00 2.05196359e-01 5.51938627e-01\n",
      "  1.45990306e+00 3.18086683e-01 3.29004720e+00 3.99354499e+00\n",
      "  2.91399997e+00 3.28111059e+00 2.73169201e+00 4.10984573e+00\n",
      "  1.18323691e+00 1.51277173e+00 7.72049804e-01 1.06631972e+00\n",
      "  1.50872808e+00 4.64343213e-01 9.59928126e-02 3.14656610e-01]\n",
      " [1.57859707e+00 3.81913788e+00 1.72454898e-01 9.29589884e-01\n",
      "  1.83755432e+00 5.95645737e-02 3.66769845e+00 4.37119624e+00\n",
      "  3.29165123e+00 3.65876185e+00 3.10934327e+00 4.48749699e+00\n",
      "  1.56088817e+00 1.89042299e+00 1.14970106e+00 1.44397098e+00\n",
      "  1.88637934e+00 8.41994470e-01 4.73644069e-01 6.29946467e-02]]\n",
      "Absolute diff in delta:\n",
      "[ 0.77344167  4.5549703   2.61555196  0.74218763  5.57953818  0.60306861\n",
      "  1.88311089  2.32237103  5.29802624 10.85938753  1.37623527  0.33278386\n",
      "  1.52695777  5.42298212  9.03860879  3.05158686  2.42797565  0.46596383\n",
      "  2.10923878  2.70002748]\n",
      "Absolute diff in sigma:\n",
      "[[0.]]\n"
     ]
    }
   ],
   "source": [
    "#Univariate IRT Recovery\n",
    "result_dict = mirt_param_recovery(1000, q_type=\"singular\", item_dimension=20, latent_dimension=1, stop_threshold=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "##### Results for Monte Carlo sample varying through ttest with normal MC\n",
      "Latent dimension: 1,  Item dimension: 20, sample size 1000 \\\n",
      "Runtime: 37.86 seconds, 20 steps, 1.89 seconds per step \\\n",
      "Optimal marginal Likelihood: -8714.19, Estimated: -8697.21, Initial -9512.15\n",
      "|               |   rmse_A |   rmse_delta |   rmse_sigma |\n",
      "|:--------------|---------:|-------------:|-------------:|\n",
      "| estimated     | 0.182642 |     0.211132 |            0 |\n",
      "| early_initial | 1.69549  |     1.49975  |            0 |\n",
      "| girth         | 0.313235 |     4.2295   |            0 |\n"
     ]
    }
   ],
   "source": [
    "print_result(result_dict, \"Monte Carlo sample varying through ttest with normal MC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate IRT/Full GA\n",
    "\n",
    "------------------------------------\n",
    "##### Item Dimension=12, sample_size=200: Results for Fixed sample per em-step\n",
    "Runtime: 4.38 seconds, 7 steps, 0.63 seconds per step \\\n",
    "Optimal marginal Likelihood: -1284.1, Estimated: -1273.09, Initial -1330.43\n",
    "|           |   rmse_A |   rmse_delta |   rmse_sigma |\n",
    "|:----------|---------:|-------------:|-------------:|\n",
    "| Estimated | 0.508687 |     0.196944 |            0 |\n",
    "| Girth     | 0.377882 |     2.65875  |            0 |\n",
    "| direct    | 0.305489 |     0.318168 |            0 |\n",
    "| Initial   | 1.5583   |     0.861273 |            0 |\n",
    "\n",
    "------------------------------------\n",
    "##### Item Dimension=20, sample_size=1000: Results for Fixed sample per em-step\n",
    "Runtime: 85.11 seconds, 19 steps, 4.48 seconds per step \\\n",
    "Optimal marginal Likelihood: -9199.01, Estimated: -9183.03, Initial -9784.69\n",
    "|           |   rmse_A |   rmse_delta |   rmse_sigma |\n",
    "|:----------|---------:|-------------:|-------------:|\n",
    "| Estimated | 0.352003 |     0.578688 |            0 |\n",
    "| Girth     | 0.468473 |     4.98511  |            0 |\n",
    "| Initial   | 1.66615  |     2.01114  |            0 |\n",
    "\n",
    "------------------------------------\n",
    "##### Results for Monte Carlo sample varying through ttest\n",
    "Latent dimension: 1,  Item dimension: 20, sample size 1000 \\\n",
    "Runtime: 31.86 seconds, 10 steps, 3.19 seconds per step \\\n",
    "Optimal marginal Likelihood: -9619.61, Estimated: -9601.49, Initial -9970.74\n",
    "|               |   rmse_A |   rmse_delta |   rmse_sigma |\n",
    "|:--------------|---------:|-------------:|-------------:|\n",
    "| estimated     | 0.175897 |     0.223543 |            0 |\n",
    "| early_initial | 1.21508  |     1.78456  |            0 |\n",
    "| girth         | 0.327131 |     4.71968  |            0 |\n",
    "\n",
    "------------------------------------\n",
    "##### Results for Monte Carlo sample varying through ttest with normal MC\n",
    "Latent dimension: 1,  Item dimension: 20, sample size 1000 \\\n",
    "Runtime: 37.86 seconds, 20 steps, 1.89 seconds per step \\\n",
    "Optimal marginal Likelihood: -8714.19, Estimated: -8697.21, Initial -9512.15\n",
    "|               |   rmse_A |   rmse_delta |   rmse_sigma |\n",
    "|:--------------|---------:|-------------:|-------------:|\n",
    "| estimated     | 0.182642 |     0.211132 |            0 |\n",
    "| early_initial | 1.69549  |     1.49975  |            0 |\n",
    "| girth         | 0.313235 |     4.2295   |            0 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real latent covariance: [[1.     0.1921]\n",
      " [0.1921 1.    ]]\n",
      "Covariance matrix is good: True\n",
      "EM Iteration 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jesper\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_qmc.py:2039: UserWarning: The balance properties of Sobol' points require n to be a power of 2.\n",
      "  samples = self.engine.random(n)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Monte Carlo Sample size: 300\n",
      "Step: 2: current parameter_diff: 9.087457477954748, current marginal loglikelihood: -12789.826209045792\n",
      "EM Iteration 3\n",
      "Current Monte Carlo Sample size: 300\n",
      "Step: 3: current parameter_diff: 9.347286786290436, current marginal loglikelihood: -12431.792159340152\n",
      "EM Iteration 4\n",
      "Current Monte Carlo Sample size: 300\n",
      "Step: 4: current parameter_diff: 5.994195183510891, current marginal loglikelihood: -12324.415808814525\n",
      "EM Iteration 5\n",
      "Current Monte Carlo Sample size: 330\n",
      "Step: 5: current parameter_diff: 3.466965558217997, current marginal loglikelihood: -12291.666326556195\n",
      "EM Iteration 6\n",
      "Current Monte Carlo Sample size: 363\n",
      "Step: 6: current parameter_diff: 3.0517259450824583, current marginal loglikelihood: -12274.293408739399\n",
      "EM Iteration 7\n",
      "Current Monte Carlo Sample size: 399\n",
      "Step: 7: current parameter_diff: 1.6828800520798761, current marginal loglikelihood: -12268.44295499595\n",
      "EM Iteration 8\n",
      "Current Monte Carlo Sample size: 438\n",
      "Step: 8: current parameter_diff: 1.5472995648012011, current marginal loglikelihood: -12266.741491100976\n",
      "EM Iteration 9\n",
      "Current Monte Carlo Sample size: 481\n",
      "Step: 9: current parameter_diff: 0.9405471813539303, current marginal loglikelihood: -12257.26354486137\n",
      "EM Iteration 10\n",
      "Current Monte Carlo Sample size: 529\n",
      "Step: 10: current parameter_diff: 0.5530337635868852, current marginal loglikelihood: -12254.874420202255\n",
      "EM Iteration 11\n",
      "Current Monte Carlo Sample size: 581\n",
      "Step: 11: current parameter_diff: 0.9182088621850061, current marginal loglikelihood: -12252.639608779638\n",
      "EM Iteration 12\n",
      "Current Monte Carlo Sample size: 581\n",
      "Step: 12: current parameter_diff: 0.6457048580426479, current marginal loglikelihood: -12250.319820728353\n",
      "EM Iteration 13\n",
      "Current Monte Carlo Sample size: 581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jesper\\Documents\\GitHub\\Knowledge-Growth-Prediction\\em_algorithm\\e_step_mirt_2pl.py:264: RuntimeWarning: divide by zero encountered in log\n",
      "  icc_values), r_item_theta) + np.multiply(np.log(1-icc_values), np.subtract(r_0_theta, r_item_theta))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 13: current parameter_diff: 0.40565533319178126, current marginal loglikelihood: -12248.475980359144\n",
      "EM Iteration 14\n",
      "Current Monte Carlo Sample size: 581\n",
      "Step: 14: current parameter_diff: 0.3981727860081429, current marginal loglikelihood: -12251.628743992456\n",
      "EM Iteration 15\n",
      "Current Monte Carlo Sample size: 639\n",
      "Step: 15: current parameter_diff: 0.3759899463682548, current marginal loglikelihood: -12251.09622265484\n",
      "EM Iteration 16\n",
      "Current Monte Carlo Sample size: 702\n",
      "Step: 16: current parameter_diff: 0.07730277535592268, current marginal loglikelihood: -12250.114423241039\n",
      "EM Iteration 17\n",
      "Current Monte Carlo Sample size: 772\n",
      "Step: 17: current parameter_diff: 0.35397135818851444, current marginal loglikelihood: -12249.62312895641\n",
      "Absolute diff in A:\n",
      "[[ 0.14141196  0.        ]\n",
      " [ 0.14652275  0.        ]\n",
      " [ 0.24777834  0.        ]\n",
      " [ 0.39441549  0.        ]\n",
      " [ 0.12016762  0.        ]\n",
      " [ 0.32373102  0.        ]\n",
      " [ 2.04123377  0.        ]\n",
      " [ 0.07098307  0.        ]\n",
      " [ 0.06713308  0.        ]\n",
      " [ 0.          0.20182688]\n",
      " [ 0.          0.62813809]\n",
      " [ 0.          0.09920095]\n",
      " [ 0.          0.01945836]\n",
      " [ 0.          0.18659965]\n",
      " [ 0.          0.15575047]\n",
      " [ 0.          0.08789252]\n",
      " [ 0.          1.4778765 ]\n",
      " [ 0.          0.04189966]\n",
      " [ 0.         10.97192658]\n",
      " [ 0.          0.01780647]]\n",
      "Absolute diff in delta:\n",
      "[0.11951806 0.01624619 0.00828051 0.00229788 0.03779432 0.12022373\n",
      " 0.3486814  0.00835183 0.058682   0.13972121 0.09226136 0.03582283\n",
      " 0.07487817 0.05699409 0.08076706 0.08706214 0.40613611 0.01579479\n",
      " 1.00325414 0.03622401]\n",
      "Absolute diff in sigma:\n",
      "[[0.     0.0592]\n",
      " [0.0592 0.    ]]\n",
      "Absolute diff in A:\n",
      "[[ 1.36526825  0.        ]\n",
      " [ 1.11545869  0.        ]\n",
      " [ 1.73464119  0.        ]\n",
      " [ 1.36717029  0.        ]\n",
      " [ 0.86321887  0.        ]\n",
      " [ 1.3189492   0.        ]\n",
      " [ 7.95629842  0.        ]\n",
      " [ 0.25893288  0.        ]\n",
      " [ 0.90547762  0.        ]\n",
      " [ 0.          3.59522736]\n",
      " [ 0.          1.62115369]\n",
      " [ 0.          0.60013944]\n",
      " [ 0.          0.69561718]\n",
      " [ 0.          3.18601677]\n",
      " [ 0.          0.67271571]\n",
      " [ 0.          0.01684306]\n",
      " [ 0.          2.47056086]\n",
      " [ 0.          2.57133627]\n",
      " [ 0.         11.96739471]\n",
      " [ 0.          0.77011617]]\n",
      "Absolute diff in delta:\n",
      "[0.06091239 0.02035124 0.864845   0.03297919 0.0250019  0.13604297\n",
      " 1.95588372 0.02782104 0.03300903 2.77138941 0.09108795 0.05574691\n",
      " 0.08273561 0.12214658 0.05284058 0.0228591  0.39977876 0.28998553\n",
      " 1.02811303 0.1957758 ]\n",
      "Absolute diff in sigma:\n",
      "[[0.     0.3079]\n",
      " [0.3079 0.    ]]\n"
     ]
    }
   ],
   "source": [
    "performance_dict = mirt_param_recovery(sample_size=1000, item_dimension=20, latent_dimension=2, q_type=\"seperated\", girth=False, stop_threshold=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "##### Results for Fixed Issue with simulation Covariance\n",
      "Latent dimension: 2,  Item dimension: 20, sample size 1000 \\\n",
      "Runtime: 51.07 seconds, 18 steps, 2.84 seconds per step \\\n",
      "Optimal marginal Likelihood: -11670.7, Estimated: -12247.32, Initial -13560.2\n",
      "|               |   rmse_A |   rmse_delta |   rmse_sigma |\n",
      "|:--------------|---------:|-------------:|-------------:|\n",
      "| estimated     |  1.78631 |     0.262764 |    0.0418607 |\n",
      "| early_initial |  2.54062 |     0.826317 |    0.217718  |\n"
     ]
    }
   ],
   "source": [
    "print_result(performance_dict, \"Fixed Issue with simulation Covariance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------\n",
    "##### Results for Seperated Q-Matrix\n",
    "Latent dimension: 2,  Item dimension: 20, sample size 1000 \\\n",
    "Runtime: 142.07 seconds, 26 steps, 5.46 seconds per step \\\n",
    "Optimal marginal Likelihood: -9384.38, Estimated: -10189.47, Initial -11459.9\n",
    "|               |   rmse_A |   rmse_delta |   rmse_sigma |\n",
    "|:--------------|---------:|-------------:|-------------:|\n",
    "| estimated     |  4.00013 |      3.10678 |    0.0201383 |\n",
    "| early_initial |  4.5183  |      2.5846  |    0.165491  |\n",
    "\n",
    "------------------------------------\n",
    "##### Results for BFGS for Q_0 with approximate Jacobi\n",
    "Latent dimension: 2,  Item dimension: 20, sample size 1000 \\\n",
    "Runtime: 61.55 seconds, 12 steps, 5.13 seconds per step \\\n",
    "Optimal marginal Likelihood: -9363.89, Estimated: -9711.58, Initial -10528.79\n",
    "|               |   rmse_A |   rmse_delta |   rmse_sigma |\n",
    "|:--------------|---------:|-------------:|-------------:|\n",
    "| estimated     |  3.02507 |      1.83482 |    0.0645047 |\n",
    "| early_initial |  2.06432 |      2.18337 |    0.289049  |\n",
    "\n",
    "------------------------------------\n",
    "##### Results for Monte Carlo sample varying through ttest\n",
    "Latent dimension: 2,  Item dimension: 20, sample size 1000 \\\n",
    "Runtime: 325.73 seconds, 42 steps, 7.76 seconds per step \\\n",
    "Optimal marginal Likelihood: -9929.77, Estimated: -10179.96, Initial -10767.41\n",
    "|               |   rmse_A |   rmse_delta |   rmse_sigma |\n",
    "|:--------------|---------:|-------------:|-------------:|\n",
    "| estimated     |  1.25777 |     0.965894 |   0.00557421 |\n",
    "| early_initial |  1.98812 |     1.68516  |   0.719705   |\n",
    "\n",
    "------------------------------------\n",
    "##### Results for Fixed random Covariance 1, girth included\n",
    "Latent dimension: 2,  Item dimension: 20, sample size 1000 \\\n",
    "Runtime: 57.16 seconds, 14 steps, 4.08 seconds per step \\\n",
    "Optimal marginal Likelihood: -11668.66, Estimated: -11672.6, Initial -12307.41\n",
    "|               |   rmse_A |   rmse_delta |   rmse_sigma |\n",
    "|:--------------|---------:|-------------:|-------------:|\n",
    "| estimated     | 0.183251 |    0.0861252 |    0.0215108 |\n",
    "| early_initial | 0.786712 |    0.393667  |    0.0471788 |\n",
    "| girth         | 1.28298  |    0.263374  |    0.350541  |\n",
    "\n",
    "------------------------------------\n",
    "##### Results for Fixed Issue with simulation Covariance\n",
    "Latent dimension: 2,  Item dimension: 20, sample size 1000 \\\n",
    "Runtime: 24.71 seconds, 11 steps, 2.25 seconds per step \\\n",
    "Optimal marginal Likelihood: -11186.38, Estimated: -11389.57, Initial -12010.77\n",
    "|               |   rmse_A |   rmse_delta |   rmse_sigma |\n",
    "|:--------------|---------:|-------------:|-------------:|\n",
    "| estimated     |  1.83766 |      1.4664  |    0.0743169 |\n",
    "| early_initial |  2.7041  |      2.66224 |    0.0627911 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real latent covariance: [[1.     0.5392 0.4093]\n",
      " [0.5392 1.     0.5406]\n",
      " [0.4093 0.5406 1.    ]]\n",
      "Covariance matrix is good: True\n",
      "EM Iteration 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jesper\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_qmc.py:2039: UserWarning: The balance properties of Sobol' points require n to be a power of 2.\n",
      "  samples = self.engine.random(n)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Monte Carlo Sample size: 600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jesper\\Documents\\GitHub\\Knowledge-Growth-Prediction\\em_algorithm\\e_step_mirt_2pl.py:198: RuntimeWarning: divide by zero encountered in log\n",
      "  factor = np.log(self.model.latent_density(theta, sigma=sigma))\n",
      "c:\\Users\\Jesper\\Documents\\GitHub\\Knowledge-Growth-Prediction\\em_algorithm\\e_step_mirt_2pl.py:198: RuntimeWarning: divide by zero encountered in log\n",
      "  factor = np.log(self.model.latent_density(theta, sigma=sigma))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.22255116 0.4851635 ]\n",
      " [0.22255116 1.         0.28710379]\n",
      " [0.4851635  0.28710379 1.        ]]\n",
      "Step: 2: current parameter_diff: 22.836966115835242, current marginal loglikelihood: -11263.404209075177\n",
      "EM Iteration 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jesper\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_qmc.py:2039: UserWarning: The balance properties of Sobol' points require n to be a power of 2.\n",
      "  samples = self.engine.random(n)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Monte Carlo Sample size: 600\n",
      "[[1.         0.03209561 0.46728994]\n",
      " [0.03209561 1.         0.18680867]\n",
      " [0.46728994 0.18680867 1.        ]]\n",
      "Step: 3: current parameter_diff: 12.765040130244333, current marginal loglikelihood: -11025.095432664773\n",
      "EM Iteration 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jesper\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_qmc.py:2039: UserWarning: The balance properties of Sobol' points require n to be a power of 2.\n",
      "  samples = self.engine.random(n)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Monte Carlo Sample size: 660\n",
      "[[ 1.         -0.12237363  0.46206731]\n",
      " [-0.12237363  1.          0.13165586]\n",
      " [ 0.46206731  0.13165586  1.        ]]\n",
      "Step: 4: current parameter_diff: 11.082485951986573, current marginal loglikelihood: -10917.861640370744\n",
      "EM Iteration 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jesper\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_qmc.py:2039: UserWarning: The balance properties of Sobol' points require n to be a power of 2.\n",
      "  samples = self.engine.random(n)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Monte Carlo Sample size: 726\n",
      "[[ 1.         -0.13268712  0.46966192]\n",
      " [-0.13268712  1.          0.07677147]\n",
      " [ 0.46966192  0.07677147  1.        ]]\n",
      "Step: 5: current parameter_diff: 5.054700187758239, current marginal loglikelihood: -10871.624165962843\n",
      "EM Iteration 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jesper\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_qmc.py:2039: UserWarning: The balance properties of Sobol' points require n to be a power of 2.\n",
      "  samples = self.engine.random(n)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Monte Carlo Sample size: 798\n",
      "[[ 1.         -0.15335902  0.48429796]\n",
      " [-0.15335902  1.          0.00857838]\n",
      " [ 0.48429796  0.00857838  1.        ]]\n",
      "Step: 6: current parameter_diff: 7.350049766942949, current marginal loglikelihood: -10846.63925009043\n",
      "EM Iteration 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jesper\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_qmc.py:2039: UserWarning: The balance properties of Sobol' points require n to be a power of 2.\n",
      "  samples = self.engine.random(n)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Monte Carlo Sample size: 877\n",
      "[[ 1.         -0.18130942  0.49736388]\n",
      " [-0.18130942  1.         -0.04688012]\n",
      " [ 0.49736388 -0.04688012  1.        ]]\n",
      "Step: 7: current parameter_diff: 4.21590743744123, current marginal loglikelihood: -10830.644137405307\n",
      "EM Iteration 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jesper\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_qmc.py:2039: UserWarning: The balance properties of Sobol' points require n to be a power of 2.\n",
      "  samples = self.engine.random(n)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Monte Carlo Sample size: 964\n",
      "[[ 1.         -0.15152568  0.50240847]\n",
      " [-0.15152568  1.         -0.07665482]\n",
      " [ 0.50240847 -0.07665482  1.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jesper\\Documents\\GitHub\\Knowledge-Growth-Prediction\\em_algorithm\\e_step_mirt_2pl.py:264: RuntimeWarning: divide by zero encountered in log\n",
      "  icc_values), r_item_theta) + np.multiply(np.log(1-icc_values), np.subtract(r_0_theta, r_item_theta))\n",
      "c:\\Users\\Jesper\\Documents\\GitHub\\Knowledge-Growth-Prediction\\em_algorithm\\e_step_mirt_2pl.py:264: RuntimeWarning: invalid value encountered in multiply\n",
      "  icc_values), r_item_theta) + np.multiply(np.log(1-icc_values), np.subtract(r_0_theta, r_item_theta))\n",
      "c:\\Users\\Jesper\\Documents\\GitHub\\Knowledge-Growth-Prediction\\em_algorithm\\m_step_mirt_2pl.py:70: RuntimeWarning: overflow encountered in exp\n",
      "  population = random.choices(population=population_base, weights=np.exp(\n"
     ]
    }
   ],
   "source": [
    "performance_dict = mirt_param_recovery(sample_size=1000, item_dimension=20, latent_dimension=3, q_type=\"pyramid\", girth=False, stop_threshold=10, ensure_id=True, q_share=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'performance_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Jesper\\Documents\\GitHub\\Knowledge-Growth-Prediction\\simulation_experiments.ipynb Zelle 21\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Jesper/Documents/GitHub/Knowledge-Growth-Prediction/simulation_experiments.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m print_result(performance_dict, \u001b[39m\"\u001b[39m\u001b[39mWith Covariance Matrix partially aligned to Q-matrix\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'performance_dict' is not defined"
     ]
    }
   ],
   "source": [
    "print_result(performance_dict, \"With Covariance Matrix partially aligned to Q-matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------\n",
    "##### Results for Pyramid Q-Matrix\n",
    "Latent dimension: 3,  Item dimension: 20, sample size 200 \\\n",
    "Runtime: 121.22 seconds, 46 steps, 2.64 seconds per step \\\n",
    "Optimal marginal Likelihood: -2144.15, Estimated: -2155.08, Initial -2699.63\n",
    "|               |   rmse_A |   rmse_delta |   rmse_sigma |\n",
    "|:--------------|---------:|-------------:|-------------:|\n",
    "| estimated     |  11.0034 |      1.77461 |     0.889828 |\n",
    "| early_initial |  10.5116 |      2.15986 |     0.522199 |\n",
    "\n",
    "------------------------------------\n",
    "##### Results for Pyramid Q-Matrix\n",
    "Latent dimension: 3,  Item dimension: 20, sample size 1000 \\\n",
    "Runtime: 313.22 seconds, 51 steps, 6.14 seconds per step \\\n",
    "Optimal marginal Likelihood: -9452.24, Estimated: -9813.87, Initial -11216.48\n",
    "|               |   rmse_A |   rmse_delta |   rmse_sigma |\n",
    "|:--------------|---------:|-------------:|-------------:|\n",
    "| estimated     |  5.34115 |      1.4068  |     0.425982 |\n",
    "| early_initial |  5.98238 |      2.25109 |     0.234288 |\n",
    "\n",
    "------------------------------------\n",
    "##### Results for Pyramid Q-Matrix\n",
    "Latent dimension: 3,  Item dimension: 30, sample size 2000 \\\n",
    "Runtime: 1521.51 seconds, 76 steps, 20.02 seconds per step \\\n",
    "Optimal marginal Likelihood: -30844.13, Estimated: -32521.34, Initial -37390.6\n",
    "|               |   rmse_A |   rmse_delta |   rmse_sigma |\n",
    "|:--------------|---------:|-------------:|-------------:|\n",
    "| estimated     |  2.55959 |       1.9952 |    0.314331  |\n",
    "| early_initial |  3.32034 |       3.514  |    0.0239562 |\n",
    "\n",
    "------------------------------------\n",
    "##### Results for BFGS for Q_0 with approximated gradient\n",
    "Latent dimension: 3,  Item dimension: 20, sample size 1000 \\\n",
    "Runtime: 350.28 seconds, 64 steps, 5.47 seconds per step \\\n",
    "Optimal marginal Likelihood: -10498.87, Estimated: -11303.0, Initial -12740.14\n",
    "|               |   rmse_A |   rmse_delta |   rmse_sigma |\n",
    "|:--------------|---------:|-------------:|-------------:|\n",
    "| estimated     |  10.2704 |     0.68597  |    0.318713  |\n",
    "| early_initial |  10.4626 |     0.846172 |    0.0895367 |\n",
    "\n",
    "------------------------------------\n",
    "##### Results for BFGS for Q_0 with exact gradient\n",
    "Latent dimension: 3,  Item dimension: 20, sample size 1000 \\\n",
    "Runtime: 152.91 seconds, 31 steps, 4.93 seconds per step \\\n",
    "Optimal marginal Likelihood: -11106.69, Estimated: -11211.51, Initial -12370.23\n",
    "|               |   rmse_A |   rmse_delta |   rmse_sigma |\n",
    "|:--------------|---------:|-------------:|-------------:|\n",
    "| estimated     |  3.5074  |      2.54509 |     0.21123  |\n",
    "| early_initial |  3.51819 |      2.66313 |     0.319647 |\n",
    "\n",
    "------------------------------------\n",
    "##### Results for Newton-Raphson for Q_0 with approximated second derivative\n",
    "Latent dimension: 3,  Item dimension: 20, sample size 1000 \\\n",
    "Runtime: 352.93 seconds, 62 steps, 5.69 seconds per step \\\n",
    "Optimal marginal Likelihood: -10237.22, Estimated: -10482.36, Initial -12569.49\n",
    "|               |   rmse_A |   rmse_delta |   rmse_sigma |\n",
    "|:--------------|---------:|-------------:|-------------:|\n",
    "| estimated     |  5.23694 |      2.45127 |     0.508499 |\n",
    "| early_initial |  5.36172 |      3.29141 |     0.640209 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real latent covariance: [[1.     0.     0.2545]\n",
      " [0.     1.     0.3721]\n",
      " [0.2545 0.3721 1.    ]]\n",
      "Covariance matrix is good: True\n",
      "EM Iteration 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jesper\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_qmc.py:2039: UserWarning: The balance properties of Sobol' points require n to be a power of 2.\n",
      "  samples = self.engine.random(n)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Monte Carlo Sample size: 600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jesper\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\_numdiff.py:576: RuntimeWarning: invalid value encountered in subtract\n",
      "  df = fun(x) - f0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "[[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "Invalid Covariance encountered, trying last step covariance\n",
      "Step: 2: current parameter_diff: 41.855085339761395, current marginal loglikelihood: -12550.72345228223\n",
      "EM Iteration 3\n",
      "Current Monte Carlo Sample size: 660\n",
      "[[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "[[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "Invalid Covariance encountered, trying last step covariance\n",
      "Step: 3: current parameter_diff: 28.922785136715092, current marginal loglikelihood: -12131.893852917503\n",
      "EM Iteration 4\n",
      "Current Monte Carlo Sample size: 660\n",
      "[[ 1.00000000e+000 -7.56483606e-249 -7.12199634e-243]\n",
      " [-7.56483606e-249  1.00000000e+000 -1.46994029e-260]\n",
      " [-7.12199634e-243 -1.46994029e-260  1.00000000e+000]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jesper\\Documents\\GitHub\\Knowledge-Growth-Prediction\\em_algorithm\\e_step_mirt_2pl.py:264: RuntimeWarning: divide by zero encountered in log\n",
      "  icc_values), r_item_theta) + np.multiply(np.log(1-icc_values), np.subtract(r_0_theta, r_item_theta))\n",
      "c:\\Users\\Jesper\\Documents\\GitHub\\Knowledge-Growth-Prediction\\em_algorithm\\e_step_mirt_2pl.py:264: RuntimeWarning: invalid value encountered in multiply\n",
      "  icc_values), r_item_theta) + np.multiply(np.log(1-icc_values), np.subtract(r_0_theta, r_item_theta))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 4: current parameter_diff: 24.909956480277785, current marginal loglikelihood: -11869.365012663717\n",
      "EM Iteration 5\n",
      "Current Monte Carlo Sample size: 660\n",
      "[[1.         0.07473132 0.19983603]\n",
      " [0.07473132 1.         0.24058055]\n",
      " [0.19983603 0.24058055 1.        ]]\n",
      "Step: 5: current parameter_diff: 20.731814136925763, current marginal loglikelihood: -11739.105149945846\n",
      "EM Iteration 6\n",
      "Current Monte Carlo Sample size: 660\n",
      "[[1.         0.02395303 0.25925938]\n",
      " [0.02395303 1.         0.26711545]\n",
      " [0.25925938 0.26711545 1.        ]]\n",
      "Step: 6: current parameter_diff: 6.423400003338906, current marginal loglikelihood: -11720.71525563623\n",
      "EM Iteration 7\n",
      "Current Monte Carlo Sample size: 726\n",
      "[[1.         0.02766565 0.2770886 ]\n",
      " [0.02766565 1.         0.30801604]\n",
      " [0.2770886  0.30801604 1.        ]]\n",
      "Step: 7: current parameter_diff: 5.599935651052099, current marginal loglikelihood: -11726.261698793634\n",
      "EM Iteration 8\n",
      "Current Monte Carlo Sample size: 798\n",
      "[[1.         0.03611896 0.29298871]\n",
      " [0.03611896 1.         0.33452034]\n",
      " [0.29298871 0.33452034 1.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jesper\\Documents\\GitHub\\Knowledge-Growth-Prediction\\em_algorithm\\m_step_mirt_2pl.py:70: RuntimeWarning: overflow encountered in exp\n",
      "  population = random.choices(population=population_base, weights=np.exp(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 8: current parameter_diff: 8.88763105930743, current marginal loglikelihood: -11739.130271363902\n",
      "EM Iteration 9\n",
      "Current Monte Carlo Sample size: 877\n",
      "[[1.         0.04450944 0.2860444 ]\n",
      " [0.04450944 1.         0.34325432]\n",
      " [0.2860444  0.34325432 1.        ]]\n",
      "Step: 9: current parameter_diff: 6.972349751947515, current marginal loglikelihood: -11721.612152810394\n",
      "EM Iteration 10\n",
      "Current Monte Carlo Sample size: 964\n",
      "[[1.         0.04267512 0.28987184]\n",
      " [0.04267512 1.         0.33339445]\n",
      " [0.28987184 0.33339445 1.        ]]\n",
      "Step: 10: current parameter_diff: 13.349635834760017, current marginal loglikelihood: -11712.217814439908\n",
      "EM Iteration 11\n",
      "Current Monte Carlo Sample size: 1060\n",
      "[[1.         0.05402791 0.27611641]\n",
      " [0.05402791 1.         0.32730623]\n",
      " [0.27611641 0.32730623 1.        ]]\n",
      "Step: 11: current parameter_diff: 13.121900001706786, current marginal loglikelihood: -11752.478352914124\n",
      "EM Iteration 12\n",
      "Current Monte Carlo Sample size: 1166\n",
      "[[1.         0.03472167 0.29289335]\n",
      " [0.03472167 1.         0.31423842]\n",
      " [0.29289335 0.31423842 1.        ]]\n",
      "Step: 12: current parameter_diff: 12.92705941994013, current marginal loglikelihood: -11773.525002062834\n",
      "EM Iteration 13\n",
      "Current Monte Carlo Sample size: 1282\n",
      "[[1.         0.04206202 0.28354236]\n",
      " [0.04206202 1.         0.34677087]\n",
      " [0.28354236 0.34677087 1.        ]]\n",
      "Step: 13: current parameter_diff: 14.069785350523503, current marginal loglikelihood: -11888.973247891026\n",
      "EM Iteration 14\n",
      "Current Monte Carlo Sample size: 1282\n",
      "[[1.         0.04470603 0.30510719]\n",
      " [0.04470603 1.         0.31712275]\n",
      " [0.30510719 0.31712275 1.        ]]\n",
      "Step: 14: current parameter_diff: 12.996930583013478, current marginal loglikelihood: -11919.620612639617\n",
      "EM Iteration 15\n",
      "Current Monte Carlo Sample size: 1410\n",
      "[[1.         0.03289506 0.31780259]\n",
      " [0.03289506 1.         0.33049459]\n",
      " [0.31780259 0.33049459 1.        ]]\n",
      "Step: 15: current parameter_diff: 12.407788859306613, current marginal loglikelihood: -11918.172775706451\n",
      "EM Iteration 16\n",
      "Current Monte Carlo Sample size: 1551\n",
      "[[1.         0.03358675 0.32117101]\n",
      " [0.03358675 1.         0.34333722]\n",
      " [0.32117101 0.34333722 1.        ]]\n",
      "Step: 16: current parameter_diff: 15.80893260174836, current marginal loglikelihood: -12160.280411491387\n",
      "EM Iteration 17\n",
      "Current Monte Carlo Sample size: 1706\n",
      "[[1.         0.03828454 0.3173103 ]\n",
      " [0.03828454 1.         0.37550231]\n",
      " [0.3173103  0.37550231 1.        ]]\n",
      "Step: 17: current parameter_diff: 17.733213121984406, current marginal loglikelihood: -12120.335550218635\n",
      "EM Iteration 18\n",
      "Current Monte Carlo Sample size: 1706\n",
      "[[1.         0.03947006 0.30946325]\n",
      " [0.03947006 1.         0.42371964]\n",
      " [0.30946325 0.42371964 1.        ]]\n",
      "Step: 18: current parameter_diff: 16.20566266842648, current marginal loglikelihood: -12159.97257104385\n",
      "EM Iteration 19\n",
      "Current Monte Carlo Sample size: 1876\n",
      "[[1.         0.05036364 0.315018  ]\n",
      " [0.05036364 1.         0.45976397]\n",
      " [0.315018   0.45976397 1.        ]]\n",
      "Step: 19: current parameter_diff: 17.15942650707747, current marginal loglikelihood: -12319.975242536013\n",
      "EM Iteration 20\n",
      "Current Monte Carlo Sample size: 2063\n",
      "[[1.         0.05564366 0.33809592]\n",
      " [0.05564366 1.         0.46824847]\n",
      " [0.33809592 0.46824847 1.        ]]\n",
      "Step: 20: current parameter_diff: 16.691893000641358, current marginal loglikelihood: -12259.903212209978\n",
      "EM Iteration 21\n",
      "Current Monte Carlo Sample size: 2269\n",
      "[[1.         0.08912059 0.32975034]\n",
      " [0.08912059 1.         0.45420422]\n",
      " [0.32975034 0.45420422 1.        ]]\n",
      "Step: 21: current parameter_diff: 23.66059479399594, current marginal loglikelihood: -12604.479047689154\n",
      "EM Iteration 22\n",
      "Current Monte Carlo Sample size: 2495\n",
      "[[1.         0.08254014 0.32608357]\n",
      " [0.08254014 1.         0.47241503]\n",
      " [0.32608357 0.47241503 1.        ]]\n",
      "Step: 22: current parameter_diff: 20.38471152818203, current marginal loglikelihood: -12431.250915065328\n",
      "EM Iteration 23\n",
      "Current Monte Carlo Sample size: 2744\n",
      "[[1.         0.08504754 0.3504352 ]\n",
      " [0.08504754 1.         0.49784505]\n",
      " [0.3504352  0.49784505 1.        ]]\n",
      "Step: 23: current parameter_diff: 24.10400754464389, current marginal loglikelihood: -12276.607911791718\n",
      "EM Iteration 24\n",
      "Current Monte Carlo Sample size: 3018\n",
      "[[1.         0.10774412 0.35177853]\n",
      " [0.10774412 1.         0.45853182]\n",
      " [0.35177853 0.45853182 1.        ]]\n",
      "Step: 24: current parameter_diff: 22.541689707305267, current marginal loglikelihood: -12489.193570693122\n",
      "EM Iteration 25\n",
      "Current Monte Carlo Sample size: 3319\n",
      "[[1.         0.10661726 0.34589446]\n",
      " [0.10661726 1.         0.41512853]\n",
      " [0.34589446 0.41512853 1.        ]]\n",
      "Step: 25: current parameter_diff: 25.243161391043913, current marginal loglikelihood: -12530.126933447274\n",
      "EM Iteration 26\n",
      "Current Monte Carlo Sample size: 3650\n",
      "[[1.         0.05332288 0.32572397]\n",
      " [0.05332288 1.         0.32202492]\n",
      " [0.32572397 0.32202492 1.        ]]\n",
      "Step: 26: current parameter_diff: 22.217647900015496, current marginal loglikelihood: -12327.542608689702\n",
      "EM Iteration 27\n",
      "Current Monte Carlo Sample size: 4015\n",
      "[[1.         0.04531018 0.29629237]\n",
      " [0.04531018 1.         0.3749033 ]\n",
      " [0.29629237 0.3749033  1.        ]]\n",
      "Step: 27: current parameter_diff: 24.456232729238387, current marginal loglikelihood: -12569.487190457674\n",
      "EM Iteration 28\n",
      "Current Monte Carlo Sample size: 4015\n",
      "[[1.         0.0664822  0.2553332 ]\n",
      " [0.0664822  1.         0.32259075]\n",
      " [0.2553332  0.32259075 1.        ]]\n",
      "Step: 28: current parameter_diff: 21.160665319248636, current marginal loglikelihood: -12482.746614190011\n",
      "EM Iteration 29\n",
      "Current Monte Carlo Sample size: 4416\n",
      "[[1.         0.08727014 0.22960587]\n",
      " [0.08727014 1.         0.33549268]\n",
      " [0.22960587 0.33549268 1.        ]]\n",
      "Step: 29: current parameter_diff: 24.144751376772238, current marginal loglikelihood: -12540.769966653768\n",
      "EM Iteration 30\n",
      "Current Monte Carlo Sample size: 4857\n",
      "[[1.         0.0830018  0.20951295]\n",
      " [0.0830018  1.         0.32728332]\n",
      " [0.20951295 0.32728332 1.        ]]\n",
      "Step: 30: current parameter_diff: 18.567347369526907, current marginal loglikelihood: -12605.802540473838\n",
      "EM Iteration 31\n",
      "Current Monte Carlo Sample size: 5342\n",
      "[[1.         0.10384263 0.19035454]\n",
      " [0.10384263 1.         0.33995062]\n",
      " [0.19035454 0.33995062 1.        ]]\n",
      "Step: 31: current parameter_diff: 18.27550659381697, current marginal loglikelihood: -12488.402669715779\n",
      "EM Iteration 32\n",
      "Current Monte Carlo Sample size: 5876\n",
      "[[1.         0.09216813 0.16231849]\n",
      " [0.09216813 1.         0.34736474]\n",
      " [0.16231849 0.34736474 1.        ]]\n",
      "Step: 32: current parameter_diff: 18.659892839891487, current marginal loglikelihood: -12963.804592738707\n",
      "EM Iteration 33\n",
      "Current Monte Carlo Sample size: 6463\n",
      "[[1.         0.08934729 0.16282502]\n",
      " [0.08934729 1.         0.3309664 ]\n",
      " [0.16282502 0.3309664  1.        ]]\n",
      "Step: 33: current parameter_diff: 23.50586764065138, current marginal loglikelihood: -13510.649271026294\n",
      "EM Iteration 34\n",
      "Current Monte Carlo Sample size: 7109\n",
      "[[1.         0.08710583 0.15552528]\n",
      " [0.08710583 1.         0.29611591]\n",
      " [0.15552528 0.29611591 1.        ]]\n",
      "Step: 34: current parameter_diff: 21.960943064628275, current marginal loglikelihood: -13944.259625971496\n",
      "EM Iteration 35\n",
      "Current Monte Carlo Sample size: 7109\n",
      "[[1.         0.07793025 0.16516396]\n",
      " [0.07793025 1.         0.36413403]\n",
      " [0.16516396 0.36413403 1.        ]]\n",
      "Step: 35: current parameter_diff: 27.121295291247954, current marginal loglikelihood: -13503.312147530629\n",
      "EM Iteration 36\n",
      "Current Monte Carlo Sample size: 7819\n",
      "[[1.         0.10383503 0.15573248]\n",
      " [0.10383503 1.         0.38227496]\n",
      " [0.15573248 0.38227496 1.        ]]\n",
      "Step: 36: current parameter_diff: 20.49072253096319, current marginal loglikelihood: -13457.903630401384\n",
      "EM Iteration 37\n",
      "Current Monte Carlo Sample size: 8600\n",
      "[[1.         0.0952063  0.1697639 ]\n",
      " [0.0952063  1.         0.46301737]\n",
      " [0.1697639  0.46301737 1.        ]]\n",
      "Step: 37: current parameter_diff: 27.90481089780214, current marginal loglikelihood: -12706.910698711592\n",
      "EM Iteration 38\n",
      "Current Monte Carlo Sample size: 9460\n",
      "[[1.         0.11529993 0.26172741]\n",
      " [0.11529993 1.         0.55011103]\n",
      " [0.26172741 0.55011103 1.        ]]\n",
      "Step: 38: current parameter_diff: 25.492536506460198, current marginal loglikelihood: -12568.140485448821\n",
      "EM Iteration 39\n",
      "Current Monte Carlo Sample size: 10406\n",
      "[[1.         0.10827926 0.31252693]\n",
      " [0.10827926 1.         0.47192521]\n",
      " [0.31252693 0.47192521 1.        ]]\n",
      "Step: 39: current parameter_diff: 23.39773718705719, current marginal loglikelihood: -12458.470015244868\n",
      "EM Iteration 40\n",
      "Current Monte Carlo Sample size: 11446\n",
      "[[1.         0.08448759 0.34971178]\n",
      " [0.08448759 1.         0.4185697 ]\n",
      " [0.34971178 0.4185697  1.        ]]\n",
      "Step: 40: current parameter_diff: 25.01324472722742, current marginal loglikelihood: -12669.061288880423\n",
      "EM Iteration 41\n",
      "Current Monte Carlo Sample size: 12590\n",
      "[[ 1.00000000e+000 -2.61463218e-102 -1.08935164e-109]\n",
      " [-2.61463218e-102  1.00000000e+000 -4.18362278e-029]\n",
      " [-1.08935164e-109 -4.18362278e-029  1.00000000e+000]]\n",
      "Step: 41: current parameter_diff: 21.568233132762924, current marginal loglikelihood: -12849.955625780705\n",
      "EM Iteration 42\n",
      "Current Monte Carlo Sample size: 13849\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Jesper\\Documents\\GitHub\\Knowledge-Growth-Prediction\\simulation_experiments.ipynb Zelle 23\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Jesper/Documents/GitHub/Knowledge-Growth-Prediction/simulation_experiments.ipynb#X31sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m performance_dict \u001b[39m=\u001b[39m mirt_param_recovery(sample_size\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m, item_dimension\u001b[39m=\u001b[39;49m\u001b[39m30\u001b[39;49m, latent_dimension\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m, q_type\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mfull\u001b[39;49m\u001b[39m\"\u001b[39;49m, girth\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, stop_threshold\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, q_share\u001b[39m=\u001b[39;49m\u001b[39m0.0\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\Jesper\\Documents\\GitHub\\Knowledge-Growth-Prediction\\simulation_experiments.ipynb Zelle 23\u001b[0m in \u001b[0;36mmirt_param_recovery\u001b[1;34m(sample_size, item_dimension, latent_dimension, q_type, girth, stop_threshold, ensure_id, q_share)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Jesper/Documents/GitHub/Knowledge-Growth-Prediction/simulation_experiments.ipynb#X31sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39m#Fit Model\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Jesper/Documents/GitHub/Knowledge-Growth-Prediction/simulation_experiments.ipynb#X31sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Jesper/Documents/GitHub/Knowledge-Growth-Prediction/simulation_experiments.ipynb#X31sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m em\u001b[39m.\u001b[39;49mfit(sample[\u001b[39m\"\u001b[39;49m\u001b[39mearly_responses\u001b[39;49m\u001b[39m\"\u001b[39;49m], max_iter\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, stop_threshold\u001b[39m=\u001b[39;49mstop_threshold)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Jesper/Documents/GitHub/Knowledge-Growth-Prediction/simulation_experiments.ipynb#X31sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m run_time \u001b[39m=\u001b[39m  (time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Jesper/Documents/GitHub/Knowledge-Growth-Prediction/simulation_experiments.ipynb#X31sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39m#Measure Performance\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jesper\\Documents\\GitHub\\Knowledge-Growth-Prediction\\em_algorithm\\em_algorithm.py:43\u001b[0m, in \u001b[0;36mem_algorithm.fit\u001b[1;34m(self, data, hyper_params, max_iter, stop_threshold)\u001b[0m\n\u001b[0;32m     41\u001b[0m last_step_marginal_loglikelihood \u001b[39m=\u001b[39m marginal_loglikelihood\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m     42\u001b[0m \u001b[39m# print(\"E-step\")\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m posterior_expectation \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49me_step\u001b[39m.\u001b[39;49mstep(\n\u001b[0;32m     44\u001b[0m     response_data\u001b[39m=\u001b[39;49mdata, \u001b[39miter\u001b[39;49m\u001b[39m=\u001b[39;49mi)\n\u001b[0;32m     45\u001b[0m \u001b[39m# print(\"M-step\")\u001b[39;00m\n\u001b[0;32m     46\u001b[0m current_parameters, log_likelihood \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mm_step\u001b[39m.\u001b[39mstep(\n\u001b[0;32m     47\u001b[0m     pe_functions\u001b[39m=\u001b[39mposterior_expectation)\n",
      "File \u001b[1;32mc:\\Users\\Jesper\\Documents\\GitHub\\Knowledge-Growth-Prediction\\em_algorithm\\e_step_mirt_2pl.py:97\u001b[0m, in \u001b[0;36me_step_ga_mml.step\u001b[1;34m(self, response_data, current_item_parameters, current_person_parameters, iter)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mCurrent Monte Carlo Sample size: \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mN))\n\u001b[0;32m     95\u001b[0m theta_sample \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39msample_competency(\n\u001b[0;32m     96\u001b[0m     sample_size\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mN, qmc\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m---> 97\u001b[0m \u001b[39mreturn\u001b[39;00m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprepare_q_functions(theta_sample, response_data, normalising_constant_array))\n",
      "File \u001b[1;32mc:\\Users\\Jesper\\Documents\\GitHub\\Knowledge-Growth-Prediction\\em_algorithm\\e_step_mirt_2pl.py:105\u001b[0m, in \u001b[0;36me_step_ga_mml.prepare_q_functions\u001b[1;34m(self, theta_sample, response_data, normalising_constant_array)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[39m# Calculate repeating inner functions\u001b[39;00m\n\u001b[0;32m    103\u001b[0m r_0_theta \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mr_0(\n\u001b[0;32m    104\u001b[0m     theta_sample, normalising_constant_array, response_data)\n\u001b[1;32m--> 105\u001b[0m r_item_theta_list \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mr_item(item, theta_sample, normalising_constant_array, response_data)\n\u001b[0;32m    106\u001b[0m                      \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, J)]\n\u001b[0;32m    107\u001b[0m \u001b[39m# Calculate final q-functions\u001b[39;00m\n\u001b[0;32m    108\u001b[0m q_0 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mq_0(\n\u001b[0;32m    109\u001b[0m     theta\u001b[39m=\u001b[39mtheta_sample, normalising_constant_array\u001b[39m=\u001b[39mnormalising_constant_array, response_data\u001b[39m=\u001b[39mresponse_data)\n",
      "File \u001b[1;32mc:\\Users\\Jesper\\Documents\\GitHub\\Knowledge-Growth-Prediction\\em_algorithm\\e_step_mirt_2pl.py:105\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[39m# Calculate repeating inner functions\u001b[39;00m\n\u001b[0;32m    103\u001b[0m r_0_theta \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mr_0(\n\u001b[0;32m    104\u001b[0m     theta_sample, normalising_constant_array, response_data)\n\u001b[1;32m--> 105\u001b[0m r_item_theta_list \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mr_item(item, theta_sample, normalising_constant_array, response_data)\n\u001b[0;32m    106\u001b[0m                      \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, J)]\n\u001b[0;32m    107\u001b[0m \u001b[39m# Calculate final q-functions\u001b[39;00m\n\u001b[0;32m    108\u001b[0m q_0 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mq_0(\n\u001b[0;32m    109\u001b[0m     theta\u001b[39m=\u001b[39mtheta_sample, normalising_constant_array\u001b[39m=\u001b[39mnormalising_constant_array, response_data\u001b[39m=\u001b[39mresponse_data)\n",
      "File \u001b[1;32mc:\\Users\\Jesper\\Documents\\GitHub\\Knowledge-Growth-Prediction\\em_algorithm\\e_step_mirt_2pl.py:182\u001b[0m, in \u001b[0;36me_step_ga_mml.r_item\u001b[1;34m(self, item, theta, normalising_constant_array, response_data)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mr_item\u001b[39m(\u001b[39mself\u001b[39m, item: \u001b[39mint\u001b[39m, theta: np\u001b[39m.\u001b[39marray, normalising_constant_array, response_data):\n\u001b[1;32m--> 182\u001b[0m     numerator \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mresponse_matrix_probability(\n\u001b[0;32m    183\u001b[0m         theta\u001b[39m=\u001b[39;49mtheta, response_matrix\u001b[39m=\u001b[39;49mresponse_data\u001b[39m.\u001b[39;49mto_numpy()))\n\u001b[0;32m    184\u001b[0m     \u001b[39m# This coefficient is different to r_0\u001b[39;00m\n\u001b[0;32m    185\u001b[0m     numerator \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmultiply(\n\u001b[0;32m    186\u001b[0m         numerator, response_data\u001b[39m.\u001b[39miloc[:, item]\u001b[39m.\u001b[39mto_numpy()\u001b[39m.\u001b[39mtranspose())\n",
      "File \u001b[1;32mc:\\Users\\Jesper\\Documents\\GitHub\\Knowledge-Growth-Prediction\\models\\mirt_2pl.py:150\u001b[0m, in \u001b[0;36mmirt_2pl.response_matrix_probability\u001b[1;34m(self, theta, response_matrix, A, delta)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[39m# We want to apply each response vector to each competency-induced correct-response-probability\u001b[39;00m\n\u001b[0;32m    148\u001b[0m correct_response_probabilities \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mexpand_dims(\n\u001b[0;32m    149\u001b[0m     correct_response_probabilities, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m--> 150\u001b[0m probability_vector \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49madd(np\u001b[39m.\u001b[39;49mmultiply(correct_response_probabilities, response_matrix),\n\u001b[0;32m    151\u001b[0m                             np\u001b[39m.\u001b[39;49mmultiply(np\u001b[39m.\u001b[39;49msubtract(\u001b[39m1\u001b[39;49m, correct_response_probabilities), np\u001b[39m.\u001b[39;49msubtract(\u001b[39m1\u001b[39;49m, response_matrix)))\n\u001b[0;32m    152\u001b[0m probability \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mprod(probability_vector, axis\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m    153\u001b[0m \u001b[39mreturn\u001b[39;00m(probability)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "performance_dict = mirt_param_recovery(sample_size=1000, item_dimension=30, latent_dimension=3, q_type=\"full\", girth=False, stop_threshold=10, q_share=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "##### Results for With fixed Discrimination sampling and BFGS\n",
      "Latent dimension: 3,  Item dimension: 20, sample size 1000 \\\n",
      "Runtime: 63.64 seconds, 14 steps, 4.55 seconds per step \\\n",
      "Optimal marginal Likelihood: -8684.81, Estimated: -8676.2, Initial -9809.83\n",
      "|               |   rmse_A |   rmse_delta |   rmse_sigma |\n",
      "|:--------------|---------:|-------------:|-------------:|\n",
      "| estimated     | 0.933735 |     0.514423 |    0.0383988 |\n",
      "| early_initial | 2.67536  |     0.636687 |    0.231996  |\n"
     ]
    }
   ],
   "source": [
    "print_result(performance_dict, \"With fixed Discrimination sampling and BFGS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------\n",
    "##### Results for With BFGS as covariance optimization Algorithm\n",
    "Latent dimension: 3,  Item dimension: 20, sample size 1000 \\\n",
    "Runtime: 160.7 seconds, 20 steps, 8.04 seconds per step \\\n",
    "Optimal marginal Likelihood: -11451.44, Estimated: -11746.37, Initial -12757.23\n",
    "|               |   rmse_A |   rmse_delta |   rmse_sigma |\n",
    "|:--------------|---------:|-------------:|-------------:|\n",
    "| estimated     |  4.12413 |      1.19297 |     0.539132 |\n",
    "| early_initial |  4.06187 |      1.22103 |     0.159225 |\n",
    "\n",
    "------------------------------------\n",
    "##### Results for With Cholesky covariance decomposition\n",
    "Latent dimension: 3,  Item dimension: 20, sample size 1000 \\\n",
    "Runtime: 60.82 seconds, 14 steps, 4.34 seconds per step \\\n",
    "Optimal marginal Likelihood: -11369.92, Estimated: -12102.54, Initial -13629.98\n",
    "|               |   rmse_A |   rmse_delta |   rmse_sigma |\n",
    "|:--------------|---------:|-------------:|-------------:|\n",
    "| estimated     |  2.47435 |     0.400838 |     0.181127 |\n",
    "| early_initial |  2.98819 |     0.686696 |     0.142997 |\n",
    "\n",
    "------------------------------------\n",
    "##### Results for With Cholesky covariance decomposition and BFGS\n",
    "Latent dimension: 3,  Item dimension: 30, sample size 1000 \\\n",
    "Runtime: 94.77 seconds, 12 steps, 7.9 seconds per step \\\n",
    "Optimal marginal Likelihood: -15960.47, Estimated: -17344.15, Initial -19786.45\n",
    "|               |   rmse_A |   rmse_delta |   rmse_sigma |\n",
    "|:--------------|---------:|-------------:|-------------:|\n",
    "| estimated     |  48.8803 |     0.777924 |     0.149531 |\n",
    "| early_initial |  49.0831 |     1.33755  |     0.207159 |\n",
    "\n",
    "------------------------------------\n",
    "##### Results for With fixed Discrimination sampling and BFGS\n",
    "Latent dimension: 3,  Item dimension: 30, sample size 1000 \\\n",
    "Runtime: 91.68 seconds, 12 steps, 7.64 seconds per step \\\n",
    "Optimal marginal Likelihood: -12149.74, Estimated: -12157.89, Initial -14965.74\n",
    "|               |   rmse_A |   rmse_delta |   rmse_sigma |\n",
    "|:--------------|---------:|-------------:|-------------:|\n",
    "| estimated     |  0.3929  |     0.249323 |    0.0275205 |\n",
    "| early_initial |  2.20296 |     0.582838 |    0.380006  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procedure for better model performance:\n",
    "\n",
    "1. Implement MIRT Baseline (done)\n",
    "2. Test GA with quadratic function (done)\n",
    "3. use pycma (done)\n",
    "4. Test mirt-functions (response-matrix-probability, done)\n",
    "5. Read on MC MIRT (MC-Errorbounds usage or quasi-MC or importance sampling)\n",
    "6. Use importance sampling\n",
    "7. Implement Newton Raphson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimeted Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 2., 0., 0.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [0., 0., 2., 2.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.optimize import approx_fprime\n",
    "\n",
    "def func(C_vector):\n",
    "    dim = np.sqrt(C_vector.shape).astype(np.int)[0]\n",
    "    C = C_vector.reshape((dim, dim))\n",
    "    sigma = np.matmul(C, C.transpose())\n",
    "    return(sigma.flatten())\n",
    "\n",
    "approx_fprime(f=func, xk=np.ones(2*2))\n",
    "\n",
    "#Ich brauche wohl irgendeine Art von Matrixprodukt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.49011612e-08, 2.00000001e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [2.00000000e+00, 3.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n",
       "       [2.00000000e+00, 3.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 4.00000000e+00, 6.00000000e+00]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "approx_fprime(f=func, xk=np.arange(0,4\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2: Competency Gain Prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f96c9f0abe66cee0a81d860b29e85a2729d567fff345231565bc586735399795"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
