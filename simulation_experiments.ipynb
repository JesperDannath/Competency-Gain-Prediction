{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jesper\\Documents\\GitHub\\Knowledge-Growth-Prediction\\models\n",
      "C:\\Users\\Jesper\\Documents\\GitHub\\Knowledge-Growth-Prediction\\models\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from simulation_framework.item_response_simulation import item_response_simulation\n",
    "from simulation_framework.simulate_competency import respondent_population\n",
    "from simulation_framework.simulate_responses import response_simulation\n",
    "from scipy.stats import multivariate_normal\n",
    "import models\n",
    "import em_algorithm\n",
    "import pandas as pd\n",
    "import time\n",
    "from girth import multidimensional_twopl_mml\n",
    "from girth import twopl_mml\n",
    "import cma\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def params_to_vector(model):\n",
    "    item_dimension = model.item_dimension\n",
    "    latent_dimension = model.latent_dimension\n",
    "    A_flat = model.item_parameters[\"discrimination_matrix\"].flatten()\n",
    "    A_flat = A_flat[A_flat != 0]\n",
    "    A_cut = len(A_flat)\n",
    "    delta_cut = A_cut+item_dimension\n",
    "    delta = model.item_parameters[\"intercept_vector\"]\n",
    "    sigma_flat = model.person_parameters[\"covariance\"][np.triu_indices(\n",
    "            model.latent_dimension, k=1)]\n",
    "    return(np.concatenate((A_flat, delta, sigma_flat), axis=0))\n",
    "\n",
    "def vector_to_params(vector, model):\n",
    "    item_dimension = model.item_dimension\n",
    "    latent_dimension = model.latent_dimension \n",
    "    q_matrix = model.item_parameters[\"q_matrix\"] \n",
    "    q_flat = q_matrix.flatten()\n",
    "    A_cut = len(q_flat[q_flat != 0])\n",
    "    delta_cut = A_cut+item_dimension\n",
    "    A = vector[0:A_cut]\n",
    "    A = model.fill_zero_discriminations(A).reshape((item_dimension, latent_dimension))\n",
    "    delta = vector[A_cut:delta_cut]\n",
    "    item_parameters = {\"discrimination_matrix\": A, \"intercept_vector\": delta}\n",
    "    corr = vector[delta_cut: len(vector)]\n",
    "    sigma = model.corr_to_sigma(corr, False)\n",
    "    return({\"item_parameters\": item_parameters, \"person_parameters\": {\"covariance\": sigma}})\n",
    "\n",
    "def direct_marginal_optimization(model, response_data):\n",
    "    #Get initial parameters\n",
    "    x0 = params_to_vector(model)\n",
    "    response_data = response_data.to_numpy()\n",
    "    #Optimize with GA\n",
    "    def marginal_l_func(input_vector):\n",
    "        parameters = vector_to_params(input_vector, model)\n",
    "        try:\n",
    "            model.set_parameters(parameters)\n",
    "        except Exception:\n",
    "            return(np.inf)\n",
    "        result = -1*model.marginal_response_loglikelihood(response_data)\n",
    "        return(result)\n",
    "    es = cma.CMAEvolutionStrategy(x0=x0, sigma0=0.5)\n",
    "    es.optimize(marginal_l_func, maxfun=100000)\n",
    "    #Get result\n",
    "    result = es.result.xfavorite\n",
    "    return(vector_to_params(result, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.mirt_2pl import mirt_2pl\n",
    "\n",
    "def rmse(y_pred: np.array, y_true: np.array) -> float:\n",
    "    MSE = np.square(np.subtract(y_pred.flatten(), y_true.flatten())).mean()\n",
    "    RMSE = np.sqrt(MSE)\n",
    "    return(float(RMSE))\n",
    "\n",
    "def experiment_performance(estimated_parameter_dict, real_parameter_dict):\n",
    "    res_dict = {}\n",
    "    if \"item_parameters\" in estimated_parameter_dict.keys():\n",
    "        A_pred = estimated_parameter_dict[\"item_parameters\"][\"discrimination_matrix\"]\n",
    "        delta_pred = estimated_parameter_dict[\"item_parameters\"][\"intercept_vector\"]\n",
    "\n",
    "        A_true = real_parameter_dict[\"item_parameters\"][\"discrimination_matrix\"]\n",
    "        delta_true = real_parameter_dict[\"item_parameters\"][\"intercept_vector\"]\n",
    "\n",
    "        print(\"Absolute diff in A:\")\n",
    "        print(np.abs(A_true-A_pred))\n",
    "\n",
    "        print(\"Absolute diff in delta:\")\n",
    "        print(np.abs(delta_true-delta_pred))\n",
    "\n",
    "        res_dict[\"rmse_A\"] = rmse(A_pred, A_true)\n",
    "        res_dict[\"rmse_delta\"] = rmse(delta_true, delta_pred)\n",
    "\n",
    "    if \"person_parameters\" in estimated_parameter_dict.keys():\n",
    "        sigma_pred = estimated_parameter_dict[\"person_parameters\"][\"covariance\"]\n",
    "        sigma_true = real_parameter_dict[\"person_parameters\"][\"covariance\"]\n",
    "\n",
    "        print(\"Absolute diff in sigma:\")\n",
    "        print(np.abs(sigma_true-sigma_pred)) # TODO: Evtl. die Hauptdiagonale ausschlie√üen!\n",
    "\n",
    "        res_dict[\"rmse_sigma\"] = rmse(sigma_true, sigma_pred) \n",
    "    if len(res_dict.keys())==0:\n",
    "        raise Exception(\"No performance to calculate\")\n",
    "    return(res_dict)\n",
    "\n",
    "def standardize_parameters(parameter_dict):\n",
    "        covariance = parameter_dict[\"person_parameters\"][\"covariance\"]\n",
    "        A = parameter_dict[\"item_parameters\"][\"discrimination_matrix\"]\n",
    "        if len(covariance.shape)<=1:\n",
    "            correlation_matrix  = np.array([[1]])\n",
    "            inv_sqrt_cov = np.array([[np.sqrt(1/covariance)]])\n",
    "            A = np.multiply(A, inv_sqrt_cov)\n",
    "        else:\n",
    "            sd_vector = np.sqrt(covariance.diagonal())\n",
    "            inv_sd_matrix = np.linalg.inv(np.diag(sd_vector))\n",
    "            correlation_matrix = np.dot(\n",
    "            np.dot(inv_sd_matrix, covariance), inv_sd_matrix)\n",
    "            A = np.dot(A, np.linalg.inv(inv_sd_matrix))\n",
    "        parameter_dict[\"item_parameters\"][\"discrimination_matrix\"] = A\n",
    "        parameter_dict[\"person_parameters\"][\"covariance\"] = correlation_matrix\n",
    "        return(parameter_dict)\n",
    "\n",
    "def create_parameter_dict(estimated_early_parameters, real_early_parameters, estimated_late_parameters, real_late_parameters):\n",
    "    parameter_dict = {\"real_early_parameters\": real_early_parameters,\n",
    "                   \"estimated_early_parameters\": estimated_early_parameters}\n",
    "    return(parameter_dict)\n",
    "\n",
    "\n",
    "def create_performance_dict(parameter_dict, run_dict, sample=None, baselines=None, model=None):\n",
    "    result_dict = parameter_dict\n",
    "    result_dict[\"sample\"] = sample\n",
    "    #Model Performance\n",
    "    result_dict[\"early_performance\"] = {}\n",
    "    result_dict[\"early_performance\"][\"rmse\"] = experiment_performance(real_parameter_dict=result_dict[\"real_early_parameters\"], \n",
    "                                                              estimated_parameter_dict=result_dict[\"estimated_early_parameters\"])\n",
    "    #Baseline's Performance\n",
    "    baselines[\"early_initial\"][\"performance\"] = {\"rmse\": experiment_performance(real_parameter_dict=result_dict[\"real_early_parameters\"], \n",
    "                                                              estimated_parameter_dict=baselines[\"early_initial\"][\"parameters\"])}\n",
    "    if \"girth\" in baselines.keys():\n",
    "        girth_data = result_dict[\"sample\"][\"early_responses\"].to_numpy().transpose()\n",
    "        if model.latent_dimension == 1:\n",
    "            girth_estimates = twopl_mml(girth_data)\n",
    "        else:\n",
    "            girth_estimates = multidimensional_twopl_mml(girth_data, n_factors=model.latent_dimension)\n",
    "        girth_item_parameters = {\"discrimination_matrix\": girth_estimates[\"Discrimination\"], \"intercept_vector\": girth_estimates[\"Difficulty\"]}\n",
    "        girth_parameters = {\"item_parameters\": girth_item_parameters}\n",
    "        girth_estimated_covariance = np.cov(girth_estimates[\"Ability\"], rowvar=True)\n",
    "        girth_parameters[\"person_parameters\"] = {\"covariance\": girth_estimated_covariance}\n",
    "        girth_parameters = standardize_parameters(girth_parameters)\n",
    "        girth_performance_rmse = experiment_performance(real_parameter_dict=result_dict[\"real_early_parameters\"], \n",
    "                                                              estimated_parameter_dict=girth_parameters)\n",
    "        baselines[\"girth\"][\"parameters\"] = girth_parameters\n",
    "        baselines[\"girth\"][\"performance\"] = {\"rmse\": girth_performance_rmse}\n",
    "\n",
    "    if \"early_direct\" in baselines.keys():\n",
    "        dir_model = mirt_2pl(item_dimension=model.item_dimension, latent_dimension=model.latent_dimension, Q=model.item_parameters[\"q_matrix\"])\n",
    "        direct_early_item_parameters = direct_marginal_optimization(dir_model, response_data=sample[\"early_responses\"])\n",
    "        direct_early_performance_rmse = experiment_performance(real_parameter_dict=result_dict[\"real_early_parameters\"], \n",
    "                                                              estimated_parameter_dict=direct_early_item_parameters)\n",
    "        baselines[\"early_direct\"][\"parameters\"] = direct_early_item_parameters\n",
    "        baselines[\"early_direct\"][\"performance\"] = {\"rmse\": direct_early_performance_rmse}\n",
    "\n",
    "    result_dict[\"baselines\"] = baselines\n",
    "    likelihood = calculate_marginal_likelihoods(model=model, response_data=sample[\"early_responses\"], real_parameters=result_dict[\"real_early_parameters\"],\n",
    "                                                initial_parameters=baselines[\"early_initial\"][\"parameters\"], estimated_parameters=result_dict[\"estimated_early_parameters\"])\n",
    "    result_dict[\"early_performance\"][\"marginal_likelihood\"] = likelihood\n",
    "    result_dict[\"early_performance\"][\"run\"] = run_dict[\"early\"]\n",
    "    return(result_dict)\n",
    "\n",
    "def calculate_marginal_likelihoods(model, response_data, real_parameters, initial_parameters, estimated_parameters):\n",
    "    model.set_parameters(initial_parameters)\n",
    "    initial_marginal_likelihood = model.marginal_response_loglikelihood(response_data=response_data.to_numpy())\n",
    "    model.set_parameters(real_parameters)\n",
    "    optimal_marginal_likelihood = model.marginal_response_loglikelihood(response_data=response_data.to_numpy())\n",
    "    model.set_parameters(estimated_parameters)\n",
    "    marginal_likelihood_estimated = model.marginal_response_loglikelihood(response_data=response_data.to_numpy())\n",
    "    likelihood_dict = {\"optimal\": optimal_marginal_likelihood, \"estimated\": marginal_likelihood_estimated, \"initial\": initial_marginal_likelihood}\n",
    "    return(likelihood_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def direct_optimization_benchmark():\n",
    "    latent_dimension = 2\n",
    "    item_dimension = 6\n",
    "    sample_size=100\n",
    "\n",
    "    #Define Population\n",
    "    real_latent_cov = np.array([[1,0.2],\n",
    "                    [0.2,1]])\n",
    "\n",
    "    latent_distribution = multivariate_normal(mean=np.array([0,0]), cov=real_latent_cov)\n",
    "    population = respondent_population(latent_dimension=latent_dimension, latent_distribution=latent_distribution)\n",
    "\n",
    "    #Define Test\n",
    "    A = np.array([[0.5,0],\n",
    "                  [2,0],\n",
    "                  [0,0.4],\n",
    "                  [0.7,0.6],\n",
    "                  [2, 0.9],\n",
    "                  [0, 1.5]])\n",
    "    Q = np.array([[1,0],\n",
    "                  [1,0],\n",
    "                  [0,1],\n",
    "                  [1,1],\n",
    "                  [1,1],\n",
    "                  [0,1]])\n",
    "\n",
    "    delta = np.array([0, 0.5, 1, 0, 1.5, 0.9])\n",
    "    early_item_parameters = {\"discrimination_matrix\": A, \"intercept_vector\": delta, \"q_matrix\": Q, \"item_dimension\": item_dimension, \"latent_dimension\": latent_dimension}\n",
    "    real_early_parameters = {\"item_parameters\": early_item_parameters, \"person_parameters\": {\"covariance\": real_latent_cov}}\n",
    "\n",
    "    #Sample responses\n",
    "    response_simulation_obj = response_simulation(population=population, item_dimension = item_dimension, early_item_params=early_item_parameters)\n",
    "    sample = response_simulation_obj.sample(sample_size)\n",
    "\n",
    "    #Fit Parameters\n",
    "    #Initialize model\n",
    "    model = models.mirt_2pl(latent_dimension=2, item_dimension=6, Q=Q)\n",
    "    model.initialize_from_responses(response_data=sample[\"early_responses\"])\n",
    "\n",
    "    estimated_params = direct_marginal_optimization(model, response_data=sample[\"early_responses\"])\n",
    "    return(estimated_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 0: MIRT-2PL Performance Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mirt_performance_benchmark() -> dict:\n",
    "    latent_dimension = 2\n",
    "    item_dimension = 6\n",
    "    sample_size=100\n",
    "\n",
    "    #Define Population\n",
    "    real_latent_cov = np.array([[1,0.2],\n",
    "                    [0.2,1]])\n",
    "\n",
    "    latent_distribution = multivariate_normal(mean=np.array([0,0]), cov=real_latent_cov)\n",
    "    population = respondent_population(latent_dimension=latent_dimension, latent_distribution=latent_distribution)\n",
    "\n",
    "    #Define Test\n",
    "    A = np.array([[0.5,0],\n",
    "                  [2,0],\n",
    "                  [0,0.4],\n",
    "                  [0.7,0.6],\n",
    "                  [2, 0.9],\n",
    "                  [0, 1.5]])\n",
    "    Q = np.array([[1,0],\n",
    "                  [1,0],\n",
    "                  [0,1],\n",
    "                  [1,1],\n",
    "                  [1,1],\n",
    "                  [0,1]])\n",
    "\n",
    "    delta = np.array([0, 0.5, 1, 0, 1.5, 0.9])\n",
    "    early_item_parameters = {\"discrimination_matrix\": A, \"intercept_vector\": delta, \"q_matrix\": Q, \"item_dimension\": item_dimension, \"latent_dimension\": latent_dimension}\n",
    "    real_early_parameters = {\"item_parameters\": early_item_parameters, \"person_parameters\": {\"covariance\": real_latent_cov}}\n",
    "\n",
    "    #Sample responses\n",
    "    response_simulation_obj = response_simulation(population=population, item_dimension = item_dimension, early_item_params=early_item_parameters)\n",
    "    sample = response_simulation_obj.sample(sample_size)\n",
    "\n",
    "    #Fit Parameters\n",
    "    #Initialize model\n",
    "    model = models.mirt_2pl(latent_dimension=2, item_dimension=6, Q=Q)\n",
    "    model.initialize_from_responses(response_data=sample[\"early_responses\"])\n",
    "    initial_early_parameters = model.get_parameters()\n",
    "    e_step = em_algorithm.e_step_ga_mml(model=model)\n",
    "    m_step = em_algorithm.m_step_ga_mml(model)\n",
    "    em = em_algorithm.em_algo(e_step=e_step, m_step=m_step, model=model)\n",
    "\n",
    "    #Fit Model\n",
    "    start_time = time.time()\n",
    "    em.fit(sample[\"early_responses\"], max_iter=50)\n",
    "    run_time =  (time.time() - start_time)\n",
    "\n",
    "    #Create Baselines\n",
    "    baselines = {\"early_initial\": {\"parameters\": initial_early_parameters}, \"girth\": {}, \"early_direct\": {}}\n",
    "    \n",
    "    #Create results\n",
    "    early_estimated_parameters = em.model.get_parameters()\n",
    "\n",
    "    parameter_dict = create_parameter_dict(estimated_early_parameters=early_estimated_parameters,\n",
    "                          real_early_parameters = real_early_parameters,\n",
    "                          estimated_late_parameters=None, real_late_parameters=None)\n",
    "    run_dict = {\"early\": {\"runtime\": run_time,\n",
    "                \"number_steps\": em.n_steps}}\n",
    "    performance_dict = create_performance_dict(parameter_dict=parameter_dict, run_dict=run_dict, sample=sample, baselines=baselines, model=model)\n",
    "    return(performance_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print_result(result_dict, description=\"\"):\n",
    "    #Description\n",
    "    print(\"------------------------------------\")\n",
    "    print(\"##### Results for {0}\".format(description))\n",
    "    #Experiment Properties:\n",
    "    latent_dimension = result_dict[\"sample\"][\"latent_dimension\"]\n",
    "    item_dimension = result_dict[\"sample\"][\"item_dimension\"]\n",
    "    sample_size = result_dict[\"sample\"][\"sample_size\"]\n",
    "    print(\"Latent dimension: {0},  Item dimension: {1}, sample size {2} \\\\\".format(latent_dimension, item_dimension, sample_size))\n",
    "    #Performance/time\n",
    "    ep_dict = result_dict[\"early_performance\"]\n",
    "    runtime = np.round(ep_dict[\"run\"][\"runtime\"], 2)\n",
    "    steps = ep_dict[\"run\"][\"number_steps\"]\n",
    "    print(\"Runtime: {0} seconds, {1} steps, {2} seconds per step \\\\\".format(runtime, steps, np.round(runtime/steps, 2)))\n",
    "    #Performance/results\n",
    "    l_optimal = np.round(ep_dict[\"marginal_likelihood\"][\"optimal\"], 2)\n",
    "    l_estimated = np.round(ep_dict[\"marginal_likelihood\"][\"estimated\"], 2)\n",
    "    l_real = np.round(ep_dict[\"marginal_likelihood\"][\"initial\"], 2)\n",
    "    print(\"Optimal marginal Likelihood: {0}, Estimated: {1}, Initial {2}\".format(l_optimal,l_estimated,l_real))\n",
    "    #print(\"Performance: rmse-mean = {0} \\\\\".format(np.round(np.mean(np.array(list(result_dict[\"early_performance\"].values()))), 4)))\n",
    "    rmse_model = ep_dict[\"rmse\"]\n",
    "    \n",
    "    rmse_frame = pd.DataFrame(columns=[\"rmse_A\", \"rmse_delta\", \"rmse_sigma\"])\n",
    "    rmse_frame = rmse_frame.append(rmse_model, ignore_index=True)\n",
    "    index = [\"estimated\"]\n",
    "    for baseline in list(result_dict[\"baselines\"].keys()):\n",
    "        rmse_baseline = result_dict[\"baselines\"][baseline][\"performance\"][\"rmse\"]\n",
    "        rmse_frame = rmse_frame.append(rmse_baseline, ignore_index=True)\n",
    "        index.append(baseline)\n",
    "    rmse_frame.index = index\n",
    "    print(rmse_frame.to_markdown())\n",
    "                                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EM Iteration 2\n",
      "Current Monte Carlo Sample size: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jesper\\anaconda3\\lib\\site-packages\\scipy\\stats\\_qmc.py:2039: UserWarning: The balance properties of Sobol' points require n to be a power of 2.\n",
      "  samples = self.engine.random(n)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 2: current parameter_diff: 1.7696927079916756, current marginal loglikelihood: -370.58996916417544\n",
      "EM Iteration 3\n",
      "Current Monte Carlo Sample size: 300\n",
      "Step: 3: current parameter_diff: 0.42359683758172406, current marginal loglikelihood: -370.10636148292815\n",
      "EM Iteration 4\n",
      "Current Monte Carlo Sample size: 360\n",
      "Step: 4: current parameter_diff: 0.373014145884365, current marginal loglikelihood: -369.74380602753797\n",
      "EM Iteration 5\n",
      "Current Monte Carlo Sample size: 360\n",
      "Step: 5: current parameter_diff: 0.5249486480225427, current marginal loglikelihood: -369.5677709304813\n",
      "EM Iteration 6\n",
      "Current Monte Carlo Sample size: 432\n",
      "Step: 6: current parameter_diff: 0.20546962329286378, current marginal loglikelihood: -369.1280354609925\n",
      "EM Iteration 7\n",
      "Current Monte Carlo Sample size: 432\n",
      "Step: 7: current parameter_diff: 0.12076279038520388, current marginal loglikelihood: -369.0871680390001\n",
      "EM Iteration 8\n",
      "Current Monte Carlo Sample size: 518\n",
      "Step: 8: current parameter_diff: 0.06353642408981242, current marginal loglikelihood: -369.17464634765156\n",
      "EM Iteration 9\n",
      "Current Monte Carlo Sample size: 621\n",
      "Step: 9: current parameter_diff: 0.050799999999999956, current marginal loglikelihood: -369.2535308807064\n",
      "Absolute diff in A:\n",
      "[[0.35944264 0.        ]\n",
      " [0.73634289 0.        ]\n",
      " [0.         0.11655422]\n",
      " [0.3        0.4       ]\n",
      " [0.39169343 0.62474202]\n",
      " [0.         0.3703817 ]]\n",
      "Absolute diff in delta:\n",
      "[0.08004271 0.42631899 0.01949461 0.16034265 0.02963756 0.27774153]\n",
      "Absolute diff in sigma:\n",
      "[[0.    0.127]\n",
      " [0.127 0.   ]]\n",
      "Absolute diff in A:\n",
      "[[0.5 0. ]\n",
      " [1.  0. ]\n",
      " [0.  0.6]\n",
      " [0.3 0.4]\n",
      " [1.  0.1]\n",
      " [0.  0.5]]\n",
      "Absolute diff in delta:\n",
      "[0.08004271 0.41995729 0.05553839 0.16034265 0.7462282  0.04446161]\n",
      "Absolute diff in sigma:\n",
      "[[0.  0.3]\n",
      " [0.3 0. ]]\n",
      "Absolute diff in A:\n",
      "[[0.28303907 0.7408168 ]\n",
      " [1.42548136 0.99182536]\n",
      " [1.74056804 2.64843144]\n",
      " [0.15339304 0.04452695]\n",
      " [0.32779363 0.05496751]\n",
      " [0.71145944 1.5       ]]\n",
      "Absolute diff in delta:\n",
      "[0.0976629  0.38617024 1.41561936 0.2146273  0.23298369 0.20651757]\n",
      "Absolute diff in sigma:\n",
      "[[1.11022302e-16 1.11593770e-01]\n",
      " [1.11593770e-01 2.22044605e-16]]\n",
      "(6_w,12)-aCMA-ES (mu_w=3.7,w_1=40%) in dimension 15 (seed=432723, Sat Oct  8 19:06:34 2022)\n",
      "Iterat #Fevals   function value  axis ratio  sigma  min&max std  t[m:s]\n",
      "    1     12 3.943035786912717e+02 1.0e+00 4.60e-01  4e-01  5e-01 0:00.1\n",
      "    2     24 3.940597872717543e+02 1.1e+00 4.30e-01  4e-01  4e-01 0:00.2\n",
      "    3     36 3.821707091361643e+02 1.2e+00 4.15e-01  4e-01  4e-01 0:00.2\n",
      "[[ 1.         -1.08069158]\n",
      " [-1.08069158  1.        ]]\n",
      "[[1.         1.32166558]\n",
      " [1.32166558 1.        ]]\n",
      "[[1.         1.34109419]\n",
      " [1.34109419 1.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jesper\\anaconda3\\lib\\site-packages\\cma\\utilities\\utils.py:343: UserWarning: function values with index [3] are not finite but [inf]. (class=CMAEvolutionStrategy method=ask iteration=3)\n",
      "  warnings.warn(msg + ' (' +\n",
      "c:\\Users\\Jesper\\anaconda3\\lib\\site-packages\\cma\\utilities\\utils.py:343: UserWarning: function values with index [11] are not finite but [inf]. (class=CMAEvolutionStrategy method=ask iteration=5)\n",
      "  warnings.warn(msg + ' (' +\n",
      "c:\\Users\\Jesper\\anaconda3\\lib\\site-packages\\cma\\utilities\\utils.py:343: UserWarning: function values with index [1] are not finite but [inf]. (class=CMAEvolutionStrategy method=ask iteration=6)\n",
      "  warnings.warn(msg + ' (' +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         1.71821313]\n",
      " [1.71821313 1.        ]]\n",
      "[[1.         1.17121982]\n",
      " [1.17121982 1.        ]]\n",
      "[[1.         1.06951427]\n",
      " [1.06951427 1.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jesper\\anaconda3\\lib\\site-packages\\cma\\utilities\\utils.py:343: UserWarning: function values with index [4] are not finite but [inf]. (class=CMAEvolutionStrategy method=ask iteration=7)\n",
      "  warnings.warn(msg + ' (' +\n",
      "c:\\Users\\Jesper\\anaconda3\\lib\\site-packages\\cma\\utilities\\utils.py:343: UserWarning: function values with index [3] are not finite but [inf]. (class=CMAEvolutionStrategy method=ask iteration=8)\n",
      "  warnings.warn(msg + ' (' +\n",
      "c:\\Users\\Jesper\\anaconda3\\lib\\site-packages\\cma\\utilities\\utils.py:343: UserWarning: function values with index [3] are not finite but [inf]. (class=CMAEvolutionStrategy method=ask iteration=9)\n",
      "  warnings.warn(msg + ' (' +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   53    636 3.680830559292414e+02 2.5e+00 8.05e-02  5e-02  9e-02 0:03.3\n",
      "  100   1200 3.678035683980852e+02 3.7e+00 2.87e-02  2e-02  3e-02 0:06.0\n",
      "  187   2244 3.676182653719185e+02 6.5e+00 7.40e-03  3e-03  1e-02 0:11.0\n",
      "  200   2400 3.677084939338521e+02 6.5e+00 5.68e-03  3e-03  7e-03 0:11.7\n",
      "  300   3600 3.675116698032161e+02 8.9e+00 3.61e-03  1e-03  4e-03 0:17.6\n",
      "  400   4800 3.676025693976969e+02 1.6e+01 8.98e-03  3e-03  1e-02 0:23.5\n",
      "  500   6000 3.674863026095088e+02 2.2e+01 2.49e-03  7e-04  3e-03 0:29.2\n",
      "  600   7200 3.676645762446752e+02 2.7e+01 2.06e-03  6e-04  2e-03 0:35.0\n"
     ]
    }
   ],
   "source": [
    "performance_dict = mirt_performance_benchmark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "##### Results for Quasi Monte-Carlo with increasing sample-size based on ttest\n",
      "Latent dimension: 2,  Item dimension: 6, sample size 100 \\\n",
      "Runtime: 4.15 seconds, 16 steps, 0.26 seconds per step \\\n",
      "Optimal marginal Likelihood: -367.97, Estimated: -363.66, Initial -370.45\n",
      "|               |   rmse_A |   rmse_delta |   rmse_sigma |\n",
      "|:--------------|---------:|-------------:|-------------:|\n",
      "| estimated     | 0.361749 |     0.369746 |    0.0462448 |\n",
      "| early_initial | 0.509902 |     0.383683 |    0.212132  |\n",
      "| girth         | 0.90968  |     0.367442 |    0.0977334 |\n",
      "| early_direct  | 0.362239 |     0.343475 |    0.128536  |\n"
     ]
    }
   ],
   "source": [
    "print_result(performance_dict, \"Quasi Monte-Carlo with increasing sample-size based on ttest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------\n",
    "##### Results for Naive, all-Genetic, no vectorization\n",
    "Runtime: 29100 seconds, 100+ steps, 291 seconds per step\\\n",
    "Performance: rmse-mean = 0.5896464054719196\n",
    "\n",
    "------------------------------------\n",
    "##### Results for Vectorized q_item\n",
    "Runtime: 613.3871161937714 seconds, 100+ steps, 6.0731397642947655 seconds per step \\\n",
    "Performance: rmse-mean = 0.6466789259215839\n",
    "\n",
    "------------------------------------\n",
    "##### Results for More precise results through higher N and pop_size\n",
    "Runtime: 2239.073846578598 seconds, 100+ steps, 22.169047985926714 seconds per step \\\n",
    "Performance: rmse-mean = 0.6384660709857508\n",
    "\n",
    "------------------------------------\n",
    "##### Results for Debug GA sorting, Add Likelihood-based stopping criterion\n",
    "Runtime: 135.11203932762146 seconds, 7 steps, 19.301719903945923 seconds per step \\\n",
    "Performance: rmse-mean = 0.5616448369465917\n",
    "\n",
    "------------------------------------\n",
    "##### Results for Add vectorization in Q_0\n",
    "Runtime: 228.78 seconds, 17 steps, 13.46 seconds per step \\\n",
    "Performance: rmse-mean = 0.6174\n",
    "\n",
    "------------------------------------\n",
    "##### Results for Add vectorization in E-Step normalizing constant\n",
    "Runtime: 28.37 seconds, 9 steps, 3.15 seconds per step \\\n",
    "Performance: rmse-mean = 0.5808\n",
    "\n",
    "------------------------------------\n",
    "##### Results for Add Suggested Initial Parameters (Zhang)\n",
    "Runtime: 61.22 seconds, 19 steps, 3.22 seconds per step \\\n",
    "Performance: rmse-mean = 0.5625\n",
    "\n",
    "------------------------------------\n",
    "##### Results for Fixed Q_item\n",
    "Runtime: 81.11 seconds, 12 steps, 6.76 seconds per step \\\n",
    "Optimal marginal Likelihood: -375.43, Estimated: -393.8, Initial -391.83\n",
    "|           |   rmse_A |   rmse_delta |   rmse_sigma |\n",
    "|:----------|---------:|-------------:|-------------:|\n",
    "| Estimated | 0.762005 |     0.512703 |     0.600404 |\n",
    "| Girth     | 1.61804  |     0.750525 |   nan        |\n",
    "| Initial   | 0.770281 |     0.227528 |     0.141421 |\n",
    "\n",
    "------------------------------------\n",
    "##### Results for Inproved GA stoppimg rule\n",
    "Runtime: 42.54 seconds, 7 steps, 6.08 seconds per step \\\n",
    "Optimal marginal Likelihood: -378.68, Estimated: -391.87, Initial -378.08\n",
    "|           |   rmse_A |   rmse_delta |   rmse_sigma |\n",
    "|:----------|---------:|-------------:|-------------:|\n",
    "| Estimated | 0.845078 |     0.568092 |    0.167374  |\n",
    "| Girth     | 0.930362 |     0.554795 |    0.141421  |\n",
    "| direct    | 0.401578 |     0.609516 |    0.0526782 |\n",
    "| Initial   | 0.509902 |     0.364352 |    0.141421  |\n",
    "\n",
    "------------------------------------\n",
    "##### Results for pycma ga used\n",
    "Runtime: 489.8 seconds, 16 steps, 30.61 seconds per step \\\n",
    "Optimal marginal Likelihood: -381.34, Estimated: -414.28, Initial -379.77\n",
    "|           |   rmse_A |   rmse_delta |   rmse_sigma |\n",
    "|:----------|---------:|-------------:|-------------:|\n",
    "| Estimated | 0.942127 |     0.505808 |     0.215139 |\n",
    "| Girth     | 1.42144  |     0.632431 |   nan        |\n",
    "| Initial   | 0.509902 |     0.489947 |     0.141421 |\n",
    "\n",
    "------------------------------------\n",
    "##### Results for pycma, higher sigma0\n",
    "Runtime: 282.36 seconds, 10 steps, 28.24 seconds per step \\\n",
    "Optimal marginal Likelihood: -368.93, Estimated: -399.56, Initial -369.53\n",
    "|           |   rmse_A |   rmse_delta |   rmse_sigma |\n",
    "|:----------|---------:|-------------:|-------------:|\n",
    "| Estimated | 0.898735 |     0.48221  |     0.195257 |\n",
    "| Girth     | 1.79316  |     0.515695 |   nan        |\n",
    "| direct    | 0.458306 |     0.262779 |     0.139413 |\n",
    "| Initial   | 0.509902 |     0.273981 |     0.141421 |\n",
    "\n",
    "------------------------------------\n",
    "##### Results for Monte Carlo with seed\n",
    "Runtime: 97.6 seconds, 9 steps, 10.84 seconds per step \\\n",
    "Optimal marginal Likelihood: -376.79, Estimated: -399.07, Initial -372.28\n",
    "|           |      rmse_A |   rmse_delta |   rmse_sigma |\n",
    "|:----------|------------:|-------------:|-------------:|\n",
    "| Estimated |    1.09615  |     0.970204 |     0.120425 |\n",
    "| Girth     |    1.45372  |     0.34729  |     0.141421 |\n",
    "| direct    | 2935.78     |  1035.68     |     0.014461 |\n",
    "| Initial   |    0.509902 |     0.445143 |     0.141421 |\n",
    "\n",
    "------------------------------------\n",
    "##### Results for Monte Cralo with fixed sample per em-step\n",
    "Runtime: 1.22 seconds, 5 steps, 0.24 seconds per step \\\n",
    "Optimal marginal Likelihood: -381.06, Estimated: -373.26, Initial -377.69\n",
    "|           |   rmse_A |   rmse_delta |   rmse_sigma |\n",
    "|:----------|---------:|-------------:|-------------:|\n",
    "| Estimated | 0.500043 |     0.273166 |    0.0853068 |\n",
    "| Girth     | 0.98542  |     0.334766 |    0.141421  |\n",
    "| direct    | 0.57518  |     0.335156 |    0.0914744 |\n",
    "| Initial   | 0.509902 |     0.431741 |    0.141421  |\n",
    "\n",
    "------------------------------------\n",
    "##### Results for Newton Raphson of Q_0 with approximate second derivative\n",
    "Latent dimension: 2,  Item dimension: 6, sample size 100 \\\n",
    "Runtime: 2.2 seconds, 9 steps, 0.24 seconds per step \\\n",
    "Optimal marginal Likelihood: -389.58, Estimated: -375.96, Initial -386.41\n",
    "|               |   rmse_A |   rmse_delta |   rmse_sigma |\n",
    "|:--------------|---------:|-------------:|-------------:|\n",
    "| estimated     | 0.452731 |     0.428534 |     0.011738 |\n",
    "| early_initial | 0.509902 |     0.451316 |     0.212132 |\n",
    "| girth         | 1.54173  |     0.489318 |     0.164638 |\n",
    "| early_direct  | 1.10778  |     0.416042 |     0.189961 |\n",
    "\n",
    "------------------------------------\n",
    "##### Results for Quasi Monte-Carlo with increasing sample-size based on ttest'scipy\n",
    "Latent dimension: 2,  Item dimension: 6, sample size 100 \\\n",
    "Runtime: 589.08 seconds, 52 steps, 11.33 seconds per step \\\n",
    "Optimal marginal Likelihood: -371.52, Estimated: -366.22, Initial -373.6\n",
    "|               |   rmse_A |   rmse_delta |   rmse_sigma |\n",
    "|:--------------|---------:|-------------:|-------------:|\n",
    "| estimated     | 0.287802 |     0.302635 |    0.0019799 |\n",
    "| early_initial | 0.509902 |     0.292938 |    0.212132  |\n",
    "| girth         | 1.1188   |     0.385494 |    0.0478773 |\n",
    "| early_direct  | 0.282345 |     0.319402 |    0.0080443 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procedure for better runtime\n",
    "\n",
    "1. Add Performance Benchmark (done)\n",
    "2. Add Vectorization to q_item (done)\n",
    "3. Add better Initialization (done)\n",
    "3. Add Vectorization to q_0 (done)\n",
    "4. Add q_0 Derivation 1. + BFGS (done)\n",
    "5. Add q_0 Derivation 2. + Newton Raphson\n",
    "6. Use cython (maybe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1: MIRT-2PL Parameter Recovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unittest import result\n",
    "\n",
    "def mirt_param_recovery(sample_size, item_dimension = 20, latent_dimension=3, q_type=\"seperated\", girth=True, stop_threshold=0.2, ensure_id=False, q_share=0.0) -> dict:\n",
    "    \n",
    "    #Simulate Responses\n",
    "    simulation = item_response_simulation(item_dimension=item_dimension, latent_dimension=latent_dimension)\n",
    "    parameter_dict = simulation.set_up(q_structure=q_type, q_share=q_share, ensure_id=ensure_id)\n",
    "    sample = simulation.sample(sample_size=sample_size)\n",
    "\n",
    "    #Define Population\n",
    "    #population = respondent_population(latent_dimension=latent_dimension)\n",
    "    real_latent_cov = parameter_dict[\"real_early_parameters\"][\"person_parameters\"][\"covariance\"]\n",
    "    print(\"Real latent covariance: {0}\".format(real_latent_cov))\n",
    "    \n",
    "\n",
    "    #Sample responses\n",
    "    #response_simulation_obj = response_simulation(population=population, item_dimension=item_dimension)\n",
    "    #response_simulation_obj.initialize_random_q_structured_matrix(structure=q_type, ensure_id=ensure_id)\n",
    "    #early_item_parameters = response_simulation_obj.initialize_random_item_parameters()\n",
    "    parameter_dict[\"real_early_parameters\"].update({\"item_dimension\": item_dimension, \"latent_dimension\": latent_dimension})\n",
    "    real_early_parameters = parameter_dict[\"real_early_parameters\"]#{\"item_parameters\": early_item_parameters, \"person_parameters\": {\"covariance\": real_latent_cov}}\n",
    "\n",
    "    #Fit Parameters\n",
    "    #Initialize model\n",
    "    model = models.mirt_2pl(latent_dimension=latent_dimension, item_dimension=item_dimension, Q=real_early_parameters[\"item_parameters\"][\"q_matrix\"])\n",
    "    print(\"Covariance matrix is good: {0}\".format(model.check_sigma(real_latent_cov)))\n",
    "    model.initialize_from_responses(response_data=sample[\"early_responses\"])\n",
    "    initial_early_parameters = model.get_parameters()\n",
    "    e_step = em_algorithm.e_step_ga_mml(model=model)\n",
    "    m_step = em_algorithm.m_step_ga_mml(model)\n",
    "    em = em_algorithm.em_algo(e_step=e_step, m_step=m_step, model=model)\n",
    "\n",
    "    #Fit Model\n",
    "    start_time = time.time()\n",
    "    em.fit(sample[\"early_responses\"], max_iter=100, stop_threshold=stop_threshold)\n",
    "    run_time =  (time.time() - start_time)\n",
    "\n",
    "    #Measure Performance\n",
    "    early_estimated_item_parameters = em.model.item_parameters\n",
    "    early_estimated_person_parameters = em.model.person_parameters\n",
    "\n",
    "    #Create Baselines\n",
    "    baselines = {\"early_initial\": {\"parameters\": initial_early_parameters}}\n",
    "    if girth==True:\n",
    "        baselines[\"girth\"] = {}\n",
    "\n",
    "    #Create results\n",
    "    early_estimated_parameters = em.model.get_parameters()\n",
    "\n",
    "    parameter_dict = create_parameter_dict(estimated_early_parameters=early_estimated_parameters,\n",
    "                          real_early_parameters = real_early_parameters,\n",
    "                          estimated_late_parameters=None, real_late_parameters=None)\n",
    "    run_dict = {\"early\": {\"runtime\": run_time,\n",
    "                \"number_steps\": em.n_steps}}\n",
    "    performance_dict = create_performance_dict(parameter_dict=parameter_dict, run_dict=run_dict, sample=sample, baselines=baselines, model=model)\n",
    "\n",
    "    return(performance_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real latent covariance: [[1.]]\n",
      "Covariance matrix is good: True\n",
      "EM Iteration 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jesper\\anaconda3\\lib\\site-packages\\scipy\\stats\\_qmc.py:2039: UserWarning: The balance properties of Sobol' points require n to be a power of 2.\n",
      "  samples = self.engine.random(n)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Monte Carlo Sample size: 150\n",
      "Step: 2: current parameter_diff: 20.92439564532225, current marginal loglikelihood: -8910.492710324956\n",
      "EM Iteration 3\n",
      "Current Monte Carlo Sample size: 180\n",
      "Step: 3: current parameter_diff: 9.809719715710592, current marginal loglikelihood: -8834.26793346509\n",
      "EM Iteration 4\n",
      "Current Monte Carlo Sample size: 216\n",
      "Step: 4: current parameter_diff: 5.074222025392416, current marginal loglikelihood: -8804.164133349997\n",
      "EM Iteration 5\n",
      "Current Monte Carlo Sample size: 259\n",
      "Step: 5: current parameter_diff: 2.297277979962996, current marginal loglikelihood: -8796.737923373841\n",
      "EM Iteration 6\n",
      "Current Monte Carlo Sample size: 310\n",
      "Step: 6: current parameter_diff: 2.75208250396536, current marginal loglikelihood: -8795.999486702127\n",
      "EM Iteration 7\n",
      "Current Monte Carlo Sample size: 372\n",
      "Step: 7: current parameter_diff: 0.3226698388793409, current marginal loglikelihood: -8793.867408990402\n",
      "EM Iteration 8\n",
      "Current Monte Carlo Sample size: 446\n",
      "Step: 8: current parameter_diff: 1.2038431953447497, current marginal loglikelihood: -8791.7166154968\n",
      "EM Iteration 9\n",
      "Current Monte Carlo Sample size: 535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jesper\\Documents\\GitHub\\Knowledge-Growth-Prediction\\em_algorithm\\e_step_mirt_2pl.py:260: RuntimeWarning: divide by zero encountered in log\n",
      "  icc_values), r_item_theta) + np.multiply(np.log(1-icc_values), np.subtract(r_0_theta, r_item_theta))\n",
      "c:\\Users\\Jesper\\Documents\\GitHub\\Knowledge-Growth-Prediction\\em_algorithm\\e_step_mirt_2pl.py:260: RuntimeWarning: invalid value encountered in multiply\n",
      "  icc_values), r_item_theta) + np.multiply(np.log(1-icc_values), np.subtract(r_0_theta, r_item_theta))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 9: current parameter_diff: 2.434544830313956, current marginal loglikelihood: -8794.794419833572\n",
      "EM Iteration 10\n",
      "Current Monte Carlo Sample size: 642\n",
      "Step: 10: current parameter_diff: 0.2447697163707434, current marginal loglikelihood: -8794.436511827398\n",
      "EM Iteration 11\n",
      "Current Monte Carlo Sample size: 770\n",
      "Step: 11: current parameter_diff: 1.0991016801058746, current marginal loglikelihood: -8790.755641813757\n",
      "EM Iteration 12\n",
      "Current Monte Carlo Sample size: 924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jesper\\Documents\\GitHub\\Knowledge-Growth-Prediction\\em_algorithm\\m_step_mirt_2pl.py:70: RuntimeWarning: overflow encountered in exp\n",
      "  population = random.choices(population=population_base, weights=np.exp(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 12: current parameter_diff: 3.0580715482334835, current marginal loglikelihood: -8819.665499989813\n",
      "EM Iteration 13\n",
      "Current Monte Carlo Sample size: 924\n",
      "Step: 13: current parameter_diff: 3.6800389299500487, current marginal loglikelihood: -8912.144109280896\n",
      "EM Iteration 14\n",
      "Current Monte Carlo Sample size: 1108\n",
      "Step: 14: current parameter_diff: 5.75286832444813, current marginal loglikelihood: -8830.867078491956\n",
      "EM Iteration 15\n",
      "Current Monte Carlo Sample size: 1108\n",
      "Step: 15: current parameter_diff: 2.734590776760328, current marginal loglikelihood: -8874.298894890944\n",
      "EM Iteration 16\n",
      "Current Monte Carlo Sample size: 1108\n",
      "Step: 16: current parameter_diff: 2.770682917042631, current marginal loglikelihood: -8891.349486464915\n",
      "EM Iteration 17\n",
      "Current Monte Carlo Sample size: 1329\n",
      "Step: 17: current parameter_diff: 3.892323472787454, current marginal loglikelihood: -8844.21780037292\n",
      "EM Iteration 18\n",
      "Current Monte Carlo Sample size: 1594\n",
      "Step: 18: current parameter_diff: 4.776805134864283, current marginal loglikelihood: -8869.018494839322\n",
      "EM Iteration 19\n",
      "Current Monte Carlo Sample size: 1912\n",
      "Step: 19: current parameter_diff: 3.183748800897347, current marginal loglikelihood: -8942.109397663024\n",
      "EM Iteration 20\n",
      "Current Monte Carlo Sample size: 2294\n",
      "Step: 20: current parameter_diff: 3.2553603021754953, current marginal loglikelihood: -8999.180816739521\n",
      "EM Iteration 21\n",
      "Current Monte Carlo Sample size: 2752\n",
      "Step: 21: current parameter_diff: 3.802253201551746, current marginal loglikelihood: -8970.604190844922\n",
      "EM Iteration 22\n",
      "Current Monte Carlo Sample size: 2752\n",
      "Step: 22: current parameter_diff: 4.555091105487184, current marginal loglikelihood: -8965.860861904534\n",
      "EM Iteration 23\n",
      "Current Monte Carlo Sample size: 3302\n",
      "Step: 23: current parameter_diff: 3.8530107596424537, current marginal loglikelihood: -8866.853863417577\n",
      "EM Iteration 24\n",
      "Current Monte Carlo Sample size: 3302\n",
      "Step: 24: current parameter_diff: 4.002838186775151, current marginal loglikelihood: -8941.392078409935\n",
      "EM Iteration 25\n",
      "Current Monte Carlo Sample size: 3302\n",
      "Step: 25: current parameter_diff: 3.9415863243888207, current marginal loglikelihood: -9045.772965444416\n",
      "EM Iteration 26\n",
      "Current Monte Carlo Sample size: 3962\n",
      "Step: 26: current parameter_diff: 7.52547707558007, current marginal loglikelihood: -9104.631415830354\n",
      "EM Iteration 27\n",
      "Current Monte Carlo Sample size: 4754\n",
      "Step: 27: current parameter_diff: 7.004814901427139, current marginal loglikelihood: -9056.82782214487\n",
      "EM Iteration 28\n",
      "Current Monte Carlo Sample size: 5704\n",
      "Step: 28: current parameter_diff: 3.3517332943817504, current marginal loglikelihood: -9034.198194802231\n",
      "EM Iteration 29\n",
      "Current Monte Carlo Sample size: 6844\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Jesper\\Documents\\GitHub\\Knowledge-Growth-Prediction\\simulation_experiments.ipynb Zelle 14\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Jesper/Documents/GitHub/Knowledge-Growth-Prediction/simulation_experiments.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#Univariate IRT Recovery\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Jesper/Documents/GitHub/Knowledge-Growth-Prediction/simulation_experiments.ipynb#X20sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m result_dict \u001b[39m=\u001b[39m mirt_param_recovery(\u001b[39m1000\u001b[39;49m, q_type\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msingular\u001b[39;49m\u001b[39m\"\u001b[39;49m, item_dimension\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m, latent_dimension\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, stop_threshold\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\Jesper\\Documents\\GitHub\\Knowledge-Growth-Prediction\\simulation_experiments.ipynb Zelle 14\u001b[0m in \u001b[0;36mmirt_param_recovery\u001b[1;34m(sample_size, item_dimension, latent_dimension, q_type, girth, stop_threshold, ensure_id, q_share)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Jesper/Documents/GitHub/Knowledge-Growth-Prediction/simulation_experiments.ipynb#X20sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39m#Fit Model\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Jesper/Documents/GitHub/Knowledge-Growth-Prediction/simulation_experiments.ipynb#X20sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Jesper/Documents/GitHub/Knowledge-Growth-Prediction/simulation_experiments.ipynb#X20sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m em\u001b[39m.\u001b[39;49mfit(sample[\u001b[39m\"\u001b[39;49m\u001b[39mearly_responses\u001b[39;49m\u001b[39m\"\u001b[39;49m], max_iter\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, stop_threshold\u001b[39m=\u001b[39;49mstop_threshold)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Jesper/Documents/GitHub/Knowledge-Growth-Prediction/simulation_experiments.ipynb#X20sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m run_time \u001b[39m=\u001b[39m  (time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Jesper/Documents/GitHub/Knowledge-Growth-Prediction/simulation_experiments.ipynb#X20sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39m#Measure Performance\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jesper\\Documents\\GitHub\\Knowledge-Growth-Prediction\\em_algorithm\\em_algorithm.py:43\u001b[0m, in \u001b[0;36mem_algorithm.fit\u001b[1;34m(self, data, hyper_params, max_iter, stop_threshold)\u001b[0m\n\u001b[0;32m     41\u001b[0m last_step_marginal_loglikelihood \u001b[39m=\u001b[39m marginal_loglikelihood\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m     42\u001b[0m \u001b[39m# print(\"E-step\")\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m posterior_expectation \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49me_step\u001b[39m.\u001b[39;49mstep(\n\u001b[0;32m     44\u001b[0m     response_data\u001b[39m=\u001b[39;49mdata, \u001b[39miter\u001b[39;49m\u001b[39m=\u001b[39;49mi)\n\u001b[0;32m     45\u001b[0m \u001b[39m# print(\"M-step\")\u001b[39;00m\n\u001b[0;32m     46\u001b[0m current_parameters, log_likelihood \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mm_step\u001b[39m.\u001b[39mstep(\n\u001b[0;32m     47\u001b[0m     pe_functions\u001b[39m=\u001b[39mposterior_expectation)\n",
      "File \u001b[1;32mc:\\Users\\Jesper\\Documents\\GitHub\\Knowledge-Growth-Prediction\\em_algorithm\\e_step_mirt_2pl.py:97\u001b[0m, in \u001b[0;36me_step_ga_mml.step\u001b[1;34m(self, response_data, current_item_parameters, current_person_parameters, iter)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mCurrent Monte Carlo Sample size: \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mN))\n\u001b[0;32m     95\u001b[0m theta_sample \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39msample_competency(\n\u001b[0;32m     96\u001b[0m     sample_size\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mN, qmc\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m---> 97\u001b[0m \u001b[39mreturn\u001b[39;00m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprepare_q_functions(theta_sample, response_data, normalising_constant_array))\n",
      "File \u001b[1;32mc:\\Users\\Jesper\\Documents\\GitHub\\Knowledge-Growth-Prediction\\em_algorithm\\e_step_mirt_2pl.py:105\u001b[0m, in \u001b[0;36me_step_ga_mml.prepare_q_functions\u001b[1;34m(self, theta_sample, response_data, normalising_constant_array)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[39m# Calculate repeating inner functions\u001b[39;00m\n\u001b[0;32m    103\u001b[0m r_0_theta \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mr_0(\n\u001b[0;32m    104\u001b[0m     theta_sample, normalising_constant_array, response_data)\n\u001b[1;32m--> 105\u001b[0m r_item_theta_list \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mr_item(item, theta_sample, normalising_constant_array, response_data)\n\u001b[0;32m    106\u001b[0m                      \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, J)]\n\u001b[0;32m    107\u001b[0m \u001b[39m# Calculate final q-functions\u001b[39;00m\n\u001b[0;32m    108\u001b[0m q_0 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mq_0(\n\u001b[0;32m    109\u001b[0m     theta\u001b[39m=\u001b[39mtheta_sample, normalising_constant_array\u001b[39m=\u001b[39mnormalising_constant_array, response_data\u001b[39m=\u001b[39mresponse_data)\n",
      "File \u001b[1;32mc:\\Users\\Jesper\\Documents\\GitHub\\Knowledge-Growth-Prediction\\em_algorithm\\e_step_mirt_2pl.py:105\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[39m# Calculate repeating inner functions\u001b[39;00m\n\u001b[0;32m    103\u001b[0m r_0_theta \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mr_0(\n\u001b[0;32m    104\u001b[0m     theta_sample, normalising_constant_array, response_data)\n\u001b[1;32m--> 105\u001b[0m r_item_theta_list \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mr_item(item, theta_sample, normalising_constant_array, response_data)\n\u001b[0;32m    106\u001b[0m                      \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, J)]\n\u001b[0;32m    107\u001b[0m \u001b[39m# Calculate final q-functions\u001b[39;00m\n\u001b[0;32m    108\u001b[0m q_0 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mq_0(\n\u001b[0;32m    109\u001b[0m     theta\u001b[39m=\u001b[39mtheta_sample, normalising_constant_array\u001b[39m=\u001b[39mnormalising_constant_array, response_data\u001b[39m=\u001b[39mresponse_data)\n",
      "File \u001b[1;32mc:\\Users\\Jesper\\Documents\\GitHub\\Knowledge-Growth-Prediction\\em_algorithm\\e_step_mirt_2pl.py:178\u001b[0m, in \u001b[0;36me_step_ga_mml.r_item\u001b[1;34m(self, item, theta, normalising_constant_array, response_data)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mr_item\u001b[39m(\u001b[39mself\u001b[39m, item: \u001b[39mint\u001b[39m, theta: np\u001b[39m.\u001b[39marray, normalising_constant_array, response_data):\n\u001b[1;32m--> 178\u001b[0m     numerator \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mresponse_matrix_probability(\n\u001b[0;32m    179\u001b[0m         theta\u001b[39m=\u001b[39;49mtheta, response_matrix\u001b[39m=\u001b[39;49mresponse_data\u001b[39m.\u001b[39;49mto_numpy()))\n\u001b[0;32m    180\u001b[0m     \u001b[39m# This coefficient is different to r_0\u001b[39;00m\n\u001b[0;32m    181\u001b[0m     numerator \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmultiply(\n\u001b[0;32m    182\u001b[0m         numerator, response_data\u001b[39m.\u001b[39miloc[:, item]\u001b[39m.\u001b[39mto_numpy()\u001b[39m.\u001b[39mtranspose())\n",
      "File \u001b[1;32mc:\\Users\\Jesper\\Documents\\GitHub\\Knowledge-Growth-Prediction\\models\\mirt_2pl.py:152\u001b[0m, in \u001b[0;36mmirt_2pl.response_matrix_probability\u001b[1;34m(self, theta, response_matrix, A, delta)\u001b[0m\n\u001b[0;32m    148\u001b[0m correct_response_probabilities \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mexpand_dims(\n\u001b[0;32m    149\u001b[0m     correct_response_probabilities, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m    150\u001b[0m probability_vector \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39madd(np\u001b[39m.\u001b[39mmultiply(correct_response_probabilities, response_matrix),\n\u001b[0;32m    151\u001b[0m                             np\u001b[39m.\u001b[39mmultiply(np\u001b[39m.\u001b[39msubtract(\u001b[39m1\u001b[39m, correct_response_probabilities), np\u001b[39m.\u001b[39msubtract(\u001b[39m1\u001b[39m, response_matrix)))\n\u001b[1;32m--> 152\u001b[0m probability \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mprod(probability_vector, axis\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n\u001b[0;32m    153\u001b[0m \u001b[39mreturn\u001b[39;00m(probability)\n",
      "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mprod\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Jesper\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2999\u001b[0m, in \u001b[0;36mprod\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   2881\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_prod_dispatcher)\n\u001b[0;32m   2882\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprod\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue,\n\u001b[0;32m   2883\u001b[0m          initial\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue, where\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue):\n\u001b[0;32m   2884\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   2885\u001b[0m \u001b[39m    Return the product of array elements over a given axis.\u001b[39;00m\n\u001b[0;32m   2886\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2997\u001b[0m \u001b[39m    10\u001b[39;00m\n\u001b[0;32m   2998\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2999\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapreduction(a, np\u001b[39m.\u001b[39;49mmultiply, \u001b[39m'\u001b[39;49m\u001b[39mprod\u001b[39;49m\u001b[39m'\u001b[39;49m, axis, dtype, out,\n\u001b[0;32m   3000\u001b[0m                           keepdims\u001b[39m=\u001b[39;49mkeepdims, initial\u001b[39m=\u001b[39;49minitial, where\u001b[39m=\u001b[39;49mwhere)\n",
      "File \u001b[1;32mc:\\Users\\Jesper\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:87\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     85\u001b[0m             \u001b[39mreturn\u001b[39;00m reduction(axis\u001b[39m=\u001b[39maxis, out\u001b[39m=\u001b[39mout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpasskwargs)\n\u001b[1;32m---> 87\u001b[0m \u001b[39mreturn\u001b[39;00m ufunc\u001b[39m.\u001b[39;49mreduce(obj, axis, dtype, out, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpasskwargs)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Univariate IRT Recovery\n",
    "result_dict = mirt_param_recovery(1000, q_type=\"singular\", item_dimension=20, latent_dimension=1, stop_threshold=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "##### Results for Monte Carlo sample varying through ttest\n",
      "Latent dimension: 1,  Item dimension: 20, sample size 1000 \\\n",
      "Runtime: 21.38 seconds, 10 steps, 2.14 seconds per step \\\n",
      "Optimal marginal Likelihood: -10094.15, Estimated: -10067.58, Initial -10671.51\n",
      "|               |   rmse_A |   rmse_delta |   rmse_sigma |\n",
      "|:--------------|---------:|-------------:|-------------:|\n",
      "| estimated     |  1.76372 |      3.08965 |            0 |\n",
      "| early_initial |  3.07064 |      4.0076  |            0 |\n",
      "| girth         |  1.4954  |      6.8503  |            0 |\n"
     ]
    }
   ],
   "source": [
    "print_result(result_dict, \"Monte Carlo sample varying through ttest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate IRT/Full GA\n",
    "\n",
    "------------------------------------\n",
    "##### Item Dimension=12, sample_size=200: Results for Fixed sample per em-step\n",
    "Runtime: 4.38 seconds, 7 steps, 0.63 seconds per step \\\n",
    "Optimal marginal Likelihood: -1284.1, Estimated: -1273.09, Initial -1330.43\n",
    "|           |   rmse_A |   rmse_delta |   rmse_sigma |\n",
    "|:----------|---------:|-------------:|-------------:|\n",
    "| Estimated | 0.508687 |     0.196944 |            0 |\n",
    "| Girth     | 0.377882 |     2.65875  |            0 |\n",
    "| direct    | 0.305489 |     0.318168 |            0 |\n",
    "| Initial   | 1.5583   |     0.861273 |            0 |\n",
    "\n",
    "------------------------------------\n",
    "##### Item Dimension=20, sample_size=1000: Results for Fixed sample per em-step\n",
    "Runtime: 85.11 seconds, 19 steps, 4.48 seconds per step \\\n",
    "Optimal marginal Likelihood: -9199.01, Estimated: -9183.03, Initial -9784.69\n",
    "|           |   rmse_A |   rmse_delta |   rmse_sigma |\n",
    "|:----------|---------:|-------------:|-------------:|\n",
    "| Estimated | 0.352003 |     0.578688 |            0 |\n",
    "| Girth     | 0.468473 |     4.98511  |            0 |\n",
    "| Initial   | 1.66615  |     2.01114  |            0 |\n",
    "\n",
    "------------------------------------\n",
    "##### Results for Monte Carlo sample varying through ttest\n",
    "Latent dimension: 1,  Item dimension: 20, sample size 1000 \\\n",
    "Runtime: 31.86 seconds, 10 steps, 3.19 seconds per step \\\n",
    "Optimal marginal Likelihood: -9619.61, Estimated: -9601.49, Initial -9970.74\n",
    "|               |   rmse_A |   rmse_delta |   rmse_sigma |\n",
    "|:--------------|---------:|-------------:|-------------:|\n",
    "| estimated     | 0.175897 |     0.223543 |            0 |\n",
    "| early_initial | 1.21508  |     1.78456  |            0 |\n",
    "| girth         | 0.327131 |     4.71968  |            0 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real latent covariance: [[1.         0.56672093]\n",
      " [0.56672093 1.        ]]\n",
      "Covariance matrix is good: True\n",
      "EM Iteration 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jesper\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_qmc.py:2039: UserWarning: The balance properties of Sobol' points require n to be a power of 2.\n",
      "  samples = self.engine.random(n)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Monte Carlo Sample size: 300\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 2: current parameter_diff: 9.323444830286167, current marginal loglikelihood: -11834.985275023937\n",
      "EM Iteration 3\n",
      "Current Monte Carlo Sample size: 300\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 3: current parameter_diff: 5.460237617530897, current marginal loglikelihood: -11725.273459185906\n",
      "EM Iteration 4\n",
      "Current Monte Carlo Sample size: 300\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 4: current parameter_diff: 3.045977062824834, current marginal loglikelihood: -11695.808137179862\n",
      "EM Iteration 5\n",
      "Current Monte Carlo Sample size: 300\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 5: current parameter_diff: 1.0027257796336433, current marginal loglikelihood: -11687.160890125586\n",
      "EM Iteration 6\n",
      "Current Monte Carlo Sample size: 360\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 6: current parameter_diff: 0.4736484695346386, current marginal loglikelihood: -11687.932253978033\n",
      "EM Iteration 7\n",
      "Current Monte Carlo Sample size: 360\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 7: current parameter_diff: 1.122178657409971, current marginal loglikelihood: -11679.577627814007\n",
      "EM Iteration 8\n",
      "Current Monte Carlo Sample size: 432\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 8: current parameter_diff: 0.5820842920175726, current marginal loglikelihood: -11679.346482238776\n",
      "EM Iteration 9\n",
      "Current Monte Carlo Sample size: 518\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 9: current parameter_diff: 0.4010703101541926, current marginal loglikelihood: -11672.945828583248\n",
      "EM Iteration 10\n",
      "Current Monte Carlo Sample size: 518\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 10: current parameter_diff: 0.262237382047591, current marginal loglikelihood: -11670.934539365433\n",
      "EM Iteration 11\n",
      "Current Monte Carlo Sample size: 518\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 11: current parameter_diff: 0.1643188563894113, current marginal loglikelihood: -11670.443921931801\n",
      "EM Iteration 12\n",
      "Current Monte Carlo Sample size: 621\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 12: current parameter_diff: 0.16017244460535973, current marginal loglikelihood: -11670.298906632506\n",
      "EM Iteration 13\n",
      "Current Monte Carlo Sample size: 621\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 13: current parameter_diff: 0.22232906490199686, current marginal loglikelihood: -11670.650276946148\n",
      "Absolute diff in A:\n",
      "[[0.48061468 0.        ]\n",
      " [0.10186194 0.        ]\n",
      " [0.07530391 0.        ]\n",
      " [0.01219106 0.        ]\n",
      " [0.1947479  0.        ]\n",
      " [0.307554   0.        ]\n",
      " [0.21783572 0.        ]\n",
      " [0.20926335 0.        ]\n",
      " [0.         0.17205635]\n",
      " [0.         0.06848324]\n",
      " [0.         0.04977085]\n",
      " [0.         0.00136171]\n",
      " [0.         0.26235393]\n",
      " [0.         0.1163724 ]\n",
      " [0.         0.25674346]\n",
      " [0.         0.48317371]\n",
      " [0.         0.07872766]\n",
      " [0.         0.66064566]\n",
      " [0.         0.10009616]\n",
      " [0.         0.03326905]]\n",
      "Absolute diff in delta:\n",
      "[0.09155308 0.06332839 0.13639562 0.00771792 0.12170771 0.07483\n",
      " 0.01736434 0.1316043  0.02992432 0.10298391 0.1020651  0.06240361\n",
      " 0.0847465  0.03916121 0.10368726 0.0836306  0.09750131 0.0046549\n",
      " 0.13008891 0.02317328]\n",
      "Absolute diff in sigma:\n",
      "[[0.         0.03042093]\n",
      " [0.03042093 0.        ]]\n",
      "Absolute diff in A:\n",
      "[[1.46379985 0.        ]\n",
      " [0.28988038 0.        ]\n",
      " [0.5087978  0.        ]\n",
      " [0.96286505 0.        ]\n",
      " [0.66396123 0.        ]\n",
      " [1.06642472 0.        ]\n",
      " [0.48022021 0.        ]\n",
      " [1.17052876 0.        ]\n",
      " [0.         0.28497545]\n",
      " [0.         0.51675983]\n",
      " [0.         0.34038012]\n",
      " [0.         0.93205605]\n",
      " [0.         1.91160707]\n",
      " [0.         1.12259552]\n",
      " [0.         0.93402767]\n",
      " [0.         1.47202541]\n",
      " [0.         0.3462454 ]\n",
      " [0.         2.75665751]\n",
      " [0.         1.07624637]\n",
      " [0.         0.03326905]]\n",
      "Absolute diff in delta:\n",
      "[0.07370594 0.14730276 0.17855233 0.00368733 0.89372621 0.07245916\n",
      " 0.01941136 0.97278881 0.10225011 0.08103102 0.06086546 0.0371146\n",
      " 0.61509311 0.10393726 0.78081386 0.04638536 0.1014909  0.4816339\n",
      " 0.08678712 0.1299196 ]\n",
      "Absolute diff in sigma:\n",
      "[[0.         0.06672093]\n",
      " [0.06672093 0.        ]]\n",
      "Absolute diff in A:\n",
      "[[0.29179629 0.2189707 ]\n",
      " [0.28906777 0.35961924]\n",
      " [0.21623012 0.28752357]\n",
      " [0.13960258 0.07580624]\n",
      " [0.94407456 0.83875077]\n",
      " [0.26566976 0.0921888 ]\n",
      " [0.8588889  0.60967201]\n",
      " [0.4541988  1.97733042]\n",
      " [0.7166948  0.81522977]\n",
      " [0.49670402 0.63654986]\n",
      " [0.59753613 0.66227319]\n",
      " [0.04761579 0.02388526]\n",
      " [2.45187526 2.95187018]\n",
      " [2.05150774 2.1132618 ]\n",
      " [1.52474853 1.93037323]\n",
      " [0.33764181 0.52745376]\n",
      " [0.64758434 0.6035581 ]\n",
      " [2.64901918 4.02863526]\n",
      " [0.03732618 0.17511293]\n",
      " [0.91611096 1.03326905]]\n",
      "Absolute diff in delta:\n",
      "[0.07113793 0.06573959 0.17260084 0.00436298 0.14739765 0.07572227\n",
      " 0.03718611 1.1146451  0.03792224 0.10299985 0.05380507 0.03831579\n",
      " 0.0305107  0.1053365  0.10840582 0.05437313 0.13176353 0.06392554\n",
      " 0.0874747  0.0678701 ]\n",
      "Absolute diff in sigma:\n",
      "[[0.         0.49573932]\n",
      " [0.49573932 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "performance_dict = mirt_param_recovery(sample_size=1000, item_dimension=20, latent_dimension=2, q_type=\"seperated\", girth=True, stop_threshold=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "##### Results for Fixed random Covariance 1, girth included\n",
      "Latent dimension: 2,  Item dimension: 20, sample size 1000 \\\n",
      "Runtime: 57.16 seconds, 14 steps, 4.08 seconds per step \\\n",
      "Optimal marginal Likelihood: -11668.66, Estimated: -11672.6, Initial -12307.41\n",
      "|               |   rmse_A |   rmse_delta |   rmse_sigma |\n",
      "|:--------------|---------:|-------------:|-------------:|\n",
      "| estimated     | 0.183251 |    0.0861252 |    0.0215108 |\n",
      "| early_initial | 0.786712 |    0.393667  |    0.0471788 |\n",
      "| girth         | 1.28298  |    0.263374  |    0.350541  |\n"
     ]
    }
   ],
   "source": [
    "print_result(performance_dict, \"Fixed random Covariance 1, girth included\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------\n",
    "##### Results for Seperated Q-Matrix\n",
    "Latent dimension: 2,  Item dimension: 20, sample size 1000 \\\n",
    "Runtime: 142.07 seconds, 26 steps, 5.46 seconds per step \\\n",
    "Optimal marginal Likelihood: -9384.38, Estimated: -10189.47, Initial -11459.9\n",
    "|               |   rmse_A |   rmse_delta |   rmse_sigma |\n",
    "|:--------------|---------:|-------------:|-------------:|\n",
    "| estimated     |  4.00013 |      3.10678 |    0.0201383 |\n",
    "| early_initial |  4.5183  |      2.5846  |    0.165491  |\n",
    "\n",
    "------------------------------------\n",
    "##### Results for BFGS for Q_0 with approximate Jacobi\n",
    "Latent dimension: 2,  Item dimension: 20, sample size 1000 \\\n",
    "Runtime: 61.55 seconds, 12 steps, 5.13 seconds per step \\\n",
    "Optimal marginal Likelihood: -9363.89, Estimated: -9711.58, Initial -10528.79\n",
    "|               |   rmse_A |   rmse_delta |   rmse_sigma |\n",
    "|:--------------|---------:|-------------:|-------------:|\n",
    "| estimated     |  3.02507 |      1.83482 |    0.0645047 |\n",
    "| early_initial |  2.06432 |      2.18337 |    0.289049  |\n",
    "\n",
    "------------------------------------\n",
    "##### Results for Monte Carlo sample varying through ttest\n",
    "Latent dimension: 2,  Item dimension: 20, sample size 1000 \\\n",
    "Runtime: 325.73 seconds, 42 steps, 7.76 seconds per step \\\n",
    "Optimal marginal Likelihood: -9929.77, Estimated: -10179.96, Initial -10767.41\n",
    "|               |   rmse_A |   rmse_delta |   rmse_sigma |\n",
    "|:--------------|---------:|-------------:|-------------:|\n",
    "| estimated     |  1.25777 |     0.965894 |   0.00557421 |\n",
    "| early_initial |  1.98812 |     1.68516  |   0.719705   |\n",
    "\n",
    "------------------------------------\n",
    "##### Results for Fixed random Covariance 1, girth included\n",
    "Latent dimension: 2,  Item dimension: 20, sample size 1000 \\\n",
    "Runtime: 57.16 seconds, 14 steps, 4.08 seconds per step \\\n",
    "Optimal marginal Likelihood: -11668.66, Estimated: -11672.6, Initial -12307.41\n",
    "|               |   rmse_A |   rmse_delta |   rmse_sigma |\n",
    "|:--------------|---------:|-------------:|-------------:|\n",
    "| estimated     | 0.183251 |    0.0861252 |    0.0215108 |\n",
    "| early_initial | 0.786712 |    0.393667  |    0.0471788 |\n",
    "| girth         | 1.28298  |    0.263374  |    0.350541  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jesper\\Documents\\GitHub\\Knowledge-Growth-Prediction\\models\\mirt_2pl.py:103: RuntimeWarning: overflow encountered in exp\n",
      "  np.divide(1, np.add(1, np.exp(np.multiply(-1, linear_predictor)))))\n",
      "c:\\Users\\Jesper\\anaconda3\\lib\\site-packages\\scipy\\stats\\_qmc.py:2039: UserWarning: The balance properties of Sobol' points require n to be a power of 2.\n",
      "  samples = self.engine.random(n)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real latent covariance: [[1.     0.7348 0.5198]\n",
      " [0.7348 1.     0.5761]\n",
      " [0.5198 0.5761 1.    ]]\n",
      "Covariance matrix is good: True\n",
      "EM Iteration 2\n",
      "Current Monte Carlo Sample size: 600\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 2: current parameter_diff: 17.589659429116335, current marginal loglikelihood: -11681.696866135531\n",
      "EM Iteration 3\n",
      "Current Monte Carlo Sample size: 600\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 3: current parameter_diff: 6.6248661211591, current marginal loglikelihood: -11434.243215445382\n",
      "EM Iteration 4\n",
      "Current Monte Carlo Sample size: 600\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 4: current parameter_diff: 3.745292330440992, current marginal loglikelihood: -11346.077090722109\n",
      "EM Iteration 5\n",
      "Current Monte Carlo Sample size: 600\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 5: current parameter_diff: 2.866350978862611, current marginal loglikelihood: -11296.555396972382\n",
      "EM Iteration 6\n",
      "Current Monte Carlo Sample size: 600\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 6: current parameter_diff: 4.843487886961234, current marginal loglikelihood: -11206.074384934132\n",
      "EM Iteration 7\n",
      "Current Monte Carlo Sample size: 600\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 7: current parameter_diff: 2.3698502534011294, current marginal loglikelihood: -11132.711168291855\n",
      "EM Iteration 8\n",
      "Current Monte Carlo Sample size: 600\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 8: current parameter_diff: 3.743662792665709, current marginal loglikelihood: -11075.375429941738\n",
      "EM Iteration 9\n",
      "Current Monte Carlo Sample size: 600\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 9: current parameter_diff: 4.709566651410383, current marginal loglikelihood: -11043.31315517367\n",
      "EM Iteration 10\n",
      "Current Monte Carlo Sample size: 600\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 10: current parameter_diff: 3.523885407534092, current marginal loglikelihood: -11005.878887990753\n",
      "EM Iteration 11\n",
      "Current Monte Carlo Sample size: 600\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 11: current parameter_diff: 2.566733923263009, current marginal loglikelihood: -10984.515860855816\n",
      "EM Iteration 12\n",
      "Current Monte Carlo Sample size: 600\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 12: current parameter_diff: 0.4065887971500661, current marginal loglikelihood: -10979.264949556546\n",
      "EM Iteration 13\n",
      "Current Monte Carlo Sample size: 720\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 13: current parameter_diff: 0.36220027392360965, current marginal loglikelihood: -10979.800974294703\n",
      "EM Iteration 14\n",
      "Current Monte Carlo Sample size: 720\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 14: current parameter_diff: 0.9456886059154406, current marginal loglikelihood: -10971.693645264642\n",
      "EM Iteration 15\n",
      "Current Monte Carlo Sample size: 720\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 15: current parameter_diff: 0.3509684559632467, current marginal loglikelihood: -10964.28240244005\n",
      "EM Iteration 16\n",
      "Current Monte Carlo Sample size: 720\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 16: current parameter_diff: 0.9650992091605641, current marginal loglikelihood: -10960.633993209485\n",
      "EM Iteration 17\n",
      "Current Monte Carlo Sample size: 864\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 17: current parameter_diff: 0.08428961603257437, current marginal loglikelihood: -10953.349123007996\n",
      "EM Iteration 18\n",
      "Current Monte Carlo Sample size: 864\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 18: current parameter_diff: 2.337396871009521, current marginal loglikelihood: -10948.16433574753\n",
      "EM Iteration 19\n",
      "Current Monte Carlo Sample size: 1036\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 19: current parameter_diff: 0.5271385718031764, current marginal loglikelihood: -10948.796597028633\n",
      "EM Iteration 20\n",
      "Current Monte Carlo Sample size: 1243\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 20: current parameter_diff: 0.2560515764206074, current marginal loglikelihood: -10953.859676058299\n",
      "EM Iteration 21\n",
      "Current Monte Carlo Sample size: 1243\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 21: current parameter_diff: 0.3935255589306581, current marginal loglikelihood: -10953.401636285484\n",
      "EM Iteration 22\n",
      "Current Monte Carlo Sample size: 1243\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 22: current parameter_diff: 1.0697566397761848, current marginal loglikelihood: -10942.958951456876\n",
      "EM Iteration 23\n",
      "Current Monte Carlo Sample size: 1491\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 23: current parameter_diff: 0.4123218500663096, current marginal loglikelihood: -10945.008110300001\n",
      "EM Iteration 24\n",
      "Current Monte Carlo Sample size: 1491\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 24: current parameter_diff: 0.7355436279427344, current marginal loglikelihood: -10937.438647611976\n",
      "EM Iteration 25\n",
      "Current Monte Carlo Sample size: 1491\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 25: current parameter_diff: 0.3085993954789376, current marginal loglikelihood: -10937.518090227815\n",
      "EM Iteration 26\n",
      "Current Monte Carlo Sample size: 1789\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 26: current parameter_diff: 0.018200000000000327, current marginal loglikelihood: -10932.681154288093\n",
      "EM Iteration 27\n",
      "Current Monte Carlo Sample size: 1789\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 27: current parameter_diff: 0.40075979941963946, current marginal loglikelihood: -10931.089577349427\n",
      "EM Iteration 28\n",
      "Current Monte Carlo Sample size: 1789\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 28: current parameter_diff: 0.3216375104238497, current marginal loglikelihood: -10930.960857757553\n",
      "EM Iteration 29\n",
      "Current Monte Carlo Sample size: 2146\n",
      "Maximize Q-0\n",
      "Maximize the Q_i's\n",
      "Step: 29: current parameter_diff: 0.02039999999999975, current marginal loglikelihood: -10933.719703600724\n",
      "Absolute diff in A:\n",
      "[[5.50607776e-01 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 3.36757279e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 2.22967557e+00]\n",
      " [2.30478518e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.66012933e+00 0.00000000e+00 0.00000000e+00]\n",
      " [7.59257044e-01 0.00000000e+00 0.00000000e+00]\n",
      " [5.51352831e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.40964052e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.08918377e-01 5.13022690e-02 0.00000000e+00]\n",
      " [1.03348181e+00 5.78653931e-02 0.00000000e+00]\n",
      " [2.60203834e+00 3.50960127e-01 0.00000000e+00]\n",
      " [1.89804237e+00 6.97630053e-02 9.64251830e-01]\n",
      " [9.15306163e-01 4.16126642e-02 1.34809908e+00]\n",
      " [4.65302566e+00 2.77056873e+00 1.18981862e+01]\n",
      " [4.81311797e+00 2.04240686e+00 6.02729507e-01]\n",
      " [1.18332388e+00 6.86212340e-02 1.16471371e+00]\n",
      " [1.07788176e+01 9.78762815e+00 4.00268082e+02]\n",
      " [2.99429035e-01 1.51654972e-01 9.28698621e-01]\n",
      " [1.39312372e-01 1.06060858e-01 2.21301687e-01]\n",
      " [1.62585205e+00 1.20108414e+00 2.83463655e+00]]\n",
      "Absolute diff in delta:\n",
      "[1.04797806e-02 2.14483697e+00 3.81551782e-01 3.96555022e-04\n",
      " 4.06003557e-01 3.40567413e-02 8.39229975e-01 4.69722159e-01\n",
      " 1.45696056e-01 1.62428878e-02 3.04446915e-01 1.65778087e-01\n",
      " 1.64967519e-03 5.58799636e+00 7.70281597e-01 7.31167451e-02\n",
      " 1.39558610e+01 2.63111036e-02 9.22484108e-02 1.37336457e+00]\n",
      "Absolute diff in sigma:\n",
      "[[0.     0.3917 1.0874]\n",
      " [0.3917 0.     1.112 ]\n",
      " [1.0874 1.112  0.    ]]\n",
      "Absolute diff in A:\n",
      "[[4.49234115e-01 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 4.35682327e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 2.43541784e+00]\n",
      " [2.11102755e+00 0.00000000e+00 0.00000000e+00]\n",
      " [6.60571444e-01 0.00000000e+00 0.00000000e+00]\n",
      " [1.38384257e+00 0.00000000e+00 0.00000000e+00]\n",
      " [3.28078802e+00 0.00000000e+00 0.00000000e+00]\n",
      " [4.12774372e-01 0.00000000e+00 0.00000000e+00]\n",
      " [8.84854996e-01 9.78538604e-01 0.00000000e+00]\n",
      " [1.36221907e+00 3.47200202e-01 0.00000000e+00]\n",
      " [2.11090009e+00 4.39697610e-01 0.00000000e+00]\n",
      " [1.64395014e+00 7.10427102e-01 6.61859180e-03]\n",
      " [9.15306163e-01 1.35369117e-01 1.29894145e+00]\n",
      " [3.74102903e+00 3.71359486e+00 8.11220490e+00]\n",
      " [2.65898998e+00 4.25359291e+00 1.37407279e-01]\n",
      " [1.18332388e+00 8.98521995e-02 1.33304473e+00]\n",
      " [1.06454679e+01 9.09280786e+00 3.98843889e+02]\n",
      " [6.74703142e-01 5.82479811e-01 5.73974234e-02]\n",
      " [1.01791433e+00 9.70724497e-01 7.63019073e-01]\n",
      " [6.64548777e-01 2.19522166e+00 1.89552263e+00]]\n",
      "Absolute diff in delta:\n",
      "[3.06977023e-02 2.14898164e+00 6.27861231e-01 3.21929931e-01\n",
      " 4.13118010e-01 5.29693355e-02 1.78254475e+00 4.59491782e-01\n",
      " 1.12479055e-01 1.02207612e-01 8.12285864e-01 1.17955064e+00\n",
      " 5.32294004e-02 9.20940066e+00 1.59085300e+00 1.33997307e-02\n",
      " 1.41002121e+01 2.93208752e-02 4.58033891e-02 1.31006052e+00]\n",
      "Absolute diff in sigma:\n",
      "[[0.     0.2348 0.0198]\n",
      " [0.2348 0.     0.0761]\n",
      " [0.0198 0.0761 0.    ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jesper\\Documents\\GitHub\\Knowledge-Growth-Prediction\\models\\mirt_2pl.py:103: RuntimeWarning: overflow encountered in exp\n",
      "  np.divide(1, np.add(1, np.exp(np.multiply(-1, linear_predictor)))))\n"
     ]
    }
   ],
   "source": [
    "performance_dict = mirt_param_recovery(sample_size=1000, item_dimension=20, latent_dimension=3, q_type=\"pyramid\", girth=False, stop_threshold=3, ensure_id=True, q_share=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "##### Results for With Covariance Matrix partially aligned to Q-matrix\n",
      "Latent dimension: 3,  Item dimension: 20, sample size 1000 \\\n",
      "Runtime: 304.59 seconds, 30 steps, 10.15 seconds per step \\\n",
      "Optimal marginal Likelihood: -11254.37, Estimated: -10937.57, Initial -12526.56\n",
      "|               |   rmse_A |   rmse_delta |   rmse_sigma |\n",
      "|:--------------|---------:|-------------:|-------------:|\n",
      "| estimated     |  51.7548 |      3.42392 |     0.756073 |\n",
      "| early_initial |  51.5531 |      3.86416 |     0.116728 |\n"
     ]
    }
   ],
   "source": [
    "print_result(performance_dict, \"With Covariance Matrix partially aligned to Q-matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------\n",
    "##### Results for Pyramid Q-Matrix\n",
    "Latent dimension: 3,  Item dimension: 20, sample size 200 \\\n",
    "Runtime: 121.22 seconds, 46 steps, 2.64 seconds per step \\\n",
    "Optimal marginal Likelihood: -2144.15, Estimated: -2155.08, Initial -2699.63\n",
    "|               |   rmse_A |   rmse_delta |   rmse_sigma |\n",
    "|:--------------|---------:|-------------:|-------------:|\n",
    "| estimated     |  11.0034 |      1.77461 |     0.889828 |\n",
    "| early_initial |  10.5116 |      2.15986 |     0.522199 |\n",
    "\n",
    "------------------------------------\n",
    "##### Results for Pyramid Q-Matrix\n",
    "Latent dimension: 3,  Item dimension: 20, sample size 1000 \\\n",
    "Runtime: 313.22 seconds, 51 steps, 6.14 seconds per step \\\n",
    "Optimal marginal Likelihood: -9452.24, Estimated: -9813.87, Initial -11216.48\n",
    "|               |   rmse_A |   rmse_delta |   rmse_sigma |\n",
    "|:--------------|---------:|-------------:|-------------:|\n",
    "| estimated     |  5.34115 |      1.4068  |     0.425982 |\n",
    "| early_initial |  5.98238 |      2.25109 |     0.234288 |\n",
    "\n",
    "------------------------------------\n",
    "##### Results for Pyramid Q-Matrix\n",
    "Latent dimension: 3,  Item dimension: 30, sample size 2000 \\\n",
    "Runtime: 1521.51 seconds, 76 steps, 20.02 seconds per step \\\n",
    "Optimal marginal Likelihood: -30844.13, Estimated: -32521.34, Initial -37390.6\n",
    "|               |   rmse_A |   rmse_delta |   rmse_sigma |\n",
    "|:--------------|---------:|-------------:|-------------:|\n",
    "| estimated     |  2.55959 |       1.9952 |    0.314331  |\n",
    "| early_initial |  3.32034 |       3.514  |    0.0239562 |\n",
    "\n",
    "------------------------------------\n",
    "##### Results for BFGS for Q_0 with approximated gradient\n",
    "Latent dimension: 3,  Item dimension: 20, sample size 1000 \\\n",
    "Runtime: 350.28 seconds, 64 steps, 5.47 seconds per step \\\n",
    "Optimal marginal Likelihood: -10498.87, Estimated: -11303.0, Initial -12740.14\n",
    "|               |   rmse_A |   rmse_delta |   rmse_sigma |\n",
    "|:--------------|---------:|-------------:|-------------:|\n",
    "| estimated     |  10.2704 |     0.68597  |    0.318713  |\n",
    "| early_initial |  10.4626 |     0.846172 |    0.0895367 |\n",
    "\n",
    "------------------------------------\n",
    "##### Results for BFGS for Q_0 with exact gradient\n",
    "Latent dimension: 3,  Item dimension: 20, sample size 1000 \\\n",
    "Runtime: 152.91 seconds, 31 steps, 4.93 seconds per step \\\n",
    "Optimal marginal Likelihood: -11106.69, Estimated: -11211.51, Initial -12370.23\n",
    "|               |   rmse_A |   rmse_delta |   rmse_sigma |\n",
    "|:--------------|---------:|-------------:|-------------:|\n",
    "| estimated     |  3.5074  |      2.54509 |     0.21123  |\n",
    "| early_initial |  3.51819 |      2.66313 |     0.319647 |\n",
    "\n",
    "------------------------------------\n",
    "##### Results for Newton-Raphson for Q_0 with approximated second derivative\n",
    "Latent dimension: 3,  Item dimension: 20, sample size 1000 \\\n",
    "Runtime: 352.93 seconds, 62 steps, 5.69 seconds per step \\\n",
    "Optimal marginal Likelihood: -10237.22, Estimated: -10482.36, Initial -12569.49\n",
    "|               |   rmse_A |   rmse_delta |   rmse_sigma |\n",
    "|:--------------|---------:|-------------:|-------------:|\n",
    "| estimated     |  5.23694 |      2.45127 |     0.508499 |\n",
    "| early_initial |  5.36172 |      3.29141 |     0.640209 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real latent covariance: [[1.     0.6388 0.    ]\n",
      " [0.6388 1.     0.    ]\n",
      " [0.     0.     1.    ]]\n",
      "Covariance matrix is good: True\n",
      "EM Iteration 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jesper\\anaconda3\\lib\\site-packages\\scipy\\stats\\_qmc.py:2039: UserWarning: The balance properties of Sobol' points require n to be a power of 2.\n",
      "  samples = self.engine.random(n)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Monte Carlo Sample size: 600\n",
      "Step: 2: current parameter_diff: 20.550243550546323, current marginal loglikelihood: -18149.686153495782\n",
      "EM Iteration 3\n",
      "Current Monte Carlo Sample size: 600\n",
      "Step: 3: current parameter_diff: 10.215343616726535, current marginal loglikelihood: -17883.31370973797\n",
      "EM Iteration 4\n",
      "Current Monte Carlo Sample size: 600\n",
      "Step: 4: current parameter_diff: 7.723302485746889, current marginal loglikelihood: -17771.151983294196\n",
      "EM Iteration 5\n",
      "Current Monte Carlo Sample size: 600\n",
      "Step: 5: current parameter_diff: 3.8262687990163315, current marginal loglikelihood: -17686.13343764576\n",
      "EM Iteration 6\n",
      "Current Monte Carlo Sample size: 600\n",
      "Step: 6: current parameter_diff: 3.8036503763306806, current marginal loglikelihood: -17652.39359227588\n",
      "EM Iteration 7\n",
      "Current Monte Carlo Sample size: 600\n",
      "Step: 7: current parameter_diff: 3.0244823809405057, current marginal loglikelihood: -17629.497205774373\n",
      "EM Iteration 8\n",
      "Current Monte Carlo Sample size: 600\n",
      "Step: 8: current parameter_diff: 1.1105155323231457, current marginal loglikelihood: -17621.40003655325\n",
      "EM Iteration 9\n",
      "Current Monte Carlo Sample size: 600\n",
      "Step: 9: current parameter_diff: 1.0514243266099617, current marginal loglikelihood: -17605.719811084673\n",
      "EM Iteration 10\n",
      "Current Monte Carlo Sample size: 600\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "New Covariance not positive semidefinite",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Jesper\\Documents\\GitHub\\Knowledge-Growth-Prediction\\simulation_experiments.ipynb Zelle 23\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Jesper/Documents/GitHub/Knowledge-Growth-Prediction/simulation_experiments.ipynb#X43sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m performance_dict \u001b[39m=\u001b[39m mirt_param_recovery(sample_size\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m, item_dimension\u001b[39m=\u001b[39;49m\u001b[39m30\u001b[39;49m, latent_dimension\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m, q_type\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mfull\u001b[39;49m\u001b[39m\"\u001b[39;49m, girth\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, stop_threshold\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m, q_share\u001b[39m=\u001b[39;49m\u001b[39m0.0\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\Jesper\\Documents\\GitHub\\Knowledge-Growth-Prediction\\simulation_experiments.ipynb Zelle 23\u001b[0m in \u001b[0;36mmirt_param_recovery\u001b[1;34m(sample_size, item_dimension, latent_dimension, q_type, girth, stop_threshold, ensure_id, q_share)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Jesper/Documents/GitHub/Knowledge-Growth-Prediction/simulation_experiments.ipynb#X43sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39m#Fit Model\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Jesper/Documents/GitHub/Knowledge-Growth-Prediction/simulation_experiments.ipynb#X43sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Jesper/Documents/GitHub/Knowledge-Growth-Prediction/simulation_experiments.ipynb#X43sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m em\u001b[39m.\u001b[39;49mfit(sample[\u001b[39m\"\u001b[39;49m\u001b[39mearly_responses\u001b[39;49m\u001b[39m\"\u001b[39;49m], max_iter\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, stop_threshold\u001b[39m=\u001b[39;49mstop_threshold)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Jesper/Documents/GitHub/Knowledge-Growth-Prediction/simulation_experiments.ipynb#X43sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m run_time \u001b[39m=\u001b[39m  (time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Jesper/Documents/GitHub/Knowledge-Growth-Prediction/simulation_experiments.ipynb#X43sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39m#Measure Performance\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jesper\\Documents\\GitHub\\Knowledge-Growth-Prediction\\em_algorithm\\em_algorithm.py:48\u001b[0m, in \u001b[0;36mem_algorithm.fit\u001b[1;34m(self, data, hyper_params, max_iter, stop_threshold)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[39m# print(\"M-step\")\u001b[39;00m\n\u001b[0;32m     46\u001b[0m current_parameters, log_likelihood \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mm_step\u001b[39m.\u001b[39mstep(\n\u001b[0;32m     47\u001b[0m     pe_functions\u001b[39m=\u001b[39mposterior_expectation)\n\u001b[1;32m---> 48\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mset_parameters(current_parameters)\n\u001b[0;32m     49\u001b[0m marginal_loglikelihood \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mmarginal_response_loglikelihood(\n\u001b[0;32m     50\u001b[0m     data\u001b[39m.\u001b[39mto_numpy())\n\u001b[0;32m     51\u001b[0m marginal_loglikelihood_diff \u001b[39m=\u001b[39m \u001b[39mabs\u001b[39m(\n\u001b[0;32m     52\u001b[0m     marginal_loglikelihood \u001b[39m-\u001b[39m last_step_marginal_loglikelihood)\n",
      "File \u001b[1;32mc:\\Users\\Jesper\\Documents\\GitHub\\Knowledge-Growth-Prediction\\models\\mirt_2pl.py:189\u001b[0m, in \u001b[0;36mmirt_2pl.set_parameters\u001b[1;34m(self, parameters)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mperson_parameters\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m parameters\u001b[39m.\u001b[39mkeys():\n\u001b[0;32m    188\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mperson_parameters\u001b[39m.\u001b[39mupdate(parameters[\u001b[39m\"\u001b[39m\u001b[39mperson_parameters\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m--> 189\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcheck_sigma()\n",
      "File \u001b[1;32mc:\\Users\\Jesper\\Documents\\GitHub\\Knowledge-Growth-Prediction\\models\\mirt_2pl.py:76\u001b[0m, in \u001b[0;36mmirt_2pl.check_sigma\u001b[1;34m(self, sigma)\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCovariance is not symmetric\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     75\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39mall(np\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39meigvals(sigma) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m):\n\u001b[1;32m---> 76\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNew Covariance not positive semidefinite\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     77\u001b[0m \u001b[39mreturn\u001b[39;00m(\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;31mException\u001b[0m: New Covariance not positive semidefinite"
     ]
    }
   ],
   "source": [
    "performance_dict = mirt_param_recovery(sample_size=1000, item_dimension=30, latent_dimension=3, q_type=\"full\", girth=False, stop_threshold=5, q_share=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "##### Results for With BFGS as covariance optimization Algorithm\n",
      "Latent dimension: 3,  Item dimension: 20, sample size 1000 \\\n",
      "Runtime: 160.7 seconds, 20 steps, 8.04 seconds per step \\\n",
      "Optimal marginal Likelihood: -11451.44, Estimated: -11746.37, Initial -12757.23\n",
      "|               |   rmse_A |   rmse_delta |   rmse_sigma |\n",
      "|:--------------|---------:|-------------:|-------------:|\n",
      "| estimated     |  4.12413 |      1.19297 |     0.539132 |\n",
      "| early_initial |  4.06187 |      1.22103 |     0.159225 |\n"
     ]
    }
   ],
   "source": [
    "print_result(performance_dict, \"With BFGS as covariance optimization Algorithm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procedure for better model performance:\n",
    "\n",
    "1. Implement MIRT Baseline (done)\n",
    "2. Test GA with quadratic function (done)\n",
    "3. use pycma (done)\n",
    "4. Test mirt-functions (response-matrix-probability, done)\n",
    "5. Read on MC MIRT (MC-Errorbounds usage or quasi-MC or importance sampling)\n",
    "6. Use importance sampling\n",
    "7. Implement Newton Raphson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimeted Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 2., 0., 0.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [0., 0., 2., 2.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.optimize import approx_fprime\n",
    "\n",
    "def func(C_vector):\n",
    "    dim = np.sqrt(C_vector.shape).astype(np.int)[0]\n",
    "    C = C_vector.reshape((dim, dim))\n",
    "    sigma = np.matmul(C, C.transpose())\n",
    "    return(sigma.flatten())\n",
    "\n",
    "approx_fprime(f=func, xk=np.ones(2*2))\n",
    "\n",
    "#Ich brauche wohl irgendeine Art von Matrixprodukt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.49011612e-08, 2.00000001e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [2.00000000e+00, 3.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n",
       "       [2.00000000e+00, 3.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 4.00000000e+00, 6.00000000e+00]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "approx_fprime(f=func, xk=np.arange(0,4\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "652797d8287891e02114b51113b60303721b445f646084412baf5ae81281ba43"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
